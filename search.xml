<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【译文】使用BPF控制内核的ops结构体]]></title>
    <url>%2F2020%2F02%2F08%2FTranslation-Kernel-operations-structures-in-BPF%2F</url>
    <content type="text"><![CDATA[Linux内核5.6版本的众多令人惊喜的功能之一是：TCP拥塞控制算法（congestion control algorithm）可作为用户空间的BPF(Berkeley Packet Filter)程序进行加载和执行。网络开发者Toke Høiland-Jørgensen将这项功能描述为“内核正向成为支持BPF运行时的微内核迈进(march towards becoming BPF runtime-powered microkernel)”的延续性动作。从外表上看，这是赋予给BPF的一项重要的新功能，使得拥塞控制将远远超过现有能力。但当我们深入研究后发现，其令人惊喜之处远不止这些，因为该功能的实现在多个方面都取得了新的进展。 该功能的使用场景和用例似乎都比较明确，因为有大量不同的拥塞控制算法已在使用中，且每种算法都适合于不同的网络环境。利用该功能，我们有充足方法来分发更新或改进后的控制算法，因为使用者能够在无需重新构建内核甚至无需重启的情况下使用新算法，使得网络功能开发者可从运行中的拥塞控制代码中获得好处。有人可能会质疑，拥塞控制功能在概念上与BPF现有的其它功能（例如flow dissection或Infrared协议解码）没有本质的不同，但需要指出的是，拥塞控制确实涉及到相当高的复杂性。 如果看一下Martin KaFai Lau发布的patch集合，你就会发现5.6版本内核将要合并的代码不仅仅是一项能够hook住TCP拥塞控制的机制，其真实威力远不止于此。具体地说，这种新架构可用于允许BPF程序替换内核中的任何“ops结构(struct xxx_ops)”——一个由函数指针组成的结构。目前，虽然它只能替换用于拥塞控制的struct tcp_congestion_ops结构，但大量的经验表明，在内核其他地方的应用将很快涌现。 用户空间API 在用户空间中，加载新的ops结构需要如下几个步骤。首先，使用bpf()系统调用以单独的BPF程序对每个函数的实现进行加载，这些BPF程序已经可以使用新的BPF_PROG_TYPE_STRUCT_OPS类型定义ops。用户空间在每个程序提供的属性中，必须提供与要替换的结构相对应的BPF类型格式（BPF Type Format，BTF）的ID（同时用于指定稍后要实现的实际功能）。 BTF是一项较新的特性，它描述了正在运行的内核中的函数和数据结构，目前用于追踪函数的类型检查。 用户空间还必须指定一个整数偏移量，以标识此程序将要替换的函数。例如，struct tcp_congestion_ops的函数指针字段ssthresh()在结构中位于第六个字段，因此将5作为偏移量进行传递（偏移量从0开始）。目前还不明确该API如何与结构布局随机化（structure layout randomization）进行交互。 在加载每个结构字段对应的程序时，内核将返回与每个结构字段相对应的文件描述符。为了使用此描述符，用户空间还必须填充如下的结构： 12345struct bpf_tcp_congestion_ops &#123; refcount_t refcnt; enum bpf_struct_ops_state state; struct tcp_congestion_ops data;&#125;; 上面的代码中，data字段的类型是将要替换的结构——在拥塞控制中也就是struct tcp_congestion_ops，但是，此结构应包含已加载用于实现对应拥塞控制功能的程序的文件描述符，而非函数指针。尽管内核可以按如下所述覆盖内容，但也应根据需要设置该结构中的非函数字段。 最后一步，是将该结构加载到内核中，有多种方式来达到该目的，因此实际的实现几乎可以肯定是另外的方式。用户空间必须使用新添加的BPF_MAP_TYPE_STRUCT_OPS类型创建一个特殊的BPF map，与该map相关联的是内核中特殊结构的BTF类型ID（如下所述），这就是将map与要替换的结构连接在一起的方式。实际的结构替换是通过将上面的bpf_tcp_congestion_ops结构存储到零填充的map中来完成的，此外还支持的操作包括：查询map（以获取引用计数和状态字段）和通过删除元素0来删除结构。 近年来，BPF maps相关的功能和特性不断的出现，即便如此，这次添加的新功能似乎是map作首次在内核产生类似副作用的方法。也许本功能不是最优雅的接口，但大多数用户空间的开发者将永远看不到它背后的大部分细节，因为它就像其他大多数BPF的API一样，隐藏在libbpf库中的一系列宏和对象的背后。 内核空间 由于用户空间无权限任意替换结构，所以替换ops结构需要内核的支持，为了支持这样的替换，内核态必须新添加如下结构： 123456789101112131415161718#define BPF_STRUCT_OPS_MAX_NR_MEMBERS 64struct bpf_struct_ops &#123; const struct bpf_verifier_ops *verifier_ops; int (*init)(struct btf *btf); int (*check_member)(const struct btf_type *t, const struct btf_member *member); int (*init_member)(const struct btf_type *t, const struct btf_member *member, void *kdata, const void *udata); int (*reg)(void *kdata); void (*unreg)(void *kdata); const struct btf_type *type; const struct btf_type *value_type; const char *name; struct btf_func_model func_models[BPF_STRUCT_OPS_MAX_NR_MEMBERS]; u32 type_id; u32 value_id;&#125;; 本文无法包含所有这些代码的细节，并且由于宏的存在，它自动填充此结构的某些字段。 值得说明的是，verifier_ops结构中有多个函数，可用于验证各个替换功能是否可安全执行。在即将合并的补丁集中，该结构中添加了一个新字段：struct_access()，其用于控制BPF函数可以更改ops结构本身的哪些部分（如果有的话）。 内核在获取到用户空间的请求后，首先调用init()函数，来进行一切所必需的全局设置。check_member()函数决定是否允许目标结构的特定成员在BPF中实现，而init_member()则用于验证该结构中所有字段的确切值，特别地，init_member()可以验证非函数字段（例如flag字段）。 在检查通过后，则通过reg()函数进行实际地注册替换结构，具体地，在拥塞控制的场景下，该函数将tcp_congestion_ops结构（和用于函数指针的BPF相关的trampoline）安装在网络栈中将要使用的位置。相反地，unreg()则用于撤消操作。 这种类型的结构应使用特定名称创建，即添加bpf_前缀。因此，用于替换tcp_congestion_ops结构的ops结构的名字为bpf_tcp_congestion_ops，这是加载新的ops结构时用户空间必须（通过BTF的ID）引用的“特殊结构”。最后，在kernel/bpf/bpf_struct_ops_types.h中添加如下的一行代码： 1BPF_STRUCT_OPS_TYPE(tcp_congestion_ops) 借助宏操作，以及将此文件四次include到bpf_struct_ops.c中，便可处理好所有设置，而无需特殊的函数注册该结构类型。 总结 tcp_congestion_ops替换机制中内核态的实现可以在net/ipv4/bpf_tcp_ca.c文件中找到，源码树中已有两种不同控制算法的实现（DCTCP和CUBIC）。 可替换内核中任意ops结构是一项潜在的强大功能，因为内核中很大一部分代码是通过这种类型的结构调用的。比如说，如果可以替换全部或部分security_hook_heads结构，则可以以任意方式修改安全策略，例如，实现类似于KRSI的功能。还有，替换file_operations结构几乎可以重写内核I/O子系统的任何部分。 目前还没有任何人提出类似的方法，但是这样的功能肯定会吸引感兴趣的开发者。将来会有某个时刻，几乎任何内核功能都可以被用户空间的BPF代码hook或替换，那时用户将拥有改变系统运行方式的强大能力，但是我们认为“Linux内核”将变得更加充满不确定性，这也取决于从用户空间加载了哪些代码。结果可能会很有趣。 (译者注：本文原地址为 https://lwn.net/Articles/811631/)]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>eBPF</tag>
        <tag>ops结构</tag>
        <tag>microkernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【译文】将Restartable Sequcences (rseq)引入Linux的五年之旅]]></title>
    <url>%2F2020%2F01%2F23%2FTranslation-The-5-year-journey-to-bring-restartable-sequences-to-Linux%2F</url>
    <content type="text"><![CDATA[并发控制算法与per-CPU数据成对出现，是确保底层库和高性能应用程序在当今硬件上正确扩展不可或缺的一部分。这些算法保证在并发访问时，用户空间的数据结构始终保持一致，并且用户数据的修改是执行完全的，使得线程观察到的是之前或之后的状态，而非中间状态。 设计这些算法的方法有很多种，最常见的也是扩展性最差的一种是mutex。它的工作原理是，在任何时间，只允许一个线程持有mutex并修改共享数据结构。 但是，mutex并不能很好地扩展，尤其是对于per-CPU数据而言。由于在mutex加锁和解锁的临界区内只能有一个线程可访问，因此可能存在大量线程在等待锁，而等待的时间内线程没有做任何有用的事。 接下来的可扩展并发控制算法是，原子比较和交换。在这个模型中，通常使用单个指令进行同步控制，例如cmpxchg指令或x86体系结构的指令lock前缀。 但这里的问题是，在现代处理器上原子指令代价很高，相比于没有前缀的相同指令，x86的lock前缀很容易在执行成本上增加多个指令周期。更糟糕的是，无论是否只有一个线程在竞争，lock前缀都会无条件执行。 并且，并不是所有体系结构都为原子数据更新提供单独的指令。例如，ARM使用link-load/store-conditional（简称LL/SC）组合指令来读取原始数据、修改原始数据并写入新数据，如果两个线程同时尝试写入，只有一个线程将会成功，另一个线程失败并重启LL/SC指令序列。 Linux内核使用其他方法来保护per-CPU数据，例如禁用抢占或中断，或使用per-CPU本地的原子操作。遗憾的是，这些方法要么不易被用户空间使用，要么相对较慢（例如原子指令）。所以，我们需要一种轻量型的机制，用于在用户空间内保护per-CPU数据，这就是restartable sequences方法（rseq）的产生的动机。 rseq是如何工作的 rseq由新的系统调用rseq(2)所组成，该调用告诉内核当前线程rseq相关的thread-local ABI（sturct rseq对象）在内存中的位置。sturct rseq对象包含一个rseq_cs类型字段，该字段是指向当前被激活的rseq临界区的描述符（sturct rseq_cs对象）的指针，而在任何时候，只能有一个临界区被激活。此ABI有两个用途：用户空间的rseq和快速读取当前CPU编号。 临界区可细分为准备阶段（preparatory stage）和提交阶段（commit stages），其中提交阶段是仅是单条CPU指令。如果在提交阶段之前发生以下任何情况之一，则认为当前临界区被中断： 线程已迁移到另一个CPU上 信号（signal）被传递到该线程 线程被抢占 此外，由于线程被中断时需要回退机制，内核将程序寄存器（instruction pointer）指向中断处理程序的首地址，该处理程序需要执行一些纠正性的措施，例如重新发起准备阶段。在这样的设计下，乐观情况下（线程未被中断）执行速度非常快，因为开销较高的struct rseq_cs的上锁和原子指令可完全避免。 更详细地说，当前rseq临界区是由struct rseq_cs对象所描述，该对象被struct rseq对象所引用。下面用如下的图来说明它们的关系和结构体的字段。 rseq的开始和结束由start_ip和post_commit_ip（指向提交阶段后的首地址指令）所表示，而abort_ip指向中断处理程序的首地址指令。 值得注意的是，临界区和中断处理程序的实现都有所限制。例如，中止处理程序必须处于临界区以外，以及在临界区内不允许有系统调用，尝试执行系统调用将导致进程发生segmentation fault而终止。 每当线程迁移到其他CPU上执行，且在用户空间程序临界区的开始处读取cpu_id_start并比较这两个值时，内核就会更新cpu_id字段。如果它们的值不同，则正在运行的线程将被中断，且需要重新尝试rseq序列。 内核和用户空间均可修改rseq_cs字段。当启动rseq时，用户空间代码需要将指针设置为当前临界区的描述符。每当在执行当前rseq_cs描述符所描述的临界区范围之外的代码时，或发生抢断或传递信号时，就会将该指针设置为NULL。 rseq的简史 Linux在4.18内核版本中合并了对rseq的支持。作为一种无需锁或开销较高的原子指令，即可从用户空间数据中安全访问per-CPU数据的方法，restartable sequences的概念最初是由Paul Turner和Andrew Hunter在2013年所提出，但在当时还没有可用的patch。 两年后，为了促使他们将其补丁发布到Linux kernel的mailing list中，Mathieu Desnoyers于2015年5月提交了针对per-CPU临界区的patch。一个月后，Paul发布了rseq的第一个patch集合。虽然Paul在发布该版本之后便停了下来，Mathieu于2016年又重新接手，提交了新的patch集合，并在LPC 2016上介绍了这一工作。他原本希望将patch合并到Linux内核的4.15版本中，但发现存在如下的障碍： 虽然几乎每个版本的patch集都有benchmark数据，但Linus明确表示，这种假设的用例不足以合并rseq的相关功能，并需要具体的性能数据作为支撑。 后来，Facebook提供了在jemalloc内存分配器上使用patch的数据结果。因此，Mathieu收集了更多类似的benchmark结果，并在其他项目（如LTTng-UST、Userspace RCU和glibc）上提供了rseq的支持。 最终，在最初开始的五年之后，该patch集终于被合并到Linux内核中，Mathieu在Open Source Summit Europe 2018上作了名为Improve Linux User-Space Core Libraries with Restartable Sequences的演讲，其中介绍了将rseq带入Linux的多年努力。 如何在库和程序中使用rseq 使用rseq的首选方法是使用librseq，该库提供了可能会用到的所有per-CPU操作，例如使rseq(2)调用对当前线程可用（rseq_register_current_thread()），查询当前线程的CPU编号（rseq_current_cpu()），以及更新per-CPU数据（rseq_cmpeqv_storev()）。 但如果要实现自己需要的特定操作，请继续阅读以获得更详细的说明。 使用rseq(2)需要以下两步。首先，使用rseq(2)为当前线程启用该功能，该系统调用具有以下的函数原型： 1sys_rseq(struct rseq *rseq, uint32_t rseq_len, int flags, uint32_t sig) 该系统调用的目的是向内核注册struct rseq对象，其中flags参数为0表示注册，rseq_FLAG_UNREGISTER表示注销。sig参数是可用于验证rseq上下文的签名，也就是说，用于注册的签名必须与用于注销的签名相同。 比如说，你想使用rseq(2)来增加per-CPU计数器的值，为此，需要获取当前线程的CPU编号（存储在struct rseq的cpu_id_start字段中），并使用rseq修改per-CPU计数器的值。因此，需要通过C和汇编混写的代码实现，下面是完成该操作的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#define _GNU_SOURCE#include &lt;linux/rseq.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;syscall.h&gt;#include &lt;stdint.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/syscall.h&gt;static __thread volatile struct rseq __rseq_abi;#define rseq_SIG 0x53053053static int sys_rseq(volatile struct rseq *rseq_abi, uint32_t rseq_len, int flags, uint32_t sig)&#123; return syscall(__NR_rseq, rseq_abi, rseq_len, flags, sig);&#125;static void register_thread(void)&#123; int rc; rc = sys_rseq(&amp;__rseq_abi, sizeof(struct rseq), 0, rseq_SIG); if (rc) &#123; fprintf(stderr, "Failed to register rseq\n"); exit(1); &#125;&#125;#define rseq_ACCESS_ONCE(x) (*(__volatile__ __typeof__(x) *)&amp;(x))static int rseq_addv(intptr_t *v, intptr_t count, int cpu)&#123; __asm__ __volatile__ goto( ".pushsection __rseq_table, \"aw\"\n\t" ".balign 32\n\t" "cs_obj:\n\t" ".long 0, 0\n\t" /* start_ip, post_commit_ip, abort_ip */ ".quad 1f, 2f, 4f\n\t" ".popsection\n\t" "1:\n\t" "leaq cs_obj(%%rip), %%rax\n\t" "movq %%rax, %[rseq_cs]\n\t" "cmpl %[cpu_id], %[current_cpu_id]\n\t" "jnz 4f\n\t" "addq %[count], %[v]\n\t" /* final store */ "2:\n\t" ".pushsection __rseq_failure, \"ax\"\n\t" /* Disassembler-friendly signature: nopl &lt;sig&gt;(%rip). */ ".byte 0x0f, 0x1f, 0x05\n\t" ".long 0x53053053\n\t" /* rseq_FLAGS */ "4:\n\t" "jmp abort\n\t" ".popsection\n\t" : /* gcc asm goto does not allow outputs */ : [cpu_id] "r" (cpu), [current_cpu_id] "m" (__rseq_abi.cpu_id), [rseq_cs] "m" (__rseq_abi.rseq_cs), /* final store input */ [v] "m" (*v), [count] "er" (count) : "memory", "cc", "rax" : abort ); return 0;abort: return -1;&#125;int main(int argc, char **argv)&#123; int cpu, ret; intptr_t *cpu_data; long nr_cpus = sysconf(_SC_NPROCESSORS_ONLN); cpu_data = calloc(nr_cpus, sizeof(*cpu_data)); if (!cpu_data) &#123; perror("calloc"); exit(EXIT_FAILURE); &#125; register_thread(); cpu = rseq_ACCESS_ONCE(__rseq_abi.cpu_id_start); ret = rseq_addv(&amp;cpu_data[cpu], 1, cpu); if (ret) fprintf(stderr, "Failed to increment per-cpu counter\n"); else printf("cpu_data[%d] == %ld\n", cpu, cpu_data[cpu]); return 0;&#125; rseq_addv()中的代码以struct rseq_cs对象填充作为开始，该对象描述了rseq中的字段，其中start的label为1，post-commit为2，中断处理程序为4。如果线程未完成1和2之间的序列，那么将直接控制跳转到标签4，然后跳转到C中的abort位置处。 注意：必须确保CPU编号只读取一次，在编译器层面需要强制使用volatile关键字来保证这一点，而在上面的例子中，rseq_ACCESS_ONCE()宏对此提供了保证。 rseq到底有多快? rseq的主要使用场景之一是获取执行当前线程的CPU编号，通常也就是指向per-CPU数据结构的索引值。当前使用sched_getcpu()来获取CPU编号的方法，在ARM上需进行系统调用，在 x86上需调用VDSO，而rseq(2)则允许程序直接读取内核和用户空间之间共享的struct rseq对象中缓存的CPU编号值。 在该场景下，rseq在X86平台可获得20倍加速，而在ARM平台上则是35倍加速。 下图展示了获取执行当前线程的CPU编号的rseq方法的速度提升，值越小越好，其反映了速度的提升。 在arm32上读取当前CPU编号benchmark(来自于 www.efficios.com) 在x86_64上读取当前CPU编号benchmark(来自于 www.efficios.com) 如上所述，rseq也适用于其他多种使用per-CPU数据的场景，其中之一是存储计数器值。下图展示了使用rseq(2)增加per-CPU计数器时，相对于使用sched_getcpu()和原子指令的速度提升。在ARM平台上显示有11倍的提升，而在x86显示是7.7倍提升。 在arm32上统计增加计数器benchmark(来自于 www.efficios.com) 在x86_64上统计增加计数器benchmark(来自于 www.efficios.com) LTTng-UST使用per-CPU的buffer来存储event。下图展示了使用rseq(2)在per-CPU缓存中存储32位header和event时，相对于使用sched_getcpu()和原子指令的速度提升。在ARM平台上显示有1.1x的提升，而在x86显示是1.2x提升。 在arm32的LTTng-UST上将event写入per-CPU缓存的benchmark(来自于 www.efficios.com) 在x86_64的LTTng-UST上将event写入per-CPU缓存的benchmark(来自于 www.efficios.com) 最后，在Userspace RCU项目中，在liburcu库中使用rseq后，在ARM有5.8倍加速，而在x86上有1.9倍加速。 在arm32的liburcu的per-CPU上加/解锁，解引用读/比较的benchmark(来自 于www.efficios.com) 在x86_64的liburcu的per-CPU上加/解锁，解引用读/比较的benchmark(来自于www.efficios.com) 下一步计划 虽然使用rseq(2)的patch适用于LTTng、Userspace RCU和glibc，但它们现在仅处于概念验证阶段。下一阶段的工作，则是将它们合并到各自项目的代码中。对于glibc而言，这意味着patch在线程开始时自动通过rseq(2)注册，在线程退出，以及主线程的NPTL初始化时自动注销。 LTTng-UST的问题有点不同：不更改线程的affinity mask，就无法在per-CPU数据结构之间移动数据。为了解决这个问题，Mathieu提出了一个新的cpu_opv系统调用，类似readv(2)和writev(2)的struct iovec概念，该调用在特定CPU上执行固定向量操作（比较、memcpy 和add）。cpu_opv解决的rseq(2)的另一个问题是，如果单步执行到临界区，调试器将死循环。即使库使用了rseq(2)，新的cpu_opv系统调用也允许调试器与现有应用程序共存。 Mathieu最初希望能及时将新的cpu_opv系统调用合并到Linux内核的4.21版本，但Linus Torvalds已经表示，他希望看到rseq(2)的使用者首先出现，这意味着glibc需要合并那些正在进行的rseq(2)的patch工作。 (译者注：本文原地址为 https://www.efficios.com/blog/2019/02/08/linux-restartable-sequences/)]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Restartable Sequcences</tag>
        <tag>Concurrency</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【译文】在.NET上通过Wasmtime使用WebAssembly]]></title>
    <url>%2F2020%2F01%2F18%2FTranslation-Using-WebAssembly-from-NET-with-Wasmtime%2F</url>
    <content type="text"><![CDATA[概述 来自字节码联盟（Bytecode Alliance）的WebAssembly（以下简称wasm）运行时——Wasmtime，最近添加了针对.NET Core的早期预览版本API，开发者可以在他们的.NET程序中使用该API直接编程加载和运行wasm代码。 那么问题来了，.NET Core已经是跨平台的运行时，为什么.NET开发者还需关注wasm？ 如果你是.NET开发者，那么这里有几个让你对wasm感到兴奋的地方，这包括在所有平台上使用同一份可执行代码，安全地隔离不可信代码，以及通过即将来临的wasm接口类型提案（WebAssembly interface type proposal）来获得无缝的互操作体验等。 在平台间共享更多的代码 .NET编译生成二进制代码已经可以跨平台使用，但使用本地库（例如，通过C或Rust写成的库）却依然比较困难，因为它需要原生的互操作，并且为每一个所支持的平台提供单独的构建。 然而，如果C或者Rust库被编译成wasm模块，那么同一个模块可以被不同的平台和编程环境所使用，其中也包括.NET环境，这将大大简化库和使用这些库的应用的分发。 安全地隔离不可信代码 .NET曾设计使用代码访问安全性（Code Access Security）和应用程序域（Application Domain）技术来沙箱隔离不可信代码，但最终这些技术都未能有效地对不可信代码进行隔离。结果微软最后放弃了沙箱化，并最终将这些技术从.NET Core中移除。 可是，你是否曾经在你的应用中加载不可信插件时，却找不到一种方法来防止插件进行任意系统调用或者直接读取进程的内存。现在，可以通过wasm来达到该目的，因为wasm最初是为任意性很强的Web环境所设计，在Web环境中，每当用户访问网站时，不可信代码都无时不刻在执行。 通过接口类型改进互操作性 wasm的接口类型提案引入了一种新方法，该方法可以减少在托管应用程序和wasm模块之间来回传递更复杂类型所需的粘合代码。新方法的目的是为了wasm更好地与编程语言所集成。 当接口类型最终被wasmtime为.NET所支持后，它将为在wasm和.NET之间交换复杂类型提供无缝的编程体验。 深入研究通过.NET使用wasm 接下来，我们将深入研究，如何使用Wasmtime API在.NET中加载和使用编译为wasm模块的Rust库，因此对C#编程语言稍微熟悉会有所帮助。 这里描述的API相当底层，它意味着，在概念上简单的操作（例如传递或接受字符串）需要大量的粘合代码。 将来，我们还将基于wasm接口类型提供更高级别的API，这将大大减少相同操作所需的代码。使用该API将使你可以像正常.NET程序一样轻松地在.NET中与wasm模块之间进行交互。 还请注意的是，该API仍在开发中，因为我们的目标是保持Wasmtime本身的稳定性，并且可能以向后不兼容的方式发生改变。 如果你不是.NET开发者，那也没问题，请查看Wasmtime的demo代码库，以获取相应的Python，Node.js和Rust等版本的实现。 创建wasm模块 我们将从构建Rust库（pulldown_cmark）开始，该库可用于将markdown文档渲染为HTML。前面已经提到，我们不会将Rust库编译为特定目标体系结构，而是将其编译为wasm格式，使得它们可以在.NET使用。 你并不需要对Rust编程语言熟悉，但是如果是构建wasm模块，那么安装相应的Rust工具链是有用的。有关安装Rust工具链的简便方法，请参考Rustup主页。 此外，我们将使用cargo-wasi，该命令可创建将Rust编译wasm所需的基础代码和编译环境： 1cargo install cargo-wasi 然后，克隆Wasmtime的demo代码库： 12git clone https://github.com/bytecodealliance/wasmtime-demos.gitcd wasmtime-demos 该代码库包括markdown文件目录和相应的Rust代码，其中Rust代码只是封装了pulldown_cmark 而后使用cargo-wasi构建markdown的wasm模块： 12cd markdowncargo wasi build --release 此时，target/wasm32-wasi/release目录中应有编译后的markdown.wasm文件。 如果你对所实现的rust代码感兴趣，请参看src/lib.rs文件，它包含如下内容： 12345678910use pulldown_cmark::&#123;html, Parser&#125;;use wasm_bindgen::prelude::*;#[wasm_bindgen]pub fn render(input: &amp;str) -&gt; String &#123; let parser = Parser::new(input); let mut html_output = String::new(); html::push_html(&amp;mut html_output, parser); return html_output;&#125; 该rust代码的功能是export函数render，该函数的功能是将markdown格式字符串作为输入，处理并返回渲染后的HTML格式字符串。 让我们稍微暂停一下，简单地了解这里所做的事情：我们使用了一个现有的Rust crate，并用几行代码将其封装，其功能作为wasm函数进行了export，然后将其编译为可在.NET加载的wasm模块，而这里我们不用再考虑该模块将在什么平台（或体系结构）上运行，很酷啊兄弟，不是么？！ 检视wasm模块内部现在我们已经有了可使用的wasm模块，那么host需要为它需提供怎样的环境，它又为host提供了怎样的功能？ 为了弄清楚这一点，让我们使用WebAssembly Binary Toolkit里的wasm2wat工具，将模块反汇编成可读文本的表示形式： 1wasm2wat markdown.wasm --enable-multi-value &gt; markdown.wat 注意：--enable-multi-value选项提供对多个返回值函数的支持，这对于反编译markdown.wasm模块是必须的。 模块需要host所提供的环境支持模块的import方式定义了host应为模块提供哪些功能，下面是markdown模块的import段： 12(import &quot;wasi_unstable&quot; &quot;fd_write&quot; (func $fd_write (param i32 i32 i32 i32) (result i32)))(import &quot;wasi_unstable&quot; &quot;random_get&quot; (func $random_get (param i32 i32) (result i32))) 该段申明告诉我们该模块需要host提供两个函数的接口：fd_write和random_get。这两个函数实际上是具有明确行为定义的WebAssembly System Interface（简称WASI）函数：fd_write用于将数据写入特定的文件描述符中，random_get将用随机数据填充某个缓冲区。 很快我们将为.NET的host环境实现这些函数，但更重要的是要明白模块只能从host调用这些函数，host可以决定如何实现这些函数甚至是是否实现这些函数。 模块为主机提供了怎样的功能模块的export段定义了它为host提供的功能函数，以下markdown模块的export段： 123456789101112(export &quot;memory&quot; (memory 0))(export &quot;render&quot; (func $render_multivalue_shim))(export &quot;__wbindgen_malloc&quot; (func $__wbindgen_malloc))(export &quot;__wbindgen_realloc&quot; (func $__wbindgen_realloc))(export &quot;__wbindgen_free&quot; (func $__wbindgen_free))...(func $render_multivalue_shim (param i32 i32) (result i32 i32) ...)(func $__wbindgen_malloc (param i32) (result i32) ...)(func $__wbindgen_realloc (param i32 i32 i32) (result i32) ...)(func $__wbindgen_free (param i32 i32) ...) 首先，模块export了它自身的memory内存段，wasm内存是模块可访问的线性地址空间，并且是模块可以读写的唯一内存区域。由于该模块无法直接访问host地址空间的任何其他区域内存，因此这段export的内存就是host与wasm模块交换数据的区域。 其次，模块export了我们用Rust实现的render函数，但是这里有个问题是，为什么在前面Rust实现的函数只有一个参数和一个返回值，而wasm对应的函数有两个参数和两个返回值？ 在Rust中，当编译为wasm时，字符串切片类型（&amp;str）和字符串（String）均表示为初地址和长度（以字节为单位）对的形式。因此，wasm版本的函数由于更底层，便直接采用了这种底层的初地址和长度对形式来表示参数和返回值。值得注意的是，这里的初地址表示的是export内存中的字节偏移量。 那么我们回头看之前的代码，由于Rust代码返回一个String，它是一个owned自有类型，因此render的调用者负责释放包含渲染字符串的返回内存值。 在.NET的host实现过程中，我们将逐一讨论其余的export项。 创建.NET工程我们使用.NET Core SDK来创建.NET Core工程，所以请确保系统已安装了3.0或更高版本的.NET Core SDK。 为工程创建一个新的目录： 12mkdir WasmtimeDemocd WasmtimeDemo 接下来，在目录中创建.NET Core命令行工程： 1dotnet new console 最后，添加Wasmtime NuGet包的依赖关系： 1dotnet add package wasmtime --version 0.8.0-preview2 现在，我们已做好使用Wasmtime的.NET API来加载并执行markdown模块的准备。 为wasm导入.NET代码为wasm导入.NET实现的函数，跟.NET中实现IHost接口一样简单，只需一个公有的[Instance]属性来表示和host绑定的wasm模块。 Import属性被用于标记函数和域，正如wasm模块中的import那样。 我们之前提到，模块需要从host环境中import两个函数：fd_write和random_get，所以接下来对这两个函数进行实现： 在工程目录中创建一个名为Host.cs的文件，并添加如下的代码： 1234567891011121314151617181920212223242526272829using System.Security.Cryptography;using Wasmtime;namespace WasmtimeDemo&#123; class Host : IHost &#123; // These are from the current WASI proposal. const int WASI_ERRNO_NOTSUP = 58; const int WASI_ERRNO_SUCCESS = 0; public Instance Instance &#123; get; set; &#125; [Import("fd_write", Module = "wasi_unstable")] public int WriteFile(int fd, int iovs, int iovs_len, int nwritten) &#123; return WASI_ERRNO_NOTSUP; &#125; [Import("random_get", Module = "wasi_unstable")] public int GetRandomBytes(int buf, int buf_len) &#123; _random.GetBytes(Instance.Externs.Memories[0].Span.Slice(buf, buf_len)); return WASI_ERRNO_SUCCESS; &#125; private RNGCryptoServiceProvider _random = new RNGCryptoServiceProvider(); &#125;&#125; fd_write实现仅仅只是简单地返回一个错误，表示不支持该操作。它可被模块用于将错误代码写入stderr中，而在我们的demo中则永远不会真正调用。 random_get的实现使用的是随机字节填充请求缓冲区的方式。它将代表整个模块export内存的Span切片，以便.NET的实现可以直接写入请求的缓冲区，而无需进行任何的中间复制操作。Rust标准库中HashMap的实现正是通过调用random_get函数来实现。 以上就是使用Wasmtime的API将.NET函数import到wasm模块的全部步骤。不过，在加载wasm模块并在.NET使用它们之前，我们需要讨论如何将字符串作为参数，将其从.NET的host传递到render函数中。 良好的宿主环境 基于模块化的export，我们知道它export了一块memory区域。从host的角度上来看，即使该模块与host本身共享相同的进程内存，也可以将wasm模块的export内存授权为对外部进程地址空间的权限。 如果你将数据随机写入外部地址空间，则会发生意想不到的后果，因为它很容易对其他程序的状态造成破坏并引起未定义的行为，例如程序崩溃或字节反转。那么主机应如何以安全的方式将数据传递到wasm模块中呢？ Rust程序在内部使用内存分配器来管理其内存，因此，为了使.NET成为wasm模块良好的宿主，在分配和释放wasm模块可访问的内存时，必须使用相同的内存分配器。 值得庆幸的是，Rust程序用来将自身导出为wasm模块的wasm-bindgen工具也为此export了两个函数：__wbindgen_malloc和__wbindgen_free。除了__wbindgen_free需要知道内存地址和之前分配的内存大小之外，这两个函数本质上和C语言的malloc和free函数一样。 考虑到这一点，让我们为C#编写这些export函数的一个简单的封装，以便我们可以轻松分配和释放wasm模块可访问的内存大小。因此，在工程目录中创建一个名为Allocator.cs的文件，并添加如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152using System;using System.Collections.Generic;using System.Linq;using System.Text;using Wasmtime.Externs;namespace WasmtimeDemo&#123; class Allocator &#123; public Allocator(ExternMemory memory, IReadOnlyList&lt;ExternFunction&gt; functions) &#123; _memory = memory ?? throw new ArgumentNullException(nameof(memory)); _malloc = functions .Where(f =&gt; f.Name == "__wbindgen_malloc") .SingleOrDefault() ?? throw new ArgumentException("Unable to resolve malloc function."); _free = functions .Where(f =&gt; f.Name == "__wbindgen_free") .SingleOrDefault() ?? throw new ArgumentException("Unable to resolve free function."); &#125; public int Allocate(int length) &#123; return (int)_malloc.Invoke(length); &#125; public (int Address, int Length) AllocateString(string str) &#123; var length = Encoding.UTF8.GetByteCount(str); int addr = Allocate(length); _memory.WriteString(addr, str); return (addr, length); &#125; public void Free(int address, int length) &#123; _free.Invoke(address, length); &#125; private ExternMemory _memory; private ExternFunction _malloc; private ExternFunction _free; &#125;&#125; 这段代码虽然看起来很复杂，但它所做的就是从模块中按名称查找所需的export函数，并将它们封装在易于使用的接口中。我们将使用该辅助Allocator类将输入字符串分配给export的render函数。 现在，我们准备开始渲染markdown。 渲染markdown在工程目录中打开Program.cs，并将其替换为以下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051using System;using System.Linq;using Wasmtime;namespace WasmtimeDemo&#123; class Program &#123; const string MarkdownSource = "# Hello, `.NET`! Welcome to **WebAssembly** with [Wasmtime](https://wasmtime.dev)!"; static void Main() &#123; using var engine = new Engine(); using var store = engine.CreateStore(); using var module = store.CreateModule("markdown.wasm"); using var instance = module.Instantiate(new Host()); var memory = instance.Externs.Memories.SingleOrDefault() ?? throw new InvalidOperationException("Module must export a memory."); var allocator = new Allocator(memory, instance.Externs.Functions); (var inputAddress, var inputLength) = allocator.AllocateString(MarkdownSource); try &#123; object[] results = (instance as dynamic).render(inputAddress, inputLength); var outputAddress = (int)results[0]; var outputLength = (int)results[1]; try &#123; Console.WriteLine(memory.ReadString(outputAddress, outputLength)); &#125; finally &#123; allocator.Free(outputAddress, outputLength); &#125; &#125; finally &#123; allocator.Free(inputAddress, inputLength); &#125; &#125; &#125;&#125; 让我们一步步地看看这段代码做了哪些工作： 创建Engine对象，该Engine类代表了Wasmtime运行时本身。运行时支持从.NET加载和执行wasm模块； 然后创建Store对象，这个类是存放所有wasm对象（例如模块及其实例）的地方。Engine中可以有多个Store，但它们的关联对象不能相互影响； 接下来，基于markdown.wasm文件创建Module对象。Module代表wasm模块本身的数据，例如它import和export的数据。一个模块可以具有一个或多个实例，实例化是wasm模块的运行时的表示形式。它将模块的wasm指令编译为当前CPU体系结构的指令，分配模块可访问的实际内存，以及绑定从主机import的函数； 使用之前实现的Host类来实例化模块，绑定作为import项的.NET函数； 查找由模块export的memory段； 创建一个分配器，然后为需要渲染的markdown内容分配一个字符串； 以输入字符串为参数，通过将实例转换为dynamic的方式调用render函数。这本是C#的一项特性，在运行时动态绑定函数，可以将其简单地视为搜索并调用export后的render函数的快捷方式； 通过从wasm模块export的内存中读取返回的字符串，输出渲染后的HTML； 最后，释放分配的输入字符串和Rust提供给我们的返回字符串的内存。 以上就是代码所实现的步骤，然后继续运行该代码。 运行代码 在运行程序之前，需要将markdown.wasm复制到工程目录中，因为它是我们实际运行程序的地方。可以在构建目录的target/wasm32-wasi/release位置中找到该markdown.wasm文件。 从上面的Program.cs源码中，我们看到该程序对一些markdown进行了硬编码的渲染： 1# Hello, `.NET`! Welcome to **WebAssembly** with [Wasmtime](https://wasmtime.dev)! 运行程序，将其渲染为HTM格式L： 1dotnet run 如果一切正常，应该会出现下面的结果： 1&lt;h1&gt;Hello, &lt;code&gt;.NET&lt;/code&gt;! Welcome to &lt;strong&gt;WebAssembly&lt;/strong&gt; with &lt;a href="https://wasmtime.dev"&gt;Wasmtime&lt;/a&gt;!&lt;/h1&gt; Wasmtime for .NET的下一步计划是什么？从这里例子中，我们可以看到，现在实现该demo还需大量的C#代码，不是吗？ 我们计划了从两个主要的功能点来简化代码的实现： 将Wasmtime的WASI实现开放给.NET和其他语言 在上面Host的实现中，必须手动去编写fd_write和random_get，但它们实际上是WASI中已有的函数。 Wasmtime本身包含了WASI的实现，只是目前无法通过.NET的API进行访问。 一旦.NET的API可以访问和配置Wasmtime的WASI版本实现，则.NET的host环境将无需提供自己的实现。 实现.NET的接口类型 前面提到，wasm接口类型可以使wasm更加自然地与托管编程语言进行集成。 一旦.NET的API实现了未来通过后的接口类型提案，便无需像前面那样去还要创建一个辅助功能的Allocator类。 到那时，使用诸如字符串等类型的函数可很容易办到，而不必在.NET中编写任何粘合代码。 所以希望将来该demo是这样的： 1234567891011121314151617181920212223using System;using Wasmtime;namespace WasmtimeDemo&#123; interface Markdown &#123; string Render(string input); &#125; class Program &#123; const string MarkdownSource = "# Hello, `.NET`! Welcome to **WebAssembly** with [Wasmtime](https://wasmtime.dev)!"; static void Main() &#123; using var markdown = Module.Load&lt;Markdown&gt;("markdown.wasm"); Console.WriteLine(markdown.Render(MarkdownSource)); &#125; &#125;&#125; 我们都认为这样看起来简洁多了！ 结束语这是在Web浏览器之外利用不同的编程环境（包括微软的.NET平台）使用wasm的兴奋之旅的开始，如果你是.NET开发者，希望您能加入我们的旅程！ 本文的.NET示例代码可以在Wasmtime示例代码库中找到。 (译者注：本文原地址为 https://hacks.mozilla.org/2019/12/using-webassembly-from-dotnet-with-wasmtime/ ，原作者为 Peter Huene)]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Rust</tag>
        <tag>WebAssembly</tag>
        <tag>Wasmtime</tag>
        <tag>.NET</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Midori博客系列翻译（6）——性能文化]]></title>
    <url>%2F2019%2F03%2F13%2Fmidori%2F6-performance-culture%2F</url>
    <content type="text"><![CDATA[在本文中，我将聊聊“性能文化”。性能是软件工程的关键支柱之一，并且很难做正确，有时甚至都难以识别，正如一位著名的法官曾经说过的那样，“我一眼就能看出来（I know it when I see it）”。我之前已详细地聊到了性能 和文化，但两者之间的交互才会变得更有趣。能够做好这一点的团队几乎从一开始就将性能贯穿于团队运作的各个方面，并且能够主动提供可以摧毁竞争对手的良好客户体验。 虽然没有千篇一律的简单方法来获得良好的性能文化，但是你依然可以遵循一些最佳实践来将必要条件的种子植入到团队中。因此，让我们一起出发吧！ 介绍 那么到底为什么要关注于性能呢？ 其中部分原因是由于我的背景。我曾经研究过系统、运行时、编译器……这些都是客户期望运行得足够快的软件。 在这样的项目中，与在事后进行弥补相比，从一开始时就整合目标、指标和团队的流程总是容易得多。我也曾参与过很多团队的工作，有些团队在这方面做得很棒，有些团队却做得非常糟糕，而很多团队则介于两者之间。一个普遍的事实是，造成这之间差异的因素始终是文化。 另外部分原因是，无论哪种软件，性能几乎总是比我们的客户所期望的要更差。这是一个简单的物理问题：在给定有限时间以及在大小速度和功能之间进行折衷的情况下，不可能在所有方面提高程序的运行速度。但我坚信，就平均而言，团队普遍花费较少的注意力来发展严谨的性能文化。我已经很多次听说过这样的言论——“性能不是我们的首要任务”，而后来却又痛苦地意识到它的重要性。没有性能，产品就不会成功。 另外部分原因是，对于DevDiv团队而言，由于我们专注于.Net的核心性能、ASP.Net的扩展性以及将性能驱动的功能集成到C#和库中，使Visual Studio变得更快等等，使得性能是我们所有人摆在首位的指标。这对我来说尤其重要，所以我一直在将我们的经历与我在Midori 中的经历进行比较（本文也受此很大的启发）。 诊断和治疗 如何判断团队性能文化是否走上正轨？ 好吧，如果存在下面一些迹象，则表明尚未达到目标： 回答“产品在我的关键性能指标上发挥如何”这个问题很难； 性能经常退化，团队成员要么不知道，要么不关心，要么发现太晚而难以行动； 责备是对性能问题（人员，基础设施或两者皆有）的最常见反应之一； 性能测试大幅度摇摆不定，无法得到确认，并且通常被大多数团队成员所忽略； 性能是一个或几个人应该关注的事情，而不是整个团队； 产品常常出现性能问题，并且需要仓促行动才能解决（和/或不能重现问题）。 这些听起来像是技术问题，但出乎意料之外的是，它们主要是人的问题。 对此的解决方法并不容易，特别是一旦当性能文化处于十分糟糕的时候，从一开始就不挖坑始终比之后从坑里爬出来要更容易。可是当你陷入困境时，首要的原则就是停止挖坑！文化的转型必须同时从最高层开始——管理层需要在性能的提升中发挥积极的作用，提出问题，寻找方法，严谨要求——以及从下层开始，工程师积极寻求对他们正在编写的代码的性能理解，对性能退化采取无情的零容忍态度，并进行自我批判和寻求主动改进的积极性。 本文将介绍一些建立这种文化的方法，此外还有一些我发现的有助于提高效率的最佳实践。很多事情看起来很明显，但请相信我，在实践中很难看到所有一切都协调一致的进行。但是，如果一旦这样的文化得以建立，那它将产生巨大的影响力。 对于OSS（开源）软件的简单说明——我是从商业软件开发的角度写下这篇文章，因此你会看到很多“管理层”这个词，不过这里的许多相同原则也同样适用于OSS。因此，如果你愿意，只要你看到“管理层”这个词，请在脑海中转化为“管理层或项目的提交者”。* 以文化开始，以文化结束 健康的性能文化的关键组成部分包括： 性能是团队日常交流和闲聊的一部分，每个人都扮演着其中一个角色； 管理层必须（真正地，而不是表面上地）关心于优良的性能，并了解获得它们需要什么； 工程师采用科学的，数据驱动的，刨根问底的方法来提升性能（测量，测量，还是测量！）； 有健壮的工程系统来追踪目标以及它过去和现在的性能，并阻止其发生退化。 我会花一点时间大体地谈论它们中的每一个。 对话，闲聊和沟通 整个团队需要保持对性能的追求。 在我见过的把事情搞砸的团队中，一个成员被指定为性能小伙/姑娘。这是不错的方法，它可以帮助团队进行扩展，当有人带头进行调查时也很有用，并也在团队中存在主张性能的声音。但这种方式不能以团队的其他成员为代价。 这可能会导致类似于过去Microsoft对待“测试”的原则问题：工程师通过外包代码的基本质量，并假设其他人（外包人员）会发现任何可能的问题，并养成了坏习惯。当存在中心化的性能独裁者时，也会有同样的风险存在：团队中的工程师不会编写性能测试，不会主动进行基准测试，不会对性能进行profile，不会询问有关产品当前所处竞争地位的问题，并且通常不会做任何一个工程师为建立健康性能文化而做的所有事情。 当整个团队都对性能着迷时，会发生神奇的事情。随着挑战和改进的消息在团队里有机地传播，走廊充满了兴奋的气氛。 “你有没有看到Martin的哈希表重平衡改变后，将进程占用空间减少了30%？”“Jared刚刚加入了一个允许堆叠分配数组功能，我本周末想在网络堆栈上使用它，你有兴趣加入吗？”即兴的白板交流，袖手旁观的想法，以小组的方式学习等等，看到这些真的是太棒了，对胜利的兴奋和渴望推动着团队前进，便自然且不依赖于一些重量级管理层的“驱使”。 我讨厌抱怨和防备，因此我的首要原则就是：“（团队里）没有笨蛋”，所以所有的批评都必须以最具建设性和尊重的方式提出来。然而，我发现在性能状况不佳的团队中往往出现过多的抱怨、防备和机智的不诚实，这就像笨蛋一样，对团队文化是有害的，因此必须积极将这种方式淘汰掉，它可以轻松地决定你发展正确性能文化的能力。我们需要在一些关键指标上做得更好这一点上是没有错的，特别是如果你对如何做到这一点上有一些好的想法！ 除了ad-hoc的交谈方式之外，当然还需要结构化的交流，我稍后会介绍一些技巧。但是，定期在一个房间内安排一组核心人群来讨论产品特定区域的过去，现在和未来的性能至关重要。尽管有机的讨论非常有用，但每个人都很忙碌，所以重要的是要安排时间作为继续推进的提醒。 管理层：更多的胡萝卜和更少的大棒 在每个具有糟糕性能文化的团队中，都是因为管理层出了问题。 当然，工程师可以而且必须有所作为，但如果顶层的管理者和中间层都没有深入参与，对必要时间进行预算，对工作和超级明星进行奖励，那么正确的文化就不会成功建立起来。单凭一名工程师不可能将这种文化注入到整个团队，而且如果整个工作都是与管理团队相抵触的话，那么肯定更不会成功。 看到一个不会欣赏性能文化的管理者是痛苦的。他们经常会对此感到意外，并且不会意识到为什么会是这样，或者更糟糕地认为这就是工程的工作原理（“我们无法提前料到性能的重要性！”）。客户会抱怨产品在关键领域没有达到预期的效果，并且在意识到预防措施为时已晚时，具有糟糕性能文化的团队管理者便开始抱怨。你猜怎么着？这种抱怨的文化就像野火一样传播，使得工程师们也开始这样做，而真正的责任追究制却被抛之脑后。抱怨不能解决任何问题，是笨蛋才所做的事情。 注意我说管理层必须“深入参与”的意思时，不能只是表面的参与而已。当然，绿色、红色加上趋势线的图表可能需要出现在周围，并且定期的评审也很重要，我想你可以说这些都是尖头发的经理所从事的事情（相信我，这确实是有帮助的）。然而，经理必须比这些更深入，主动并定期审查整个产品的性能状况，以及其他基本质量指标和功能的进展。这是团队工作方式的核心原则，并且必须这样对待。经理必须思考竞争的格局，并向团队询问引发他们思考，且优秀而富有洞察力的问题。 性能不是免费的，它有时通过迫使团队放慢速度为代价，将精力花在除了完成功能之外的事情上，因此需要进行一些合理的权衡。在性能上花费多少精力真的取决于场景，而经理需要指导团队花费适当比例的时间。那些认为会免费获得性能的人通常在稍后不凑巧的时间点上（例如，在发布产品的最后阶段，以及在生产中尝试从1000扩大到100000个客户规模时等），最终会花费2-5倍的精力。 我的一位导师曾经说过，“你从你的团队中获得你的奖励”，对于性能和围绕它们的工程系统来说尤其如此。考虑以下两种经理： 经理A为性能文化提出口头上的鼓励。然而，她为每个迭代周期提出了固定数量的功能计划，比如，“我们必须粉碎竞争对手Z并且必须实现相同的功能！”，却没有中途休息的时间。她花了很多时间参加团队会议，赞扬新功能和演示大量的demo，甚至为工程师颁发“最具突破性功能”的奖励。结果，她的团队以一个令人印象深刻的剪辑实现出功能，并每次都向董事会演示新出炉的demo，为销售团队提供大量资源以获取新的潜在客户。但没有为性能提供门路，工程师们通常也懒得去思考性能。 经理B采取更加平衡的方法。她认为，鉴于竞争的格局和通过杰出的演示给客户和董事会成员留下深刻印象的必要性，新功能是需要不断涌现的。但她也担心在性能，可靠性和质量等方面在她所希望坚持的领域积累太多债务。因此，她会故意放慢追求新功能的步伐，并尽可能地推动团队在这些方面上努力。例如，她需要良好的工程系统以及内置性能遥测的新功能，这会让董事会成员和产品经理处于困境，而这绝对是不受欢迎和有难度的。除了颁发“最具突破性功能”奖项之外，她还要展示了性能的进展图表，并为提供最具影响力性能改进的工程师颁发了“性能忍者”奖。请注意，工程系统的改进也是符合“性能忍者”奖颁发条件的！ 你认为哪位经理会按时交付给客户所喜爱的优质产品呢？我会投给经理B。有时候为了加快速度而必须放慢脚步。 微软最近正在经历两个与这一点相关的有趣转变：一方面，消除了以“测试”作为前面提到的原则；另一方面，又重新关注于工程系统。这是一个坎坷的旅程，但令人惊讶的是，克服困难的最大障碍之一不是工程师个人，而是管理者！旧模型中的“开发经理”习惯专注于功能，功能，还是功能，并将大部分工程系统任务交给承包商，以及将大多数软件质量工作都交给了测试人员。结果，他们没有准备好承认和奖励那些对建立卓越性能文化至关重要的工作。结果如何？你猜对了：完全缺乏性能文化，但更微妙的是，最终还是出现了“领导漏洞”。直到最近，几乎没有高级工程师致力于任务关键的工程系统，并使整个团队更高效和有能力。谁想通过分配给承包商的那些繁琐的工作来创造自己的事业，而不能得到管理层的重视？再一次地，你获得了应得的回报。 有一个关于项目早期原型的“22条军规”，它是这么说的：如果你不知道项目是否能够存活下来，那么不要在性能上花费任何时间。如果你正在实现最低可行产品（MVP），并且处于一个非常烧钱的创业公司中，那这种做法是可以理解的。但我强烈反对这一点，因为架构真的很重要，一开始就做出的一些不当的架构决策可能为整个低质量代码的摩天大楼奠定了基础。因此，最好将性能作为可行性研究和早期探索的一部分。 最后，作为大型团队的经理，为了统一上述所有内容，我认为定期，比如每隔一两个迭代周期，召开会议来审核管理团队的性能进展是非常重要的。除此之外，还有更细粒度的工程师，leader和架构师级别的碰头要不断的进行。这种审查有一点“坚持”的味道，但它更多的是关于庆祝团队的自我驱动成就，并将其保持在管理层的雷达上。这些审查应该由实验室所驱动，而手动生成的数字是不合规的。 这为我带来了…… 流程和基础设施 “流程和基础设施”——多么无聊的事情！ 良好的基础设施是必须的。 缺乏上述文化特征的团队甚至不会停下来对基础设施进行投资，所以他们只会处在一个令人恼怒并缺乏严谨的环境中，而良好的流程能确保有效使用此基础设施。下面是我在本书中的最低要求： 所有的代码提交必须先通过一组门控性能测试； 任何惊险通过测试并且性能退化的提交都将毫无疑问地被撤回，我称其为零容忍规则； 连续性能遥测通过实验室，飞行和在线环境中上报； 这意味着性能测试和基础架构具有一些重要特征： 它们不会让人觉得吵闹； 能测量“正确”的东西； 可以在“合理”的时间内运行完成。 有这么一句话：“如果它不是自动化的，那么对我来说它已经死了”。 这凸显了良好基础设施的重要性，并避免了可怕的“它明明在我的机器上运行的很好”的情况出现，我可以保证每个人都遇到过：在某个谁也不知道环境配置的随机机器上运行通过测试，然后便宣称在某个基准测试上获得了成功，而在一段时间后发现并没有这种预期的结果。那么为什么会遇到这种情况？ 这里存在无数种可能性：也许是一个嘈杂进程的干扰，比如AntiVirus或搜索索引进程，或操作系统的更新程序，或者是开发者不小心把音乐留在他们的多媒体播放器的后台进行播放，也可能是BIOS没有正确调整到禁用动态时钟缩放，或由于在将数字复制并粘贴到电子表格时出现了数据输入错误，更或者是两个进行比较的基准数字来自两个根本无法比较的机器配置上。我见证过以上所有这些都在现实世界中发生过。 在任何有人参与的活动中，都会发生错误。现在这些天，我真的拒绝查看或信任任何不是来自实验室的数字，而解决方案是实现所有一切的自动化，并将精力集中在尽可能使自动化基础设施变得更好上面，通过部署最优秀的人才在这上面，为团队的其他成员打造坚实的基础。鼓励团队中的每个人修复“破损的窗户”，并采取积极主动的方法来改善基础设施，以及衷心地奖励这些做法。这样做可能会稍微前进的慢一点，但请相信我，这样做是值得的。 测试环 当我说“所有代码提交都必须通过一系列性能测试”时，我是很认真的，然后我又继续说到代码提交可能会“侥幸通过”所述测试。那么为什么会这样？ 实际的情况是，通常不可能在提交之前运行所有测试并找到所有问题，至少在合理的时间内不会达到。一个好的性能工程系统应该要在快速代码流的生产力与回归预防的保证之间做出平衡。 一种合适的方法是将测试组织成所谓的“环（ring）”： 一个内环，包含团队中所有开发者在每次提交之前要测量的测试； 一个内环，包含特定子团队的开发者在每次提交之前要测量的测试； 一个内环，包含开发者在每次提交之前自行决定要运行的测试； 除此之外的任意数量的连续环，这包括： 分支之间的每个代码流门控测试； 每晚（nightly）每周（weekly）或基于时间/资源的限制等条件的，提交后（post-commit）的测试； 发布前（pre-release）的验证； 发布后（post-release）的遥测和监测。 正如你所看到的，在实践中如何构建它有一定的灵活性。我多么希望我能谎称这是一门科学，但这确实是一门需要智慧地折衷许多因素的艺术。这是一个不断争论的焦点，也是管理团队应该积极参与辩论的话题。 一个小型团队可以在整个团队中建立一套标准的基准，而一个更大的团队可能需要沿着分支分割内环测试。无论规模大小，我们都希望主干/主分支能够为整个团队强制执行最重要的性能指标，确保没有任何损害核心场景的代码进入。 在某些情况下，我们可能会将某些提交前（pre-commit）测试留给开发者来自行决定（注意，这并不意味着运行提交前测试完全是可选的，而只是有一组是特定于此的），例如，如果测试覆盖了较少使用的组件并且我们知道每夜测试会捕获任何提交后回归。一般来说，当你拥有强大的性能文化时，有时候可以信任这种判断。信任但要验证。 让我们来看几个具体的例子。性能测试的范围通常从微观遍布宏观，因此从精确定位回归来源的角度看，他们通常也从更容易遍布到更难上 （微测试只测量一种，所以波动往往更容易理解，而宏测试则需测量整个系统，通过波动找到目标往往要费点力气）。网络服务器团队可能在最里面的预提交测试套件中，包括一系列的微测试和宏测试，比如说：每个请求分配的字节数（微），请求响应时间（微）……可能还有其他六个微到中间规模的基准测试……以及TechEmpower（宏）。感谢实验室的资源，测试并行以及强大的GitHub webhooks，使得这些测试都在15分钟内完成，并能很好地集成到你的pull request和代码审查流程中，这一点是相当不错的。但这显然不能完美的覆盖，也许每天晚上，TechEmpower需要运行4个小时，以便能在更长的时间内测量性能并识别泄漏，开发者可能通过提交前测试，但却在这个更长的测试中失败。因此，团队允许按需运行此测试，所以好的开发者可以避免丢脸。但即使错误发生了，却再也不是一种抱怨或迫害的文化，是怎样那就是怎样。 这导致我回退到了零容忍规则上。 除非出现特殊情况，否则出现回归则应立即撤销。在我看到这个成功的团队中，这一点是毫无疑问的，也没有任何借口，一旦你放松这种立场，文化就会开始崩溃。无论团队的最佳意图是什么，如果性能回归都堆积在一起，那么你最终再也回不到最初的状态。对于回归的提交应该撤消，开发者需确定根本原因，对其进行补救。理想情况下，如果合适的话，编写一个新的测试，然后再次通过所有测试环以提交签入代码，并在这次确保良好的性能。 测量，指标和统计 体面的工程师靠直觉，优秀的工程师靠测量，伟大的工程师两种都做到。 那到底测量什么？ 我将度量分为两个不同的类别： 消耗指标：它们直接测量运行测试所消耗的资源； 观察指标：它们使用系统“外部”的度量标准来衡量运行测试的结果。 一个消耗指标的例子是硬件性能计数器，比如说完成指令（instruction retired），未命中的数据缓存，未命中的指令缓存，未命中的TLB和/或上下文切换等。软件性能计数器也是很好的例子，例如I/O数量，分配（和收集）的内存，中断和/或系统调用的数量等。观察度量的示例包括运行时间和来自云提供商的运行测试成本开销。处于多种原因，两者显然都很重要。 逐字观察一整个团队的测量时间本身就非常耗费精力，虽然它可以很好地衡量最终用户将会看到什么，并因此进行良好的高级测试， 但它可以为你提供的洞察力严重缺乏，如果没有对变化的可见性，那么可能是无用的。 对于试图理解为什么会发生变化的工程师而言，消耗指标显然更有帮助。在我们上面的Web服务器团队的例子中，假设请求响应时间增加了30%，所有测试报告告诉我们的都是时间。开发者确实可以尝试在本地重现场景，并手动缩小原因范围，但是由于实验室与本地硬件的差异，这样做可能会很繁琐并耗费时间，而且可能并不完美。相反，如果是完成指令和分配内存的报告与时间回归报告一起呈现呢？从它们那里，可以很容易地看出，每个请求突然分配了256KB的内存，这在之前是没有出现的。结合考虑最近的提交，这可以使工程师在增加提交堆积在最顶层并进一步使问题难以理解之前，很容易及时地快速查明并找到罪魁祸首。而这就好像printf调试所提供的一样。 说到printf调试，遥测对于长时间运行的测试至关重要。即使是低技术含量的方法，例如每隔一段时间（例如每15秒）打印一组当前的度量值，也可以简单地通过检查数据库或日志文件来追踪到陷入困境的位置。想象一下，试图找出4小时网络服务器测试在3个半小时左右的轨道上脱轨的地方，如果没有连续的遥测，这可能真是令人头疼的一件事！当然，在这上面走的更远也是一个好主意，产品应具有内置的方式在收集此遥测，并将其与关键指标相关联。 这方面，StatsD是一个很棒的选择。 最后，尽可能科学地衡量这些指标非常重要。这包括跟踪标准差，变异系数（CV） 和几何平均值，并使用这些参数来确保两次测试结果不会相差太远。（提示：大幅度改变CV的提交应该被阻止，就像那些大幅度改变核心指标本身一样）。对你的团队进行统计数据研究也是一个不错主意！ 目标和基线 如果你缺乏目标和基线，那么上述的方法所产生的作用很小。对于每个基准/指标对，我建议你在基础架构和流程中识别四个不同的概念： 当前：当前性能（可以跨越多个指标）； 基线：产品必须保持高于/低于的阈值，否则测试失败； 迭代目标：在当前迭代周期结束之前团队必须到达的位置； 交付目标：团队必须到达此位置，才能发布有竞争力的功能/方案。 对于一个越高越好的指标（如吞吐量）来讲，那么通常情况下的情况是，交付目标 &gt;= 迭代目标 &gt;= 当前 &gt;= 基线。随着输赢比较的不断发生，应该不断进行调整。 例如，“基线棘轮效应”的过程应该在改进的过程中被锁定。一种合理的方法是将基线自动调整到当前性能的某个百分比内，理想情况是基于标准偏差和/或变异系数的。另一种方法是要求开发者手动执行此操作，以便所有棘轮操作都是有意且深思熟虑后做出的决定。有趣的是，你可能会发现在另一个方向上棘轮也是有帮助的；也就是说，阻止那些显著提高性能却没有提高基线的提交。这便迫使工程师停下来思考性能变化是否是有意的，即使是好的变化也应如此！这也被称为“确认杀戮”。 从一个迭代周期到下一个迭代周期，目标保持稳定当然是很常见的；所有数字都无法永远处于增长的状态，但是这个系统也有助于确保团队不会退步到以前所取得的结果上。 我发现组织主题背后的迭代目标很有用。制定名为“服务器性能”或者“摆脱过多的分配”的这个迭代周期，能让团队有一种凝聚力和共同目标，并混合添加一点其他有趣的东西。作为经理，我们经常忘记有趣的重要性。事实证明，性能可以是所有人的最大乐趣，并且它也是非常容易测量，这一点上工程师都很喜欢。而且，对我自己来说，这是一个可以暂时放下工作和休息的时刻！这甚至可以作为一整个团队学习的时间，以尝试一些有趣的新算法技术，比如说布隆过滤器。 并非每项性能测试都需要这种严格程度，但任何足够重要的测试在自动运行提交前肯定都需要它，也许那些每天或每月运行的测试也会如此。但管理所有这些目标和基线，以及当它们太多时，可能会变得非常麻烦。这是会成为一个真正的风险，特别是如果你要跟踪每个基准测试的多个指标。 这就是“关键绩效指标”（KPI）的理念变得非常重要的原因。这些性能指标非常重要，足以使得管理层跟踪整个团队在任何给定时间内整体产品的健康度。在我过去构建操作系统及其组件的团队中，这些指标包括进程启动时间，Web服务器吞吐量，浏览器在标准业界基准测试上的性能以及实时音频/视频客户端中丢帧数等，这包括多个指标以及上述统计指标。这些当然是包含在定期运行的提交前和提交后的测试套件中，但将它们放在同一个地方并对目标进行跟踪，是一个非常聚焦的工作。 总结 这篇文章只是简单介绍了如何进行良好的性能工程，但我希望你能理解到一件事：在性能做到出色就需要一个良好的性能文化。 这种文化需要贯穿整个组织，从管理层到工程师，以及介于两者之间的每个人。它需要透明，尊重，积极，数据驱动，自我批评和勃勃雄心。伟大的基础设施和支持流程也是必须的，管理层需要能对这些有所欣赏并进行奖励，就像他们对待功能一样（并需要经常做的更好）。只有这样，自增长的飞轮才会开始运转。 设定目标，定期沟通，痴迷地追踪目标以及面向客户的指标也是至关重要的。 要达到我在本文中所写的所有内容并不容易。老实说，记得在这些领域放慢速度并坚持这些原则是很难的一件事情，而忽悠自己尽快完成功能并把关于性能的担心留到以后却很容易。好吧，我很遗憾地告诉你，有时它就是这样的。你必须依靠你的直觉和勇气，但是，根据我的经验，与功能相比，我们往往倾向于低估性能。 如果你是一名经理，你的团队会感谢你灌输这样的文化，并且将以按计划交付性能更佳的软件作为回报。如果你是一名工程师，并处于一个痴迷于客户性能的团队中，我保证你处于仓促之中的时间会更少，而处于积极主动状态的时间更多，以及获得更多快乐的时间。同时，我很想知道你的想法以及你自己建立性能文化的经历。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Midori</tag>
        <tag>翻译</tag>
        <tag>性能</tag>
        <tag>软件工程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Midori博客系列翻译（5）——错误模型]]></title>
    <url>%2F2019%2F03%2F09%2Fmidori%2F5-the-error-model%2F</url>
    <content type="text"><![CDATA[Midori是由基于C#，通过AOT编译的且类型安全的语言编写而成的操作系统。除了其微内核部分之外，整个系统都由该语言而成，包括驱动程序、域内核和所有的用户态代码。我在前面的文章中已经提及该语言设计的一些方面，现在是时候正面介绍的时候了。整个语言需要巨大的空间来覆盖，也需要一系列的文章来分析。那从什么地方开始呢？错误模型。传递和处理错误的方式是任何一门语言的基础，尤其是用于编写可靠操作系统的语言。像我们在Midori上所做的许多其他事情一样，需要几年的几次迭代的“整个系统（wholesystem）”方法，在错误模型上也是必要的。然而，我经常听到以前团队成员们说，这是他们关于Midori最怀念的地方，而对我来说也是如此。因此，不用多说了，让我们现在开始吧。 介绍 错误模型试图回答的基本问题是：“错误”是如何传递给程序员和系统用户的。很简单，不是吗？至少它看起来是这样的。 回答这个问题的最大挑战之一是，定义错误究竟是什么。大多数语言将程序bug（缺陷）和可恢复的错误归为同一类，并使用相同的工具来处理它们，使得null指针的解引用或数组越界访问，与网络连接问题或解析错误的处理方式相同。这样的一致性乍一眼看起来似乎很不错，但它有根深蒂固的问题，特别是这种方式具有误导性并经常导致代码的不可靠。 我们的整体解决方案是提供双管齐下的错误模型。一方面，对于编程bug来讲，语言有快速失败机制，我们称之为Abandonment（放弃），另一方面，对于可恢复的错误，语言有静态检查性异常机制。这两者在编程模型和它们背后的机制方面都大相径庭，Abandonment意味着无条件地在瞬间终止整个进程，因此不再运行任何用户代码（还记得么，一个典型的Midori程序由许多小型轻量级的进程组成），而异常当然有助于程序的恢复，同时它也有深层次的类型支持以帮助检查和验证。 这段旅程漫长而曲折，为了便于讲述，我将这篇文章分为六个主要部分： 野心和学习 Bug不是可恢复的错误！ 可靠性，容错和隔离 Bug：Abandonment，断言和合约 可恢复错误：类型导向的异常 回顾与总结 事后看来，某些结果似乎很明显，特别是对于现代系统语言，如Go和Rust来说，但另外一些结果也出乎我们的意料。无论如何我都会尽力讲述这一切，并且会在此过程中提供充足的背景故事。我们尝试了许多了不起作用的东西，因此我觉得这些尝试比最终已知结果时更加有趣。 雄心和学习 让我们首先从检视我们的架构原则和要求，以及从现有的系统中学习开始。 原则 在开始这段旅程时，我们提出了，对于一个错误模型来讲的其优异体现的几个要求： 可用性：开发者面对错误时必须很容易做出“正确”的事情，几乎就像下意识一样。一位朋友和同事很准确地将其称为“成功之坑（The Pit of Success）”。为了写出符合习惯的代码，模型不应该施加过多的限制，并且在理想情况下，对于目标受众来说，它应该在认知上是熟悉的。 可靠性：错误模型是整个系统可靠性的基础，毕竟，我们正在构建的是一个操作系统，因此可靠性至关重要，你甚至可能会指责我们痴迷于在此方面追求到极致。我们对编程模型开发的大量指导原则就是“通过构造来纠正错误”。 高性能：在正常情况，系统需要高效运行，这意味着成功路径的开销要尽可能地接近于零，并且失败路径的任何增加的开销必须完全是“按使用付费（pay-for-play）”。与许多愿意为失败路径接受过度开销的现代系统不同，我们有几个性能关键的组件，错误的过度开销对于它们来说是不可接受的，因此错误处理也必须要足够高效。 并发：我们的整个系统是分布式且高度并发，所以这会引起在其他错误模型中通常也会遇到的问题，因此这部分需成为我们工作的最前沿和重心。 可诊断：无论是交互式的还是事后进行的调试，都需要高效且简单。 可组合的：错误模型是编程语言的核心功能，位于开发者代码描述的中心，因此，错误模型必须提供常见的正交性和与系统其他功能的可组合性，与单独编写的组件的集成也必须是自然、可靠和可预测的。 这是一个勇敢的要求，但我确实认为我们最终在所有方面上取得了成功。 学习 现有的错误模型并不能满足我们的上述要求，至少不完全满足，某些系统在一个维度上做得很好，但在另一个维度上表现不佳。例如，错误码返回的方式具有良好的可靠性，但许多程序员发现容易错误地使用它们，进而很容易出错，比如说忘记检查某些返回码，这显然违反了“成功之坑”的要求。 鉴于对可靠性极高的追求，我们对大多数模型并不满意这一点上并不令人惊讶。 如果你像使用脚本语言那样，对易用性的优化胜过可靠性，那么得到的结论将会非常不同。而像Java和C#这样的语言很难再优化，是因为它们处于不同使用场景的十字路口上：有时用于系统，有时又用于应用程序，但总体而言，它们的错误模型非常不适合我们的要求。 最后要提醒的是，本篇文章在时间轴上始于2000年代中期，在那之后，Go、Rust和Swift语言在错误模型上做了一些很不错的工作，但在当时，却没有这样的语言可供我们选择。 错误码 错误码可以说是最简单的错误模型。该想法非常基础，甚至不需要语言或运行时的支持，只需要函数返回一个值，这个值通常是一个整数，表示执行成功或失败： int foo() { // &lt;在这里尝试完成某项任务&gt; if (failed) { return 1; } return 0; } 以上是典型的模式，返回“0”表示成功，非零则表示失败，而调用者必须对其进行检查： int err = foo(); if (err) { // 发生错误！需对其进行处理 } 大多数系统提供表示错误码的常量集合，而不仅仅是幻数（magic number），你可以使用或不使用相关函数来获取最近一次错误发生的额外信息（例如标准C语言中的errno和Win32中的GetLastError）。返回码在编程语言中并不特别，它从本质上讲仅仅只是一个返回值而已。 C语言长期使用错误码的方式，因此，大多数基于C的生态系统也都如此。使用返回码规则编写的低层系统代码比任何其他类型的都要多，Linux是这么做的，无数任务关键和实时系统也是如此。因此可以说，它有令人印象深刻的历史记录！ 在Windows中，HRESULT与错误码是等效的。HRESULT仅仅是一个整数的“句柄”，在winerror.h中有一堆常量和宏，如S_OK，E_FAULT和SUCCEEDED()等，用于创建和检查这些返回码。Windows中最重要的代码是使用返回码规则编写，例如在内核中是没有异常的，至少不是故意这么做的。 在手动管理内存的环境中，出错时释放内存是非常困难的一件事，而返回码可以使这种情况（更容易）被容忍。C++通过使用RAII的方式来自动管理内存，但除非你是C++模型（不是C语言那部分）的彻底贯彻者（事实上相当多的系统程序员并非如此），否则并没有好的方法在你的C程序中增量式地使用RAII。 再后来，Go选择了错误码方式，虽然Go的方法与C类似，但它更现代化，并且具有更好的语法和库支持。 许多函数式语言使用monad来封装返回码，并命名为Option&lt;T&gt;、Maybe&lt;T&gt;或Error&lt;T&gt;，使得它们与数据流编程和模式匹配相结合时感觉更自然，特别是与C相比，这种方法消除了我们即将讨论的几个返回码的主要缺点。Rust已经在很大程度上采用了这个模型，它为系统程序员提供了一些令人兴奋的特性。 虽然它很简单，返回码也确实存在一些缺陷，总的说来包括以下几点： 性能可能会受到影响； 编程模型的可用性会变差； 最重要的一点是，可能会意外地忘记对错误进行检查。 让我们依次用上面提及的语言中的例子来讨论每一个缺点。 性能 错误码未满足所谓“正常情况下零开销，非正常情况下才付费（zero overhead for common cases， pay for play for uncommon cases）”的要求： 对调用约定会会造成影响。函数现在需要返回两个值（对于非void函数来说）：实际的返回值和可能的错误码，从而消耗掉更多寄存器和/或栈空间，导致调用效率降低。当然，内联化调用子集可以弥补这种开销。 在被调用点可能出现失败的任何地方需要注入分支。我将其称之为“花生酱（peanut butter）”开销，因为检查像花生酱一样被“涂抹”在代码中的各个地方，使得难以直接衡量其影响。在Midori中，我们能够通过试验和测量并确认这种影响——是的，这里的开销是不可忽略的。还有一个次要的影响是，因为函数包含更多的分支，所以更有可能混淆优化器。 这样的事实对某些人来说可能会吃惊，因为每个人毫无疑问都听说过“异常处理很耗时”的说法。事实证明，异常处理并不低效，当正确地执行时，代码会从热点路径上剔除错误处理的代码和数据，与上面提到的返回码开销相比，这种情况增加了I-cache和TLB的性能。 许多高性能系统都是使用返回码构建的，所以你可能会认为我在挑剔，正如我们所做的许多其他事情一样，一种简单的批评方式是我们采取了极端的方法，但事实是性能变得更糟糕。 忘记对它们进行检查 忘记检查返回码的情况是很容易发生的。比如说，考虑如下函数： int foo() { ... } 在调用点上，如果现在我们悄悄地忽略掉返回码，然后继续执行，会出现什么情况呢？ foo(); // 继续执行，但foo可能执行失败了！ 此时，你已经掩盖了程序中可能存在的严重错误，这很容易成为错误码最棘手和最具破坏性的问题。正如我稍后将要介绍的那样，选项类型（option）有助于在函数式语言中解决这个问题，但是在基于C的语言，甚至是Go的现代语法中，这是一个真实存在的问题。 这个问题不仅仅是在理论上存在，实际上我遇到了无数忽略返回码导致的错误，我相信你也遇到过。正是在这个错误模型的开发中，我的团队遇到了一些令人大开眼界的问题。例如，当我们将微软的语音服务器移植到Midori时，我们发现80%的繁体中文（zh-tw）请求都失败了，但开发者并不会立即看到失败并对其进行处理，相反地，客户端会得到莫名其妙的回应。起初，我们认为这是Miodri的问题，但后来我们在原始代码中发现了一个悄悄忽略掉的HRESULT。一旦我们把它移植到Midori上，这个bug就立刻出现在我们的眼帘，被找到并在移植后立即得到了修复。毫无疑问地，这样的经验告诉了我们对错误码的上述看法。 令我惊讶的是，Go将未使用的import当成错误对待，但却错过了这个更为关键性的错误，而它们仅仅一步之遥！ 没错，你可以增加静态分析检查器，或者像大多数商业C++编译器那样增加“未使用的返回值”等警告方式。 但是，一旦你错过了将其添加到语言核心并作为一项要求的机会，开发者处于对烦人的分析和警告的抱怨，这些技术都不会起到关键的作用。 不管值不值得，在我们的语言中忘记使用返回值会造成编译时错误，因此你必须显式地忽略它们。在早先时候，我们用API实现这个功能，但最终将其设计成语言的语法部分，其功能相当于&gt;/dev/null： ignore foo(); 虽然我们未选择使用错误码进行错误处理，但无法意外地忽略返回值对于系统的整体可靠性来讲非常重要。试想你多少次在调试一个问题时，才发现其根本原因是忘记使用返回值，更有甚者因为此问题造成了安全漏洞。当然，因为程序员依然可以做坏事，所以让他们使用ignore并不是完全防弹的方法，但它至少是显式的和可审计的。 编程模型的可用性 在具有错误码方式的基于C的语言中，如果在任何的函数调用位置进行检查，那么会导致大量手动的if语句的检查。尤其是如果大量函数调用失败是很常见的情况时，这可能会特别繁琐，因为在C语言的程序中，分配失败也需要通过返回码来交互。另外，多值返回也是一件很笨拙的事情。 警告：这样的抱怨其实是主观的，在许多方面，返回码的可用性实际上是优雅的。你可以重用非常简单的原语——整型，return和if分支，并在无数其他情况下使用。在我看来，错误也是编程的足够重要的一个方面，语言应该需要在这方面对你有所帮助。 Go有很好的语法快捷方式，能够稍微更愉快地对标准的返回码进行检查： if err := foo(); err != nil { // 处理错误 } 注意，我们在一行中调用了foo并在检查错误是否为非nil，这种方式相当简约。 然而，可用性的问题并不止于此。 通常，对于给定函数中的许多错误应该共享一些恢复或补救的逻辑代码，许多C程序员使用标签和goto语句来构建这样的代码，比如说： int error; // ... error = step1(); if (error) { goto Error; } // ... error = step2(); if (error) { goto Error; } // ... // 函数正常退出 return 0; // ... Error: // 错误相关的处理 return error; 不用说，这是只有妈妈才会爱的代码。 在D、C#和Java等语言中，可使用finally块对这种“在作用域退出之前”的模式进行更直接地编码，同样地，即使没有完全采用RAII和异常的方式，微软也对C++提供了专有扩展__finally。D提供scope，Go提供了defer，所有这些都有助于彻底消除goto Error的模式。 接下来，想象一下函数是如何返回真实的值和可能的错误码的？由于我们已经破坏了返回槽，所以有两种明显的可能做法： 可以将返回槽用于两个值中的一个（通常是错误码），而另一个槽，比如指针参数的形式，用于两者中的另一个（通常是实际值），这也是C中的常用做法； 可以返回一个同时在结构中具有两者的数据结构。在后文中我们将会看到，这种做法在函数式语言中相当常见，但是对于C或Go语言，由于缺少参数多态，会丢失返回值的类型信息，所以这种方式不太常看到。当然由于C++添加模板，因此原则上它也可以做到，但另一方面C++也同时增加了异常机制，所以返回码在生态系统上是匮乏的。 为了支持上面的性能要求，想象一下这两种方法对程序生成的汇编代码有何影响。 从“侧面”返回值 第一种方法在C中的例子如下所示： int foo(int* out) { // &lt;在这里尝试操作&gt; if (failed) { return 1; } *out = 42; return 0; } 真正的返回值必须“在侧面”（在本例中通过指针参数）返回，使得调用变得十分笨拙： int value; int ret = foo(&amp;value); if (ret) { // 出现错误，对其进行处理 } else { // 使用返回值... } 除了变得笨拙之外，这种模式还会扰乱编译器的定义赋值分析，削弱编译器对使用未初始化值等情况发出良好警告的能力。 归功于多值返回，Go还可以通过更好的语法来解决这个问题： func foo() (int, error) { if failed { return 0, errors.New(&quot;Bad things happened&quot;) } return 42, nil } 这使得调用点变得更加整洁，结合先前提到的单行if检查错误（一个微小的改变，因为乍一看返回的value不在作用域内）的特性，它确实成为更好的处理方式： if value, err := foo(); err != nil { // 发生错误并处理它 } else { // 使用值 ... } 注意这也有助于提醒你对错误进行检查。然而，它也不是完全没有问题，因为函数可以仅仅返回错误码，此时忘记对其进行检查就像在C中一样的容易。 正如我上面提到的，有些人会在可用性上反驳我，我想对于Go的设计师来说，更是如此。因为Go使用错误码的一个巨大吸引力是，这是当今对于过于复杂的语言的一种反叛，我们已经失去了很多C语言的优雅特性——通常情况下，你可以查看任何一行C语言代码并猜测它编译后的机器代码。我不反对这种观点，事实上，我喜欢Go的模型胜过非检查性异常或Java中的检查性异常的化身，并且即使是在我最近写这篇文章的时候，也写了很多Go代码。我看着Go的简单性并问自己，我们是否在所有的try和requires等你将很快会看到的内容上的走得太远？我不确定。Go的错误模型往往是该语言最具分裂性的方面之一，这很大程度上是因为你不能像大多数语言那样草率地对待错误，但程序员确实喜欢在Midori中编写代码。最后，很难对它们进行比较，但我确信两者都可以用来编写可靠的代码。 从数据结构中返回 函数语言通过将值或错误的可能性打包到单个数据结构的方式解决许多可用性上挑战，因为如果你想对调用点上的返回值做任何有意义的事情，就不得不从返回值中挑出错误。这要归功于数据流风格的编程，使得很容易避免遗忘检查错误这种杀手级的问题。 有关此方法的现代语言示例，请查看Scala种的Option类型。但不幸消息是，有些语言，例如ML系列中的语言，甚至是Scala（由于其JVM的血统），将这种优雅的模型与非检查性异常方法混合在一起，从而玷污了monad数据结构方法的优雅性。 Haskell做的事情更酷，在仍然使用错误值和局部控制流的前提下，提供了类似异常处理的错觉： C++程序员之间就异常还是错误返回码是正确的方式上存在长期的争议。Niklas Wirth认为异常是goto方式的转世，因此在他的语言中消除了这种方式，Haskell以更圆滑的方式解决了这个问题：函数返回错误码，但错误码的处理不会让代码变丑。 这里的技巧是使用monad而不是控制流，以支持所有熟悉的throw和catch模式。 虽然Rust也使用错误码方式，但它也采用函数式错误类型的风格。例如，假设我们在Go中编写了一个名为bar的函数，它调用foo，并只是在调用出错时才将错误传播给调用者： func bar() error { if value, err := foo(); err != nil { return err } else { // 使用值... } } 而Rust中的速记版本就不那么简洁。虽然这种外来的模式匹配语法（一个关注点而不是问题的死结）可能会让C程序员发昏，然而，任何对函数编程感到满意的人可能甚至都不会眨眼，并且这种方法毫无疑问地会对错误处理进行提醒： fn bar() -&gt; Result&lt;(), Error&gt; { match foo() { Ok(value) =&gt; /* 使用值... */, Err(err) =&gt; return Err(err) } } 但这种方式还可以变得更好，Rust具有try!宏，可以将上述写法减少到单行的表达式： fn bar() -&gt; Result&lt;(), Error&gt; { let value = try!(foo); // 使用值... } 这种方式提供了在平衡各种因素下的最佳位置。虽然它确实会遭遇到我之前提到的性能问题，但在所有其他方面都已经做得很好，但仅性能这一点，它便不是完整的解决方案。所以为此我们需要包含对快速失败（也就是Abandonment）的处理，正如我们将会看到的，它远远优于任何当今广泛使用的其他基于异常的模型。 异常 异常的历史是令人着迷的。在错误模型的研发过程中，我花了无数时间来回顾行业在这个领域的发展，其中包括阅读的一些原始论文，如Goodenough在1975年经典文章，Exception Handling: Issues and a Proposed Notation。除此之外，还研究了几种语言的方法：Ada，Eiffel，Modula-2和3，ML以及给人以灵感的CLU。许多论文比我能总结的漫长而艰辛之旅做得更好，所以我不将不在此赘述，相反，我会专注于对于构建可靠系统来讲，哪些工作是有效以及哪些是无效的。 在开发错误模型时，可靠性在我们上述的要求中是最重要的，如果无法对故障做出适当的反应，那么根据定义，系统将不会非常可靠。而通常来说，操作系统需要就是可靠性，但可悲的是，最常见的模型——非检查性异常（unchecked exception），在这个维度上是做的最差的。 出于以上原因，大多数可靠系统使用返回码而不是异常模型，因为错误码使得，在局部进行分析并决定如何最好地对错误条件进行处理成为可能。但是我说过头了，让我们继续深入下去。 非检查性异常 让我们来快速回顾一下，在非检查性异常模型中，代码throw并catch异常，但异常不是类型系统或函数签名的一部分。例如： // Foo抛出一个未处理的异常： void Foo() { throw new Exception(...); } // Bar调用Foo，并处理该异常： void Bar() { try { Foo(); } catch (Exception e) { // 处理错误 } } // Baz也调用Foo，但不处理该异常： void Baz() { Foo(); // 让错误逃逸到Baz的调用者 } 在这个模型中，任何函数调用（有时是任何语句）都可以抛出异常，并将控制权转移到其他非局部的位置。那么到底转移到何处？没有人知道。因为没有注解或类型系统的制品能辅助你的分析，因此任何人都很难推断程序在抛出时的状态，和异常被捕获或保持未处理时的最终状态。因为当异常在调用栈中向上传播，甚至在并发程序中以跨线程的方式传播时，程序的状态都可能发生更改。 当然这也是可以尝试的，为此需要阅读API文档，对代码进行手动审计，并严重依赖于代码审查以及良好的运气，但语言对此没有提供任何帮助。 因为程序中的故障总是少数，所以这并不像听起来那样完全是灾难性的。我的结论是，这就是为什么业内很多人认为非检查异常已经“足够好”，他们会为了通常的成功路径而避免引入其它的干扰，因为大多数人都不会在非系统程序中编写强大的错误处理代码，而抛出异常通常会让你快速逃离错误引起的困境。捕捉错误然后继续运行通常也是有效的，没有造成伤害，没有不合规定。因此从统计上讲，程序“能够工作”。 也许这种统计的正确性对于脚本语言是可行的，但对于操作系统的最低层次或任何任务关键的应用程序和服务而言，这不是一个合适的解决方案。我希望对此是没有争议的。 在.NET中，由于异步异常的存在，使得情况更加糟糕。C++也有所谓的“异步异常”：由硬件故障触发的故障，例如访问违例。然而，它在.NET中，它却显得非常令人讨厌，因为任意线程几乎可以在代码中的任何一处注入失败，即使在赋值语句的RHS和LHS之间也是如此！ 因此，源代码中看起来像原子的操作，在实际中却并不如此。我在10年前写过关于此的文章，尽管现在已普遍意识到.NET的线程中止是有问题的并使得这种风险减弱，但挑战实际上仍然是存在的。新的CoreCLR甚至缺少AppDomains，并且在ASP.NET Core 1.0中，栈肯定不会像过去那样使用线程中止，但它们的API仍然存在。 有一个关于C#的首席设计师Anders Hejlsberg的著名采访，名为The Trouble with Checked Exceptions。从系统程序员的角度来看，大部分的内容都会让你感到困惑，但有一点却是可以理解的，没有声明能够肯定C#的目标客户是超过如下内容的快速应用程序开发者： Bill Venners：但是你不是在这种情况下破坏他们的代码，即使是在缺乏检查性异常的语言中也是如此么？ 如果foo的新版本将抛出一个应该处理的新异常类型，那么他们的程序是不是仅仅因为在编写代码时没有预料该异常而导致崩溃呢？ Anders Hejlsberg：不会，因为在很多情况下，人们并不关心，他们不会处理任何这些异常情况。在他们的消息循环中有一个底层的异常处理程序，该处理程序只是打开一个对话框，说明出了什么问题然后继续执行。程序员通过在任何地方编写try和finally来保护他们的代码，因此如果发生异常他们将正确退出，但他们实际上对异常的处理并不感兴趣。 这让我想起了Visual Basic中的On Error Resume Next，以及Windows Forms自动捕获并透明处理应用程序抛出的错误，然后尝试继续执行的方式。 我在这里并不责怪Anders的观点，由于C#的受欢迎程度，我确信这是当时大背景下的正确选择，但这肯定不是编写操作系统代码的正确方法。 C++至少尝试过使用它的throw异常规范 提供比非检查性异常更好的方式。 但不幸的是，这个功能依赖于动态增强（dynamic enhancement），凭这一点便宣告了它的失败。 如果我写一个函数void f() throw(SomeError)，f的函数体仍然可以自由地调用抛出除SomeError之外的异常的函数；类似地，如果我声明f不会抛出异常，但使用void f() throw()仍然可以调用抛出异常的函数。因此，为了实现所述的合约，编译器和运行时必须确保，如果发生这两种情况，则需调用std::unexpected杀死进程以作为响应。 我不是唯一认识到这种设计是错误的人，事实上，throw已经遭到弃用。一篇详细的WG21论文，Deprecating Exception Specifications，阐述了C++是如何沦落于此的，在这里我提供了此文的开场白： 事实证明，异常规范在实践中几乎毫无价值，反而还为程序增加了可见的开销。 作者列举了弃用throw的三个原因。这三个原因中的两个是动态选择的结果：运行时检查（及其关联的opaque故障模式）和运行时性能开销。第三个原因是，虽然泛型代码中缺乏合成，但可以使用适当的类型系统来解决（当然这也是有开销的）。 但最糟糕的是，这种方法依赖于另一个动态强制构造——noexcept分类符，在我看来，这种解决方案与问题本身一样糟糕。 “异常安全性（Exception safety）”是C++社区中经常讨论的一种实践方法。这种方法巧妙地从调用者关于故障，状态转换和内存管理的视角对函数的意图进行分类。函数被分类为四种类型之一：“no-throw”意味着向前执行的程度得到保证且不会出现异常；“strong safety”意味着状态转换以原子的方式发生，而故障不会导致部分提交的状态更改或不变量被破坏；“basic safety”意味着，虽然函数可能发生部分提交的状态更改，但不会破坏不变量并能防止内存泄漏；最后，“no safety”意味着一切皆有可能，无任何保障。这种分类法非常有用，我鼓励任何人对错误行为采取有意和严谨的态度，无论是使用这种方法还是其它类似的方法，即使是你使用的是错误码方式。 但问题是，除了叶节点数据结构调用一组小且易于审计的其他函数之外，在使用非检查性异常的系统中遵循这些指南基本上是不可能的。试想一下：为了保证各处的安全性，你需要考虑所有函数调用的可能性，并相应地对周围的代码进行保护。这意味者要么进行防御性编程（Defensive programming），要么信任所调用函数的（无法被计算机检查的）文档，要么只调用noexcept函数而走运，要么只是希望最好的情况出现。多亏有了RAII，免于泄露的基本安全性变得更容易实现（由于智能指针的出现，现在这些安全也变得很常见），但破坏不变量这一点却也很难避免。“Exception Handling: A False Sense of Security”一文对此进行了很好地总结。 对于C++而言，真正的解决方案很容易猜到，而且非常简单，那便是对于健壮的系统程序，不要使用异常处理。这是嵌入式C++的常用做法，除此之外还有包括NASA喷气推进器实验室在内的C++的大量实时和任务关键指南也建议这么做。因此，火星上的C++代码肯定不会很快地使用上异常。 所以如果你可以安全地避免使用异常并坚持使用C++中的类C的返回码方式，那么问题又出在何处呢？ 问题出在，整个C++生态系统都在使用异常。为了遵守上述指导原则，你必须避免使用该语言的相当一部分特性。但事实证明，这些重要特性是库生态系统的重要组成部分。想使用标准模板库？太糟糕了，它使用了异常，想使用Boost？太糟糕了，它也使用异常。你的内存分配器也可能会抛出bad_alloc异常等等。甚至会导致创建现有库无异常处理分支一样的神经错乱做法，例如，Windows内核有自己的STL分支，但它不使用异常处理，但这种生态系统的分叉既不愉快也不实用。 这种混乱让我们陷入了困境，特别是因为许多语言使用非检查性异常。很明显，它们不适合编写低层次的可靠的系统代码（我如此会直截了说出来，肯定会招惹几个来自C++的反对者）。在为Midori编写多年代码后，让我回去编写使用非检查性异常的代码，会让我欲哭无泪，即使仅仅对代码进行审查也是一种折磨。但“幸运的是”，我们已经有了来自Java的检查性异常用于学习和借鉴……不是吗？ 检查性异常 检查性异常就像，几乎每个Java程序员以及近距离观察过Java的人都喜欢拍打的布娃娃。在我看来，将它与非检查性异常的混乱进行比较是不公平的。 在Java中，因为方法必须进行如下申明，所以你知道大多数方法可能会抛出什么类型异常： void foo() throws FooException, BarException { ... } 那么，现在调用者便知道调用foo可能导致抛出FooException或BarException类型的异常。因此在调用点中，程序员必须如下决定：1）按原样传播抛出的异常；2）捕获并处理它们；或者3）以某种方式转换抛出的异常类型（甚至可能是“完全遗忘掉”异常类型）。例如： // 1) 按原样传播异常： void bar() throws FooException, BarException { foo(); } // 2) 捕捉并处理它们： void bar() { try { foo(); } catch (FooException e) { // 处理FooException的错误情况 } catch (BarException e) { // 处理BarException的错误情况 } } // 3) 转换抛出的异常类型： void bar() throws Exception { foo(); } 这与我们可以使用的东西越来越接近，但它在某些情况下也会失效： 异常用于传递不可恢复的错误，如null解引用，除零等； 由于RuntimeException的存在，实际上并不知道可能抛出的所有内容，因为Java对所有错误条件使用异常，甚至对程序中的bug也是如此。设计师也意识到人们会对所有这些异常规范感到厌烦，因此他们引入了一种非检查性异常。也就是说，一个方法可以在不声明的情况下抛出这种异常，使得调用者可以无缝地调用它。 虽然签名声明了异常类型，但在调用点没有迹象表明调用可能会抛出什么类型的异常； 人们讨厌这种方式。 最后一项是很有趣的，稍后我将在描述Midori所采用的方法时再回头来看看。总而言之，人们对Java中检查性异常的厌恶主要源于上面其他三项，或者至少在其他三项上得到了增强。由此产生的模型似乎是两种方式之间最糟糕的：它无法帮助你编写完全免于错误的代码，同时也难以实用。最终，你在代码中写下了很多莫名其妙并且几乎没有什么好处的语句。另外，对接口进行版本控制也是一件很痛苦的事。正如我们稍后将会看到的，我们本来可以做得更好。 该版本控制点是值得深思的，如果你坚持使用单一类型的throw，那么其版本控制问题并不比错误码更糟糕，函数要么失败或成功。确实，如果你将API的第一版设计为无故障的模式，然后想要在第二版中添加故障的抛出代码，那么事情就被你搞砸了，在我看来，这种情况可能就会发生。API的故障模式是其设计和与调用者之间的合约的关键部分，正如你不会在调用者未知的情况下静默更改API的返回类型一样，你也不应该以语义上有意义的方式更改其故障模式。稍后将对这个有争议的问题进行讨论。 在CLU中有一种有趣的方法，正如Barbara Liskov在1979年的“Exception Handling in CLU” 一文中所描述的那样。我注意到他们非常关注于“语言学”，换句话说，他们想要一种人们喜欢的编程语言：在callites上检查和重新传播所有错误的感觉更像是返回值，但编程模型对我们现在所知的异常有更丰富和略微声明式的感觉。最重要的是，signal（它们现在的名字式throw）是检查性的，并且如果发生意外signal，还有方便的方法来终止整个程序。 异常的中普遍存在的问题 大多数的异常系统，无论是检查性的还是非检查性的，都会出现一些普遍的问题。 首先，抛出异常开销通常非常大，这基本上总是由收集堆栈跟踪（stack trace）所引起的。在托管系统中，收集堆栈跟踪还需要对元数据进行搜索，以创建函数符号名称的字符串，但是，如果错误得以捕获并处理，你甚至不需要在运行时获取这些信息；诊断能够在日志记录和诊断基础设施中更好地被实现，而不是在异常系统本身中，而上述这些关心点又是正交的。但为了真正取得上述的诊断要求，某些系统需要能够恢复堆栈跟踪；永远不要低估printf调试的强大能力以及堆栈跟踪对此的重要性。 其次，异常会严重影响代码质量。我在上一篇文章中谈到了这个主题，并且有C++环境中关于该主题很好的论文。静态类型系统信息的缺乏使得很难在编译器中对控制流进行建模，从而导致优化器变得过于保守。 大多数异常系统出问题的另一个方面是鼓励对错误进行粗粒度的处理。返回码的支持者喜欢将错误处理本地化为特定的函数调用（，而我也是这样做的）。但在异常处理系统中，很容易在一些巨大的代码块周围加上粗粒度的try/catch块，而不会仔细地对单个故障做出反应。这种方式产生的脆弱代码几乎肯定是会出错的。如果不是今天，那么沿着这条路走，不可避免的重构必将会发生，因此，这与拥有正确的语法有很大程度的关系。 最后，throw的控制流通常是不可见的，即使是使用Java的注解方法签名的方式，也无法对代码体进行审计并准确查看异常的来源。静默的控制流与goto或setjmp/longjmp一样糟糕，并且使编写可靠代码变得非常困难。 我们身在何处？ 在继续前行之前，让我们回顾一下我们所处的位置： 如果我们可以带走所有的“Goods（好家伙）”，并舍弃“Bads（坏家伙）”和“Uglies（丑家伙）”，那不是一件很好的事吗？ 仅次一点就是向前迈出的一大步，但这还远远不够，这让我想起了我们首个影响未来一切的“欢呼”时刻。对于一大类的错误，表中的所有这些方法都不合适！ Bug不是可恢复的错误！ 我们早期做出的一个重要区分，是可恢复错误和bug之间的区别： 可恢复的错误通常是程序化的数据验证的结果，一些代码对上下文的状态进行了检查，并认为这种状态对于继续执行是不可接受的。也许是正在解析的标记文本、来自网站的用户输入或易失网络的连接故障等，在这些情况下，程序期望能够正常恢复。编写此代码的开发者必须考虑在发生故障时该怎么做，因为无论你怎么编写代码，这些情况都会在构造良好的程序中发生。响应的方式可能是将情况传达给终端用户、重试或完全放弃的操作，但这是一种可预测的，经常是计划内的情况，尽管它被称为“错误”。 bug是程序员没有意料到的一种错误，这包括输入未正确验证、逻辑的编码错误或出现任何问题。这些问题通常甚至不能被及时发现，它的“次要影响”需要一段时间才能间接地观察到，而此时可能会对程序的状态造成重大破坏。因为开发者没料到会发生这种情况，所以一切都结束了。此代码可访问的所有数据结构都是被怀疑的对象，而且因为这些问题不一定能及时被发现，事实上，更多的部分将是不可信的。根据语言的隔离保证，可能使得整个进程都受到了污染。 这种区分至关重要。但令人惊讶的是，大多数系统都没有做到这一点，至少不是以一种原则性的方式进行区分！如上所述，Java，C#和动态语言仅使用异常，而C和Go仅使用返回码。 C++根据受众的不用使用两者混合的方式，但通常的情况是项目选择其中之一，并在代码的任何地方都这样使用。但你通常不会听到某种语言建议使用这两种不同的错误处理技术。 鉴于bug本质上是不可恢复的，我们没有试图对其进行try捕捉。在运行时检测到的所有bug所导致的后果，在Midori的术语中被称为Abandonment（放弃），也就是所谓的“快速失败”。 上述每种语言都提供类似Abandonment的机制：C#有Environment.FailFast，C++有std::terminate，Go有panic，以及Rust有panic!等等。每一方式都突然且迅速地销毁掉上下文环境，而此上下文的范围则取决于系统，例如，对于C#和C++来说是终止进程，对于Go来说是Goroutine，而对于Rust来说则是当前线程，并可选择地附加一个panic处理程序来对进程进行抢救。 虽然我们确实以比一般的更有纪律和无处不在的方式使用Abandonment，但我们当然不是第一个认识到这种模式的团队。这篇Haskell文章非常清楚地表达了这种区别： 我参与了用C++编写的库的开发。其中一位开发者告诉我，开发者可以分为喜欢异常和喜欢返回码两种类型。在我看来，使用返回码的朋友赢了。但是，我得到的印象是他们论点是错误的：异常和返回代同有同样的表达能力，但这并不适用于描述bug。实际上，返回码包含ARRAY_INDEX_OUT_OF_RANGE等定义，但我想知道：当程序从子程序获得该返回码时，它将如何对其作出反应？它应该向程序员发送邮件告知吗？它可以依次将此错误码返回给其调用者，但它们其实也都不知道如何对其进行处理。更糟糕的是，由于我不能对函数的实现做出假设，所以不得不认为每个子程序都有可能返回ARRAY_INDEX_OUT_OF_RANGE。我的结论是ARRAY_INDEX_OUT_OF_RANGE是一个（编程性）的错误，无法在运行时对其进行处理或修复，只能由其开发者来修复。因此，这不应该有这样的返回码存在，而是应该采用断言的方式。 放弃细粒度的可变共享内存作用域是不可信的，比如Goroutine、线程或其他方式，除非你的系统以某种方式保证潜在的内存破坏范围。但是，很不错的是这些机制是存在的并可以被我们所利用！这也就意味着在这些语言中使用Abandonment机制确实是有可能的。 然而，它还必须具有大规模成功所必需的架构元素。我相信你在想“如果我每次在我的C#程序中进行null解引用时都会抛出整个进程，那么我的一些客户会非常的生气”，和“这根本不可靠！”等相似的想法。事实证明，可靠性可能与你的想法有所不同。 可靠性，容错和隔离 在我们进一步讨论之前，我们需要先表达中心信念：故障会发生。 构建可靠的系统 这里的常识是通过系统地保证故障永不发生的方式，来构建一个可靠的系统。直观上来说，这是很有道理的，但有一个问题：在极限的情况下，这是不可能的。如果你可以单独花费数百万美元来获得这样的可靠性，就像许多任务关键的实时系统一样，那么会给你留下深刻的印象。也许使用像SPARK这样的语言（一组基于合约的Ada扩展）来形式化证明每行代码的正确性。然而，经验表明即使这种方法也不是万无一失的。 我们接受而不是反对这一事实。但如果显然试图在所有可能的情况下消除失败，那么错误模型必须使它们透明且易于处理。更重要的是，系统被构建为即使单个部件出现故障，整个系统仍然可以正常运行，然后再指导系统优雅地恢复那些故障部分。这种原则在分布式系统中是众所周知的，那为什么它又是新颖的呢？ 处于这一切的中心的操作系统，只是协作进程们的分布式网络，就像微服务的分布式集群或互联网本身，它与这些系统的主要区别在于延迟，和可以建立什么样的信任程度以及达到的难度如何，以及关于位置，身份的各种假设等。但高度异步，分布式和I/O密集型系统中的故障必然会发生。对此，我的看法是，很大程度上是因为宏内核的持续成功，使得整个世界还没有跃升到“作为分布式系统的操作系统”的洞察力。但是，一旦你这么做了，很多的设计原则就会变得明显起来。 与大多数分布式系统一样，我们的架构假设进程失败是不可避免的，尽管我们花了很长时间来防止级联故障发生，定期日志记录，以及实现程序和服务的可重启性。 当你如此假设时，便会以不同的方式来构建整个系统。 特别地，隔离至关重要，Midori的进程模型有助于轻量级细粒度的隔离，因此，程序和现代操作系统中通常称为“线程”的构造是独立的孤立实体。对一个这样的系统中的网络连接失败进行保护比在地址空间中的共享可变状态下要容易得多。 隔离同样也有助于简单性，Butler Lampson的经典文章“Hints on Computer System Design”探索了这个主题。我一直很喜欢Hoare的这句话： 可靠性的无法避免的代价是简单性（C. Hoare）。 通过将程序分解成更小的部分，每个部分都可以自行失败或成功，使得其中的每个状态机都能保持为更简单的形式，因此使得从故障中恢复变得更加容易。在我们的语言中，可能的失败点是明确的，从而有利于进一步保持这些内部状态机的正确性，并指明了与混乱的外部世界的接口。在这个世界上，单个个体失败的代价并不是那么可怕，所以我不能过分强调这一点。如果没有廉价和永远在线的隔离的架构基础，我后面描述的语言功能都不会很好的工作。 Erlang非常成功地以一种基础的方式将这样的属性构建到语言中。它与Midori一样，利用通过消息传递连接的轻量级进程并鼓励容错架构等措施来实现。它采取的一种常见的模式是“监视器”模式：其中一些进程负责监测环境，并在其他进程发生故障时重启这些进程。这篇文章在明确“让它崩溃（let it crash）”的哲学理念，和关于在实践中构建可靠的Erlang程序的推荐技术上，做了很不错的工作。 因此，关键不在于要防止失败本身，而是要知道如何以及何时处理它们。 一旦你构建了这种架构，你就会战胜它们并确保系统的运行。对我们来说，这意味着为期一周的压力运行：进程不断启动和中止，有些是由故障造成的，并同时确保整个系统良好地前进。这让我想起了像Netflix的Chaos Monkey这样的系统，它会随机终止集群中的某些机器的运行，以确保整个服务保持健康状态。 随着更多的向分布式计算的转变不断发生，我期望更多的系统采用这种理念。例如，在微服务集群中，单个容器的故障通常由封闭的集群管理软件（如Kubernetes，Amazon EC2 Container Service和Docker Swarm等）无缝地处理。因此，我在本文中描述的内容可能有助于编写更可靠的Java，Node.js/JavaScript，Python甚至是Ruby服务。不幸的是，你很可能会与所使用的语言不断抗争来实现这样的目标，因为很多进程的代码在出现问题时也会万分努力地艰难执行。 Abandonment 即使进程是轻量级、隔离且易于重新创建的，你仍然有理由认为在面对错误时放弃整个进程是一种过度的反应。那么下面让我试着来说服你。 当你尝试构建一个健壮的系统时，在运行过程中遇到bug是危险的。如果程序员没有预料到会出现特定的情况，没人知道代码下次是否还会再做正确的事情。关键的数据结构可能在不正确的状态下被丢弃，一个极端（也可能是稍微有点愚蠢）的例子是，一个用于银行业务的例程，其本来目的是将你的存款数字向下舍入现在则可能变成了向上舍入。 你可能会试图将Abandonment的粒度减少到比进程更小的范围里，但这种方式是很棘手的。举一个例子来说，假设你的进程中的一个线程遇到了一个bug，并且执行失败，而且这个bug可能是由存储在静态变量中的某些状态所触发的。即使其他线程似乎看起来不受导致故障的条件的影响，但你也无法对此确定。除非你的系统有一些属性，被你的语言隔离，隔离暴露给独立线程或其他地方的对象根集合，那么最安全的做法是，假设除了把整个地址空间全部销毁之外的任何操作都是有风险和不可靠的。 由于Midori进程的轻量级特性，放弃进程更像是在经典操作系统中放弃单个线程而不是整个进程。但我们的隔离模型让我们可靠地做到了这一点。 我承认作用域主题是个滑坡谬误：也许环境中所有的数据都已经被破坏了，那么你怎么知道中止掉这个进程就足够了？！这里有一个重要的区别，也就是进程的状态在设计上是瞬态的。在一个设计良好的系统中，它可以被丢弃并随意地被重建。没错，一个bug会对持久性状态造成破坏，但是你手头上有一个更大的麻烦，这个麻烦必须以不同的方式进行处理。 对于某些背景，我们可以考虑容错的系统设计。Abandonment（快速失败）已经是该领域的常用技术，我们可以将我们对这些系统的大部分知识应用于普通程序和进程，也许最重要的技术是定期记录和对宝贵的持久性状态做快照。Jim Gray在1985年的论文，“Why Do Computers Stop and What Can Be Done About It?”，很好地描述了这个概念。随着程序持续地向云平台迁移，并且激进地分解为更小的独立服务的趋势，瞬态和持久状态的这种明确区分甚至变得更为重要。由于这种软件编写方式的转变，在现代架构中Abandonment比以前更容易实现。实际上，放弃可以帮助你避免数据被损坏，因为在下一个快照之前检测到的bug可以防止错误状态的逸出。 Midori内核中的bug处理方式也有所不同，因为微内核中的bug与用户进程中的bug就完全不同。它可能造成的损害范围更大，因此最安全的反应是放弃整个“域”（地址空间）。值得庆幸的是，大多数你认为经典的“内核”功能——调度器、内存管理器、文件系统、网络堆栈甚至是设备驱动程序，都是在用户模式以隔离进程的方式运行，所以故障以如上所述的通常方式被限定在隔离的进程中。 Bug：Abandonment，断言和合约 Midori中如下的一些bug可能会导致Abandonment： 不正确的强制类型转换； 试图解引用null指针； 试图越界访问数组； 除零； 意外的数学上/下溢； 内存不足； 栈溢出； 显式的放弃； 合约失败； 断言失败。 我们的基本理念是：以上每种都是程序无法自动恢复的条件，让我们来依次讨论其中每一个。 普通的旧Bug类型 一些情形毫无疑问表明程序存在bug。 不正确的强制转换，试图对null指针解引用，数组越界访问或除零显然是程序逻辑的问题，因为它试图进行无法否认的非法操作。正如我们稍后将看到的，有一些是可以解决的（例如对于除零操作而言，你可能想使用NaN风格的传播），但默认情况下我们认为这是一个bug。 大多数的程序员都毫无疑问地愿意接受这一点，并且将它们以这种方式作为bug处理可将Abandonment带到内部开发循环中，从而有助于快速找到并修复开发过程中的bug。Abandonment确实有助于提高人们编写代码的效率，起初这对我来说是一个意外惊喜，但它确实是有道理的。 另一方面，其他的一些情况则是比较主观的。我们必须对这些情况的默认行为做出决定，这通常会引起争议，所以有时还需提供对程序的控制。 算术上/下溢出 如果说意外的算术上/下溢出是一种bug，这肯定是有争议的说法。然而，在不安全的系统中，这种情况经常导致安全漏洞，对此，我建议你打开国家漏洞数据库来看看这种类型漏洞的绝对数量。 事实上，我们移植到Midori（并获得性能提升）的Windows TrueType字体解析器，仅在过去几年就遭受了十几次的上/下溢出（解析器往往是像这样的安全漏洞的发生地）。 这就产生了像SafeInt这样的软件包，它基本上使你远离了原生的算术运算，转而使用检查性的库来实现。 这些漏洞中的大多数当然还伴随着对不安全内存的访问，因此，你可以有理由的认为，溢出在安全语言中是无害的，所以应该允许出现。然而，基于安全上的经验，很明显的是，程序在面临意外的上/下溢时经常会做错事。简单地说，开发者经常忽略溢出的可能性，使得程序继续执行计划之外的事。而这恰好是Abandonment试图捕捉的bug所定义的内容。关于这一点的最致命一击是哲学上的，当有任何关于正确性上的问题时，我们倾向于在明确的意图方面犯错误。 因此，所有未注解的上/下溢出都被视为bug并会导致Abandonment。除了我们的编译器会激进地优化掉冗余检查之外，这基本上与使用/checked选项来编译C#程序相类似（因为很少有人考虑在C#中使用这个选项，所欲代码生成器在删除冗余的插入检查时几乎没有那么积极地处理）。多亏了这种语言和编译器共同开发的方式，其结果远远好于大多数C++编译器面对SafeInt算法时所生成的代码。与C#一样，unchecked修饰的范围构造 也可用于故意设定的上/下溢出的情况。 虽然大多数C#和C++开发者对我所说的这个想法最初反应都是负面的，但我们的经验是：10次中有9次，这种方法都有助于避免程序中的bug，而剩下的那一次通常是在我们72小时的压力运行（我们用浏览器和多媒体播放器，以及我们认为可以给系统加压的任何应用来测试系统） 的后来某个时间点上，因为一些无害的计数器溢出时发生的Abandonment。我们花时间修复这些而不是采用压力程序提升产品成熟度的经典方式——也就是所谓的死锁和竞争条件，这一点上我总是觉得是非常有趣的。在你我之间，我会将溢出采用Abandonment！ 内存不足和栈溢出 内存不足（OOM）的情况总是很复杂，所以我们在这里的立场当然也是有争议的。 在手动管理内存的环境中，错误码风格的检查方式是最常用的方法： X* x = (X*)malloc(...); if (!x) { // 处理内存分配失败 } 这里的一个微妙的好处是：分配是痛苦的，并且需要思考，因此使用这种技术的程序在使用内存的方式上通常更加节俭和慎重。但它也有一个巨大的缺点：容易出错，并导致大量通常是未经测试的代码路径。当代码路径未经测试时，它们通常都会出错。 一般而言，开发者在系统处于资源枯竭的边缘时，非常努力地试图使他们的软件正常工作，但根据我使用Windows和.NET Framework的经验来看，这是一个令人震惊的错误。它会导致非常复杂的编程模型，比如.NET的所谓的约束执行区域（Constrained Execution Region）。如果一个程序艰难地运行着，即使是少量的内存也无法分配，那么这种情况很快就会成为可靠性的天敌，Chris Brumme奇妙的关于可靠性文章中描述了这种情形以及相关的挑战。 在某种意义上，我们系统的某些部分当然是“硬化的”，就像内核的最低层次一样，对这部分采用Abandonment其影响范围必然比单个进程要更宽，但我们也尽量保持这部分代码尽量的小。 对于系统其余部分呢？是的你猜对了——Abandonment，这很不错也很简单。 令人惊讶的是我们侥幸逃脱了多少这种方式，对此我将大部分原因都归结于隔离模型。实际上，由于资源管理的策略，我们可以故意让一个进程遭受OOM，然后对其中止的策略，并且仍然对建立在整体架构上稳定性和恢复保持信心。 如果你真的需要的话，可以选择对单个分配采取可恢复故障的方式，虽然这并不常见，但支持的机制是存在的。也许最激发积极性的例子是：假设你的程序想要分配1MB大小的缓冲区，这种情况与普通的1KB对象的分配是有所不同的。开发者可能已经思考并准备好应对，那些可能无法获得1MB大小的连续块内存的情况，并相应地对其进行处理。例如： var bb = try new byte[1024*1024] else catch; if (bb.Failed) { // 处理分配失败 } 栈溢出是这一理念的简单扩展，因为栈只是内存所支持下的一种资源。实际上，由于我们的异步链接栈模型，栈内存的溢出与堆内存的溢出在物理上是完全相同的，因此开发者对其处理方式的一致性并不令人惊讶。如今，许多系统也都以这种方式来处理栈溢出。 断言 断言是代码中的手动检查某些条件是否成立，如果不成立则触发Abandonment的机制。与大多数系统一样，我们同时具有调试（debug-only）版本和发布（release）版本的代码断言，但与大多数其他系统不同的是，我们在发布版本中的断言数量多于调试版本。事实上，我们的代码充满了断言，而大多数方法中存在多个断言。 这样做的理念是，在运行时找到bug比在遇到错误时继续运行更好，当然，我们的后端编译器也被实现为像其他方面一样激进地对断言进行优化。这种断言的密度水平类似于高可靠性系统的指导原则所建议的一样，例如，来自美国宇航局的论文，“The Power of Ten -Rules for Developing Safety Critical Code”是这样描述的： 规则：代码的断言密度应为平均每个函数最少两个断言。断言用于检查在现实生活中不应发生的异常情况。断言必须始终是无副作用的，并且应该定义为布尔测试。 理由：工业编码工作的统计数据表明，通常每写入10到100行代码，单元测试就会发现至少一个缺陷。而拦截缺陷的几率随着断言密度的增加而增加，断言的使用通常也被推荐为强防御性编码策略的一部分。 要表示断言，只需调用Debug.Assert或Release.Assert即可： void Foo() { Debug.Assert(something); // 仅对调试版本的断言 Release.Assert(something); // 始终检查性的断言 } 我们还实现了类似于C++中的__FILE__和__LINE__宏的功能，以及谓词表达式文本的__EXPR__，因此由于断言失败而导致的Abandonment会包含有用的调试信息。 在早期，我们使用不同“级别”断言的方式。断言有三个级别，分别是Contract.Strong.Assert，Contract.Assert和Contract.Weak.Assert。最强的Contract.Strong.Assert级别意味着“始终检查”，中间的Contract.Assert级别意味这“是否检查取决于编译器”，最弱的Contract.Weak.Assert级别意味着“只在调试模式下检查”。我做出了有争议的决定，以放弃这种这种分类方式。事实上，我非常确定团队49.99%的成员绝对讨厌我所选择的术语（Debug.Assert和Release.Assert），但我总是喜欢这种方式，因为它们表示的意义非常明确。旧的分类方法的问题在于，没有人确切知道何时会检查断言，而在我看来，这个领域内的混乱根本是不可接受的，因为好的断言规则对程序的可靠性非常重要。 当我们将合约添加到语言中（很快会有更多的合约）时，我们也尝试将assert变成关键字。但是，我们最终转而使用API的方式，其主要原因是断言不像合约那样，它不是API签名的一部分；并鉴于断言可以很容易地作为一个库来实现，我们也不清楚加入到语言中能获得什么。此外，像“checked in debug”和“checked in release”之类的策略根本不像是编程语言特性，我承认，多年以后，我仍然对此持怀疑态度。 合约 在Midori中，合约是捕获bug的核心机制。尽管我们以使用了Spec# 变体Sing#的Singularity作为开始，但我们很快就转移到了普通C#并且不得不重新发现我们想要的东西。在与此模型打交道多年以后，我们最终以和开始时非常不同的模样作为结束。 由于我们的语言对不变性和副作用的理解方式，所有的合约和断言都被证明是无副作用的，这可能是语言创新的最大领域，所以我一定会尽快写一篇关于此的文章。 与其他地方一样，关于合约，我们也受到许多其他系统的启发和影响。 Spec#显然是其中之一，Effiel对我们也有很大的影响力，特别是因为他有许多已发表的案例研究可以学习，另外基于Ada的SPARK的相关研究工作以及实时和嵌入式系统的建议也是如此。像Hoare的公理语义这样的编程逻辑，深入研究理论上的未知领域，为所有这些打下了基础。然而，对我来说，最有哲学意义上的灵感来自CLU以及后来的Argus的整体错误处理方法。 前置条件和后置条件 最基本的合约形式是方法的前置条件，其申明了要指派的方法必须具备的条件，并通常用于验证参数。它有时也用于验证目标对象的状态，但这通常是不受欢迎的，因为对于程序员来说，形态是很难推算的。前置条件基本上是调用者向被调用者提供的一种保证。 在我们的最终模型中，使用requires关键字声明前置条件： void Register(string name) requires !string.IsEmpty(name) { // 字符串不为空，并继续处理 } 一种稍微不太常见的合约形式是方法的后置条件，它表明在指派完方法之后保持何种状态，这是被调用者向调用者提供的一种保证。 在我们的最终模型中，使用ensure关键字声明后置条件： void Clear() ensures Count == 0 { // 继续处理，并当函数返回时，调用者可以保证Count值是0 } 也可以通过特殊名称return来声明后置条件中的返回值，而旧的参数值，例如在后置条件中引用输入所必需的值，可以通过old(..)来捕获。比如说： int AddOne(int value) ensures return == old(value)+1 { ... } 当然，前置和后置条件也可能是混合出现的，比如说下面是来自Midori内核中环形缓冲区的代码： public bool PublishPosition() requires RemainingSize == 0 ensures UnpublishedSize == 0 { ... } 此方法在知道RemainingSize的值为0时，可以安全地执行其函数体；而调用者知道UnpublishedSize也为0后，可以在被调用函数返回后安全地执行。 如果在运行时发现这些合约中任何一个是错误的，则会执行Abandonment操作。 该领域是我们与其他工作所不同之处。合约作为高级证明技术中使用的程序逻辑表达最近变得流行起来，这些工具通常使用全局分析来证明所述合约的真实性或虚假性。我们采取了一种更简单的方法：在默认情况下，合约在运行被时检查，但如果编译器可以在编译时证明其真或假，则可以自由地分别进行运行时检查或发出编译时错误。 现代编译器具有基于约束的分析，并在这方面已经做得很好，就像我在上一篇文章中提到的范围分析一样。分析器传播事实并使用它们来优化代码，优化包括消除冗余检查，在合约或正常程序逻辑中显式地编码。并且它们被训练地可以在合理的时间内执行这些分析，避免程序员因等待时间过长而切换到其他更快的编译器上。而定理证明技术根本无法满足在我们的规模上的需求，我们的核心系统模块使用最优秀定理证明分析框架，也花了一天的时间来对其进行分析！ 此外，方法声明的合约也是其签名的一部分，这意味着它们会自动显示在文档和IDE的工具提示中，所以合约与方法的返回值和参数类型一样重要。合约实际上只是类型系统的扩展，使用语言中的任意逻辑来控制交换类型的形状，因此，所有通常的子类型要求对于它们都是适用的。当然，这有助于使用标准优化编译器技术在几秒钟内完成对局部分析的模块化。 .NET和Java中90%的典型异常用法都变成了前置条件。所有的ArgumentNullException，ArgumentOutOfRangeException和相关类型，以及更重要的的人工手动检查和throw都消失了。如今，C#中的方法经常被这些检查所覆盖，仅在.NET的CoreFX代码仓库中就有数千个这样的检查。例如，下面是System.IO.TextReader中的Read方法： /// &lt;summary&gt; /// ... /// &lt;/summary&gt; /// &lt;exception cref=&quot;ArgumentNullException&quot;&gt;如果buffer为null，则抛出该异常&lt;/exception&gt; /// &lt;exception cref=&quot;ArgumentOutOfRangeException&quot;&gt;如果index小于零，则抛出该异常&lt;/exception&gt; /// &lt;exception cref=&quot;ArgumentOutOfRangeException&quot;&gt;如果count小于零，则抛出该异常&lt;/exception&gt; /// &lt;exception cref=&quot;ArgumentException&quot;&gt;如果index和cout超出缓冲区的范围，则抛出该异常&lt;/exception&gt; public virtual int Read(char[] buffer, int index, int count) { if (buffer == null) { throw new ArgumentNullException(&quot;buffer&quot;); } if (index &lt; 0) { throw new ArgumentOutOfRangeException(&quot;index&quot;); } if (count &lt; 0) { throw new ArgumentOutOfRangeException(&quot;count&quot;); } if (buffer.Length - index &lt; count) { throw new ArgumentException(); } ... } 出于多种原因，这段代码已经不能编译。这样的代码当然是非常啰嗦的，充满了繁文缛节，但当开发者真的不应该去捕捉他们时，我们必须尽力去将异常文档化，相反，他们应该在开发过程中找到错误并修复它。所有这些异常都会无意义地助长非常糟糕的行为。 另一方面，如果我们使用Midori风格的合约，那么上面的代码则折叠成如下的形式： /// &lt;summary&gt; /// ... /// &lt;/summary&gt; public virtual int Read(char[] buffer, int index, int count) requires buffer != null requires index &gt;= 0 requires count &gt;= 0 requires buffer.Length - index &gt;= count { ... } 这种方式有一些吸引人之处。首先，它更加的简洁；然而，更重要的是，它以一种记录自身并且调用者易于理解的方式自我描述API的合约。其实际表达式也可供调用者来阅读，以及供工具来理解和利用，而不要求程序员用通俗语言来表达错误条件。另外，它也使用Abandonment方式来传递失败。 我还提到我们有很多合约辅助工具来帮助开发者编写常见的前置条件。上面的显式范围检查非常混乱，且容易出错，相反地，我们可以这样编写： public virtual int Read(char[] buffer, int index, int count) requires buffer != null requires Range.IsValid(index, count, buffer.Length) { ... } 另外除了交互之外，还有两个高级的功能：数组作为切片（slice）和非零类型。我们可以将上面的代码简化到如下的形式，并同时保留相同的保证： public virtual int Read(char[] buffer) { ... } 我们再向前迈了一步…… 谦虚的开始 虽然我们提到了语法与Eiffel和Spec#的一样清晰明了，但正如我之前所提到的那样，我们真的不想在一开始就改变语言，所以实际上我们从一个简单的API方法作为开始： public bool PublishPosition() { Contract.Requires(RemainingSize == 0); Contract.Ensures(UnpublishedSize == 0); ... } 这种方法存在许多问题，正如在.NET Code Contracts的努力已经汲取了这方面的教训。 首先，以这种方式编写的合约是API实现的一部分，但我们却希望它们成为签名的一部分，这似乎是一个理论上的问题，但它实际上远非理论上的。我们希望生成的程序包含内置的元数据，使得IDE和调试器等工具可以在调用点上显示合约，同时我们还希望工具能够从合约中自动生成文档。除非你之后以某种反汇编手段从方法中提取它们（这是一种黑客的行为），否则将它们隐藏在实现中是行不通的。 另外，这种方式也使得很难与后端编译器集成，而我们发现与后端的集成对于良好的性能是必要的。 其次，你可能已经注意到对Contract.Ensures的调用存在问题。由于Ensures意味着会保留函数的所有返回路径，那么我们如何将其仅仅实现为API的形式？答案是：这是做不到的。一种方法是在语言编译器生成代码之后重写生成的MSIL，但这非常麻烦。此时，你不禁开始怀疑，为什么不简单地承认这是语言表达性和语义问题，并添加相应的语法呢？ 对我们来说，长期挣扎的另一个领域是合约是否是有条件的。在许多经典系统中，只需要检查调试版本中的合约，而对完全优化版本的合约则不检查。正如对前面的断言一样，在很长一段时间里，我们对合约也有三个相应的级别： 最弱，由Contract.Weak.*表示，表示仅调试的合约 正常，简单地用Contract.*表示，留给实现决定何时检查它们 最强，由Contract.Strong.*表示，表示总是对其检查的合约 我承认，我最初认为这是一个优雅的解决方案。但不幸的是，随着时间的推移，我们发现开发者在调试，发布或上述所有内容中是否存在“正常”级别的合约时常常存在着混淆（因此人们经常会误用最弱级别和最强级别）。无论如何，当我们开始将这个方案集成到语言和后端编译器工具链中时，我们遇到了很多问题，所以不得不稍微把目标退后一点。 首先，如果你简单地将Contract.Weak.Requires翻译成weak requires，以及将Contract.Strong.Requires翻译成strong requires，那么在我看来，你最终得到一个相当笨重和专门化的语法，以及更多让我感到不舒服的策略。所以这种方式会立即让人呼吁参数化和weak/strong策略的可替代性。 接下来，这种方法引入了一种对我来说感觉很尴尬的新条件编译模式，换句话说，如果你想对仅调试版本进行检查，可以这样写： #if DEBUG requires X #endif 最后，对我来说最后的一击是，合约应该被当作API签名的一部分。那么有条件的合约意味着什么？工具应该如何推理呢？为发布版本生成和调试版本不同的文档？而且只要存在这样的合约，就会失去如果不满足其前置条件则代码将无法运行的关键性保证。 最终，我们完成了整个条件编译的方案。 我们最终得到了单一类型的合约，它是API签名的一部分，并且在所有时刻都会被检查。如果编译器在编译时可以证明合约永远会得到满足（我们花了相当大的精力在这上面），那么完全可以免除检查，但是如果不满足其先决条件，则将保证代码永远不会执行。对于需要进行条件检查的情况，则始终有断言系统可以利用（如上所述）。 当我们部署这样的新模型时，我感到这样的方式更好。并且发现许多人因混淆而滥用上面的“weak”和“strong”概念，因此，迫使开发者做出决定给它们带来更好的代码。 未来的方向 当我们的项目结束时，许多领域的发展处于不同的成熟阶段。 不变量 我们在不变量上进行了很多的实验。每当我们与熟悉合约设计的人交谈时，他们都会对我们从第一天起就没有使用不变量而感到宽慰。说实话，我们的设计从一开始就包含了它们，但是却从来没有完成它的实现和部署，这仅仅是由于工程的产出量不足和一些困难的问题仍然存在所导致的。老实说，团队基本上满意于前置/后置条件和断言的结合，因此我怀疑在充足的时间里我们是否应完成不变量的实现。但到目前为止，我仍然对此有一些问题，所以我需要在行动中再看一段时间。 我们设计的方法是，invariant成为其封闭类型的成员。例如： public class List&lt;T&gt; { private T[] array; private int count; private invariant index &gt;= 0 &amp;&amp; index &lt; array.Length; ... } 请注意，invariant标记为private，不变量的访问性修饰符控制了需要保持不变性的成员。例如，public invariant变量只需要在具有public访问性的函数的进入和退出时保持不变，它允许private函数的常见模式暂时违反不变性，只要在public的入口点保持它们即可。当然，如上例所示，类也可以自由声明为private invariant，这需要在所有函数入口和出口保持不变性。 我其实很喜欢这样的设计，并且觉得它会有用。我们所关心的主要问题是在所有地方静默地引入检查。直到今天为止，这一点仍让我感到紧张，例如，在List&lt;T&gt;的示例中，你将在类型的每个函数的开头和结尾进行index &gt; = 0 &amp;&amp; index &lt;array.Length的检查。现在，我们的编译器最终非常善于识别和合并冗余合约检查，并且在很多情况下，合约的存在实际上使代码质量更好。但是，在上面给出的极端例子中，我确信它会造成性能损失，因此会对我们改变检查不变量的策略施加压力，从而可能会使整体合约模型变得复杂。 我真的希望我们有更多的时间来更深入地探索不变量，我不认为团队严重错过它们，当然我没有听到太多抱怨缺失他们的声音（可能是因为团队非常注重性能），但我确实认为不变量会是合约系统上的闪光之处。 高级类型系统 我喜欢说合约始于类型系统触及不到之处。类型系统允许你使用类型对变量的属性进行编码，对变量可能包含的预期范围值进行限制。类似地，合约也对变量所持有值的范围进行检查。那么它们的区别在什么地方？类型在编译时通过严格且可组合的归纳规则得以验证，这些规则对于函数局部检查而言开销更小，但通常并不总是由开发者编写的注解所辅助。合约在可能的情况下在编译时进行证明，否则在运行时被证明，因此，合约被允许使用语言本身编码的任意逻辑进行远非严格的规范。 类型是一种可取的方式，因为它们保证在编译时进行检查，同时保证检查的快速。它给开发者的保证很强，使得使用它们的整体效率更高。 然而，类型系统的局限也是不可避免的。类型系统需要留下一些协调空间，否则它会迅速膨胀并且可用性很差，并且在极端情况下会转换为双值位和字节。另一方面，我总是对需要使用合约的两个特定的协调空间区域感到失望： 空值性； 数值范围。 我们大约90%的合约都属于这两者类型。因此，我们认真研究了更复杂的类型系统，以使用类型系统而不是合约的方式对变量的空值性和范围进行分类。 具体来说，这是与使用合约的代码之间的区别： public virtual int Read(char[] buffer, int index, int count) requires buffer != null requires index &gt;= 0 requires count &gt;= 0 requires buffer.Length - index &lt; count { ... } 下面这段代码在编译时静态检查，虽然不需要但仍然保留了所有相同的保证： public virtual int Read(char[] buffer) { ... } 将这些属性放置在类型系统中可以显著地减轻错误条件检查带来的负担。我们说，对于任何给定的一个状态的生产者，都有10个对应的消费者，那么可以将责任推回到生产者身上，而不是让每个消费者自身来抵御错误条件。这么做只需要一个强制类型的断言，或者首先将值存储到正确的类型这种更好的方式。 非空类型 其中之一的非空性真的很难做到：保证静态变量不会使用null值，而这就是Tony Hoare的所谓的“十亿美元的错误”。解决这个问题对于任何语言来说都是一个正确的目标，我很高兴看到新的编程语言的设计师正在正面解决这个问题。 语言的许多方面都会在这一步中与你发生冲突，比如说泛型、零初始化和构造函数等，在现有语言中实现非空性真的很难！ 类型系统 简而言之，非空值性可以归结为一些简单的类型系统的规则： 默认情况下，所有未加修饰的类型T都是非空的； 任何类型都可以使用?进行修饰，如T?，以将其标记为可为空； null对于任何非空类型变量来说都是非法值； T可以隐式转换为T?，从某种意义上说，T是T?的子类型（尽管不完全如此）； 存在运算符将T?转换为T，并进行运行时检查，如果值为null则触发放弃机制。 大多数情况可能是“显而易见的”，因为可以选择的方法并不多。主要的原则是系统地确保所有null值对于类型系统都是可知的，特别是，没有null可以“偷偷摸摸”成为非空的T类型值，这意味着其解决了零初始化问题——可能是所有问题当中最困难的一个。 语法 从语法上来讲，我们提供了几种方法来完成任务第五项，也就是将T?转换为T的方法。当然，我们不鼓励这样做，并且希望你尽可能长时间留在“非空”的环境中。但有时它根本不可能做得到，多步骤初始化不时发生，特别是对于集合数据结构来说更是如此，因此这必须得到支持。 设想一下，我们有如下的map数据结构： Map&lt;int, Customer&gt; customers = ...; 通过构造，我们知晓了三件事： 1.Map本身不为null；2.其中的int类型的键不为null；3.其中的Customer类型的值也不为null。 我们可以说，索引器实际上返回了null以表示key键不存在。 public TValue? this[TKey key] { get { ... } } 现在我们需要一些方法来检查调用是否成功，对此我们讨论了多种语法。 最容易想到的是“guarded check”： Customer? customer = customers[id]; if (customer != null) { // 这里的customer变量的类型是非null类型Customer } 我承认，我总是对“魔法”类型的强制转换持观望态度。但让我感到恼火的是，当它出现失败时很难弄清楚出了什么问题。例如，如果将c与只持有字面null值的变量进行比较，那么它就不起作用了，但它的语法很容易记住，通常能够发挥作用。 如果值确实为null，则这些检查动态会分派到不同的逻辑上，通常，你只想断言该值为非null并在断言失败则触发放弃。有显式的类型断言运算符可以做到这一点： Customer? maybeCustomer = customers[id]; Customer customer = notnull(maybeCustomer); 除此之外，notnull操作符将类型为T?的任何表达式转换为T类型的表达式。 泛型 泛型很难，因为要考虑多个级别的空值性。考虑如下的代码： class C { public T M&lt;T&gt;(); public T? N&lt;T&gt;(); } var a = C.M&lt;object&gt;(); var b = C.M&lt;object?&gt;(); var c = C.N&lt;object&gt;(); var d = C.N&lt;object?&gt;(); 最基本问题是，a，b，c和d的类型是什么？ 我认为我们最初将其变得比我们需要的更困难，因为C#现有的可空系统非常的古怪，而我们在试图模仿它上面分心太多。不过，好消息是我们终于找到了方向，虽然这还需要一段时间。 为了说明我的所表达的意思，让我们回到这个例子。有如下的两个不同阵营： .NET阵营：a是object，b、c和d是object?； 函数式语言阵营：a是object，b和c是object?，而d是object??。 换句话说，.NET阵营认为你应该将一个或更多?的序列折叠成一个单独的?；而函数式语言阵营，由于了解组合数学的优雅，从而避免了魔法操作，并让整个代码方式也变得如此。 我们最终意识到.NET的路线方式非常复杂，且需要运行时的支持。 函数语言的做法最初会稍微改变一下你的想法。例如，对于前面的map示例： Map&lt;int, Customer?&gt; customers = ...; Customer?? customer = customers[id]; if (customer != null) { // 请注意，这里的customer仍然是“Customer?”类型，并且值依然可以是`null` } 在这个模型中，你需要一次剥掉一层?，但老实说，当你停下来思考为什么需要这么做时，它是有道理的。它更透明，并准确反映了正在发生的事情，因此最好不要排斥它。 在实现上也有问题的。最简单的实现是将T?扩展为一些“包装（wrapper）类型”，如Maybe&lt;T&gt;，然后注入适当的包装和解包操作。实际上，这是实现工作方式的符合心理模型，但存在两个原因，使得这个简单的模型不起作用。 首先，对于引用类型T来说，T?一定不能占用额外的存储空间，指针的运行时表示已经可以以null作为值。并且对于系统语言而言，我们想利用这个事实来与T一样高效地存储T?，这一点通过专门化泛型实例可以相当容易地完成。但也确实意味着非空不再仅仅是一个前端技巧，它现在也需要后端编译器的支持。 （注意，这个技巧不是那么容易能够扩展到T??！） 其次，多亏了我们的可变性注解，Midori得以支持安全的协变数组。但是如果T和T?具有不同的物理表示，那么将T[]转换为T?[]将是非变换操作。但这仅算得上是微小的瑕疵，特别是因为协变数组在插入已有的安全孔后变得不那么有用了。 无论如何，最终我们彻底放弃了.NET的Nullable&lt;T&gt;方式，转向了更多可组合的多?操作符设计。 零初始化 零初始化是真正的痛苦之处，征服它意味着要做到： 必须在构造时初始化类的所有非空字段； 所有非空元素数组必须在构造时完全被初始化。 但它变得更加糟糕。在.NET中，值的类型隐式地被零初始化。因此，最初的规则变成了： 结构的所有字段都必须是可空的。 但是这是臭名昭著的，它会立刻以可空类型污染整个系统。我的假设是，只有可空是不常见的情况（例如20%）中，可空性才真正起作用。而上述的规则会在瞬间毁掉这样的条件。 因此，我们沿着消除自动零初始化语义的道路走了下去，而这却是一个很大的变化。（C# 6选择了允许结构提供零参数构造函数的路径走了下去，并最终因为它对生态系统产生了巨大的影响而不得不支持它） 它本可以很好的工作但是严重地偏离了路线，并引发了一些可能让我们分散注意力的问题。如果我可以再来一次，我会在C#中完全消除了值与引用类型的区别。在即将发布的关于与垃圾回收器做斗争的文章中，这个理由将被阐述的更加清晰。 非空类型的命运 对于非空类型而言，我们有坚实的设计和多个原型，但却从未在整个操作系统中部署非空类型。之所以这样是因为被捆绑在我们期望的C#兼容性水平上，公平地说，我认为这一点最终是我的决定。在Midori的早期，我们所需要的是“认知熟悉度”，而在项目的后期，我们实际上考虑了是否所有功能都可以作为C#的“附加”扩展来完成。正是后来的思维模式阻止了我们认真地完成非空类型。现在，我对此的信念是，可加注解起不了作用，Spec#尝试利用!达到这个目的而极性总是被翻转。非空必须成为默认值才能实现我们想要的影响力。 我最大的遗憾之一就是我们在非空类型上等待了很久，在合约达到相当数量时，我们才对此进行过认真地探索，并且我们注意到了在项目中有数千个requires x != null。它本来是复杂而且高代价的，但如果我们同时确定值类型的区别，这将是相当杀手锏的组合。活到老，学到老！ 如果我们把我们的语言作为一个独立的项目来交付，而不同于C#本身，我相信这会有所成就的。 范围类型 我们有用于向C#添加范围类型的设计，但它总是更进一步超过了我们的复杂性限制。 其基本思想是，任何数字类型都可以给出一个下限和上限的类型参数。例如，假设有一个整型，只能持有数字0到1,000,000之间，那么它可以表示为int&lt;0..1000000&gt;。当然，应该指出的是你可能应该使用uint，所以编译器会对你发出警告。实际上，完整的数字集合可以通过这种方式在概念上表示为范围： typedef byte number&lt;0..256&gt;; typedef sbyte number&lt;-128..128&gt;; typedef short number&lt;-32768..32768&gt;; typedef ushort number&lt;0..65536&gt;; typedef int number&lt;-2147483648..2147483648&gt;; typedef uint number&lt;0..4294967295&gt;; // 等等... 真正出彩但又是可怕的复杂的部分是，使用依赖类型来允许符号范围参数。例如，假设我有一个数组，并希望传入一个索引，其范围保证是在范围之内的。那么通常我会写成： T Get(T[] array, int index) requires index &gt;= 0 &amp;&amp; index &lt; array.Length { return array[index]; } 或者也许我会用uint来消除检查的前半部分： T Get(T[] array, uint index) index &lt; array.Length { return array[index]; } 在范围类型的情形下，我可以直接将数字范围的上限与数组长度相关联： T Get(T[] array, number&lt;0, array.Length&gt; index) { return array[index]; } 当然，如果以某种方式欺骗了编译器的别名分析，则无法保证编译器会消除边界检查，但我们希望这类型的工作不会比正常的合约检查更糟糕，并且老实地说，这种方法是对类型系统中信息的更直接编码。 无论如何，我仍然把这归结为很酷的想法，但是仍然处于“很不错但不是关键性”的范畴内。 由于切片（slice）在类型系统中是一等公民，因此其“非关键”方面是尤其突出的，我可以说66%或更多使用范围检查的情况可以更好地使用切片来编写。我认为主要是人们仍然习惯于拥有它们，因此他们会编写标准的C#而不仅仅是使用切片类型。我将在即将发布的帖子中介绍切片，这样他们在大多数代码中都不再需要编写范围检查。 可恢复错误：类型导向的异常 当然，Abandonment不是唯一的主题，程序中仍然存在程序员可以合理地从中恢复错误的大量合法情况。这样的例子包括： 文件I/O 网络I/O 解析数据（例如，编译器解析器） 验证用户数据（例如，Web提交的表单） 在所有的情况下，你通常不希望在一遇到问题时就触发Abandonment机制，而相反地，该程序在预期上就可能会不时地发生错误，并需要通过一些合理的操作来对其进行处理。这通常通过将错误交给其他对象处理：向网页中输入的用户、系统管理员和使用工具的开发者等等。当然，如果Abandonment是最合适的行为，那么它不失为一种做法，但它通常也被认为是这些情况下最为极为激烈的反应。而且，特别是对于IO，它的存在使系统承担非常脆弱的风险。想象一下，如果你使用的程序在每次网络连接丢包时都因Abandonment而终止，那这简直是不可想象的！ 进入异常 对于可恢复错误，我们使用异常，这里的异常不是那种非检查性的类型，也不是Java那种检查性类型。 首要的原则是：虽然Midori有异常机制，但是一个没有注解为throws的方法永远不会抛出异常，永远永远不会。例如，Midori没有在Java中那种悄悄抛出的RuntimeException，我们无论如何都不需要这样的方式。因为在Java中使用运行时异常的相同情况下，Midori中采用的是Abandonment机制。 这导致产生的系统具有神奇特性：我们系统中90%的函数都不会抛出异常！事实上，默认情况下他们不能，这就与像C++这样的系统形成了鲜明对比。在这些系统中，你必须不遗余力地避免异常并使用noexcept来申明这一事实。当然，API仍可能因Abandonment机制而调用失败，但只有当调用者未能满足所述合约时才会发生，而这一点上类似于向函数传递了错误类型的参数。 我们选择的异常在一开始时就存在争议，我们在团队中融合了命令式、过程式、面向对象和函数式语言的视角。C程序员想使用错误码的方式，并担心我们所做的却是重新创造了Java，或者更糟糕的C#设计。函数式的视角是对所有错误使用数据流，但异常却是十分以控制流为导向的方式。最后，我认为我们选择的是我们所有可用的可恢复错误模型之间的一种妥协。正如我们稍后将看到的，我们确实提供了一种将错误视为一等类型的机制，在这种情况下，开发者想要的是更多的数据流风格的编程。 然而最重要的是，我们在这个模型中编写了很多代码，它对我们来说非常有用。即便是函数式语言的开发者也最终加入进来。多亏了我们从返回码中获得的一些线索，C程序员也加入了。 语言和类型系统 在某个时间点上，我做了一个有争议的观察和决定：正如你不会期望在零兼容性影响条件下更改函数的返回类型一样，你也不应该以这样的期望方式更改函数的异常类型。换句话说，与错误代码一样，异常只是另一种不同的返回值！ 这是针对检查性异常的一个有争议的论点。对此，我的回答可能听起来有点老生常谈，但其实很简单：这太糟糕了。在静态类型的编程语言中，异常的动态性正是它们出问题的地方。我们试图解决这些问题，因此我们拥抱了该决定，用于为强类型提供辅助，并再也没有回头过。仅此一点就有助于弥合错误码和异常之间的鸿沟。 函数抛出的异常成为其签名的一部分，就像参数和返回值一样。请记住，由于异常与Abandonment相比的不常见性，这一点也并不像你想象的那么痛苦，并且很多直观的属性也自然而然地也从这个决定中衍生出来。 因此，首要的原则就是Liskov替代原则：为了避免在C++中所发现的混乱，所有的“检查”必须在编译时静态发生。因此，WG21的文章 中提到的所有这些性能问题对我们来说都不再是问题。这种类型的系统必须是可以抵御攻击的，没有后门可以攻陷它，因为我们需要依赖于优化编译器中的throws来解决这些性能挑战，所以类型安全取决于该属性。 我们尝试了许多不同的语法。在我们致力于改变语言之前，我们使用C#属性和静态分析完成了所有工作，但是这种方式的用户体验不是很好，并且很难用这种方式实现一个真正的类型系统。此外，感觉它太简单了。我们尝试了Redhawk项目中，也就是最终成为.NET Native和CoreRT的方法。然而，尽管这种方法与我们的最终解决方案有许多类似的原则，但它也没有利用语言而仅仅是依赖于静态分析。 最终语法的基本要点是，简单地通过单个bit来声明throws方法： void Foo() throws { ... } （多年来，我们实际上把throws放在了方法的头部位置，但那没有区别） 在这一点上，可替代性问题非常简单，有throws的函数不能代替无throws的函数（这叫做非法加强）；而另一方面，无throws的函数可以代替有throws的函数（合法弱化）。而这显然会对虚拟覆盖、接口实现和lambda带来影响。 当然，我们做了所期望的协同和逆变替代等华而不实的功能。例如，如果Foo是虚拟函数并且它被没有抛出异常的函数覆盖，则不需要再声明throws。当然，虚拟地调用这样一个函数的任何调用者都无法利用这个功能，但直接调用却是可以的。 例如，下面的代码是合法的： class Base { public virtual void Foo() throws {...} } class Derived : Base { // 特定的实现不需要throws关键字： public override void Foo() {...} } Derived的调用者可以利用无throws的条件，而反之则是完全非法的： class Base { public virtual void Foo () {...} } class Derived : Base { public override void Foo() throws {...} } 对单一故障模式的鼓励是相当自由的。Java的检查性异常带来的大量复杂性将立即消失。如果你观察大多数调用失败的API，它们无一例外都有单一的故障模式（一旦Abandonment处理完成所有bug故障模式），这包括IO故障，解析失败等等。开发者倾向于编写的许多恢复操作，实际上并不依赖于在做IO时究竟哪些地方出现故障的具体细节。（有些操作会这样做，对于它们来说，守护者模式通常是更好的方案，等一下就会有关于这个守护者模式的更多内容）。现代异常中的大多数信息实际上并不适合程序使用，而相反它们是用于诊断的。 我们坚持这种“单一故障模式”有2到3年，最终我做出了支持多种故障模式的有分歧的决定。这种情况虽然并不常见，但是这样的请求经常会从团队成员中涌现出，而这些使用情景似乎是合法且有用的。它确实是以类型系统的复杂性为代价的，但仅限于所有常见的子类型方式。在更复杂的，例如中止场景中（包括后面的更多场景），则要求我们这样做。 语法如下所示： int Foo() throws FooException, BarException { ... } 从某种意义上说，单个throws是throws Exception的快捷方式。 如果你不在乎的话，很容易“忘记”额外的细节。例如，你可能希望将lambda绑定到上面的FooAPI中，但不希望调用者关心FooException或BarException。当然，lambda必须标记为throws，但不需要更多细节。这被证明是一种非常常见的模式：内部系统会使用类似的类型异常来进行内部控制流和错误处理，但是将它们全部转换为API的公共边界上的普通throws时，其中额外的细节是非必需的。 所有这些额外的类型为可恢复的错误增加了强大的功能。但是如果合约的数量超出了异常数量的10倍，那么简单的throws异常方法的数量也将超过了多故障模式方法数量的10倍。 在这一点上，你可能会疑惑的是，这与Java的检查性异常有何区别？ 大部分错误使用Abandonment表达方式的事实意味着大多数API都没有抛出； 我们鼓励单一故障模式的事实大大简化了整个系统；此外，还可以轻松地从多种模式过渡到单一故障模式，并再次回到多种模式。 利用丰富的类型系统支持弱化和强化也有帮助的，正如我们所做的其他事情一样，也有助于缩小返回码和异常之间的差距，提高代码可维护性等等…… 易于审核的调用点（Callsite） 在整个故事叙述到这个时候，我们仍然没有实现错误码的完整显式语法。函数的声明说明它们是否可能出现故障（好的方面），但这些函数的调用者仍然继承静默的控制流（坏的方面）。 这给我带来了异常模型中最喜欢的一些东西。调用点需要声明try： int value = try Foo(); 这将调用函数Foo，如果发生错误则传播其错误，否则将返回值赋值给value。 它有一个很不错的属性：所有控制流在程序中都是显式的。你可以将try视为条件return（如果你愿意，也可以认为是条件throw）。我非常喜欢这种让代码审查错误逻辑变得更容易的方式！例如，设想有一个长函数，里面有数个try语句，具有显式注释使得失败点成为控制流，因此易于选择return语句： void doSomething() throws { blah(); var x = blah_blah(blah()); var y = try blah(); // &lt;-- 啊哈！可能产生故障的调用！ blahdiblahdiblahdiblahdi(); blahblahblahblah(try blahblah()); // &lt;-- 另一个可能产生故障的调用！ and_so_on(...); } 如果你的编辑器中有语法高亮，那么try将是蓝色粗体的，这样的话就更好了。 这提供了许多返回码的强大好处，却没有它的所有包袱。 （Rust和Swift现在都支持类似的语法。我不得不承认，我对于我们没有在几年前将这种语法交付给公众而感到难过。它们的实现方式非常不同，但对此的考虑给它们的语法带来了很大的信心。） 当然，如果你正在尝试这样对如此抛出的函数采取try方法，就有一下两种可能： 异常从被调用函数中逃逸出来； 周围有一个try/catch块来处理错误。 在第一种情况下，你也需要对你的函数声明throws。当然，是传播由被调用函数声明的强类型信息，还是利用单个throws位，这是由你来决定的。 在第二种情况下，我们当然理解所有的输入类型信息，因此，如果你尝试捕捉未声明被抛出的内容，我们可能会给你一个dead code的错误，这是与传统异常系统的另一个有争议的背离。它总是提示我catch（FooException）本质上隐藏了动态类型测试。 你是否会默默地允许调用仅返回object的API，并自动将这个返回值分配给具有类型的变量？那一定是不行的！ 因此，我们也不会让你在异常上这样做。 CLU也对我们产生了影响，Liskov在一篇关于CLU历史的文章中谈到： CLU在对待未处理的异常方面的机制是不寻常的。大多数机制都通过这样的方式传递：如果调用者没有处理被调用过程引发的异常，则异常将传播给它的调用者，依此类推下去。而我们拒绝使用这种方法，因为它不符合我们关于模块化程序构建的思想。我们希望能够通过只需知道其规范而不是其实现的方式来调用过程，但如果异常自动地传播下去，则过程可能会触发其规范中未描述的异常。 虽然我们不鼓励大范围的try块，但这是在概念上传播错误码的快捷方式。如果要了解我的意思，请考虑在具有错误码的系统中你是怎么做的，比如在Go中，你可能会写出如下的代码： if err := doSomething(); err != nil { return err } 而在我们的系统中，你需要这样编码： try doSomething(); 但你可能会说，我们使用了异常，这是完全不同的！当然，运行时系统会不一样，但从语言“语义学”的角度来看，它们其实是同构的。我们鼓励人们根据错误码来思考，而不是他们所熟悉和喜爱的异常。这可能会有点意思：你可能想知道，为什么不使用返回码？在接下来的部分中，我将描述真正的场景的同构，以试图说服你我们的选择。 语法糖 我们还提供了一些处理错误的语法糖。try/catch块作用域结构有点冗长，特别是如果你尽量局部地遵循我们处理错误的预期最佳实践。对于某些地方来说，它仍然不幸地保留了一些goto的感觉，特别是如果就返回码考虑而言。这种方式让位于我们称为Result&lt;T&gt;的类型，它只是一个简单的T值或Exception。 对于数据流来说更自然的场景中，这基本上是从控制流世界到数据流世界之间的桥梁，虽然大多数开发者更喜欢熟悉的控制流语法，但两者肯定都有自己的一席之地。 为了说明常见的用法，假设你希望在重新传播异常之前记录发生的所有错误，虽然这是一种常见的模式，但使用try/catch块会让我觉得有点过于控制流式： int v; try { v = try Foo(); // 或许有更多的语句... } catch (Exception e) { Log(e); rethrow; } // 使用v值... “或许有更多的语句”位置处会吸引你在try块处挤进应该比更多的东西，将此与使用Result&lt;T&gt;进行比较，从而产生更多的返回码感觉和更方便的本地处理： Result&lt;int&gt; value = try Foo() else catch; if (value.IsFailure) { Log(value.Exception); throw value.Exception; } // 使用值`value.Value` ... 作为对故障的响应，try/else构造还允许你替换成自己的值，甚至触发Abandonment机制： int value1 = try Foo() else 42; int value2 = try Foo() else Release.Fail(); 我们还通过从Result&lt;T&gt;中抽取成员T的访问来支持NaN样式的数据流错误的传播。例如，假设有两个Result&lt;int&gt;，并希望对它们求和，那么我可以这样做： Result&lt;int&gt; x = ...; Result&lt;int&gt; y = ...; Result&lt;int&gt; z = x + y; 注意第三行，我们将两个Result&lt;int&gt;加到一起，没错是的，产生了第三个Result&lt;T&gt;。这是NaN风格的数据流传播，类似于C#的.?新功能。 我发现这种方法是异常、返回码和数据流错误传播的优雅混合。 实现 我刚才所描述的模型不必用异常来实现，因为它已经足够抽象，可以使用返回码来合理地实现。这不仅仅是理论上可行性，我们实际上就这么尝试过，这也是导致我们出于性能原因选择异常而不是返回码方式的原因。 为了说明返回码实现是如何工作的，设想如下的一些简单的转换： int foo() throws { if (...p...) { throw new Exception(); } return 42; } 变成: Result&lt;int&gt; foo() { if (...p...) { return new Result&lt;int&gt;(new Exception()); } return new Result&lt;int&gt;(42); } 以及，该代码： int x = try foo(); 变成如下的代码： int x; Result&lt;int&gt; tmp = foo(); if (tmp.Failed) { throw tmp.Exception; } x = tmp.Value; 优化编译器可以对其进行更有效地表示，特别是通过内联，消除了过多的复制操作。 如果你通过goto的方式尝试以同样的方式来对try/catch/finally进行建模，你会很快看到为什么编译器在存在非检查性异常时很难进行优化，所有都隐藏在控制流的边缘上！ 无论以哪种方式，这个例子都非常生动地展示了返回码的缺点。所有的跳转语句都处在热路径上，但它们其实是很少需要的（当然，假设故障是罕见的），并混淆你程序的黄金路径上的性能，因此违反了我们最重要的原则之一。 我在上一篇文章中描述了我们双模式实验的结果。总之，由于以下几点，异常方法在我们的关键基准测试中，以几何平均的方式，代码缩小了7％，速度提高了4％： 没有给调用约定带来影响； 没有与包装返回值和调用者分支相关联的“花生酱”开销； 所有抛出函数在类型系统中都是已知的，从而实现更灵活的代码移动； 所有抛出函数在类型系统中都是已知的，为我们提供了新颖的异常处理优化；例如在try无法抛出时将try/finally块转换为直接代码。 还有其他方面的异常也有助于提高性能。我已经提到过，我们并没有像大多数异常系统那样使用调用点来收集元数据，并将诊断留给了诊断子系统。然而，另一个常见的模式是将异常缓存为冻结对象，因此每次throw都不需要再次分配： const Exception retryLayout = new Exception(); ... throw retryLayout; 对于具有高概率抛出和捕获的系统，例如我们的解析器，FRP UI框架和其他领域来说，这对于良好的性能至关重要，这也说明了为什么我们不能简单地将“异常很慢”视为理所应当的。 模式 许多有用的模式被用于修饰我们的语言和库。 并发 早在2007年，我就写了关于并发和异常的注解的文章，虽然当时我主要是从并行共享内存计算的角度，但是所有并发编排模式都存在类似的挑战。基本的问题是单一顺序栈和单一故障模式的假设下来实现异常的方式，而在并发系统中，存在许多类型的栈和多种故障模式，可能会有0个，1个或多个模式“同时”发生。 Midori所做的一个简单改进就是，确保所有与Exception相关的基础架构处理具有多个内部错误的情况，至少那时程序员没有被迫决定，像今天大多数异常系统所鼓励的那样，抛弃故障信息。然而，更重要的是，由于我们的异步模型以及其交互方式，调度和堆栈基础架构从根本了解cactus stack（仙人掌堆栈）。 起初，我们并不支持跨异步边界的异常，但最终我们还是在跨异步进程边界上，扩展了声明throws以及可选类型化异常子句的能力。这为异步actor编程模型带来了丰富的类型化编程模型并感觉这就像是一种自然的扩展，而这一点从CLU的继任者Argus那里获得的灵感。 我们的代码诊断基础设施对其进行了修饰，以便为开发者在栈视图中提供全面的跨进程因果关系调试体验。cactus stack不仅在高度并发的系统中存在，而且它们经常在进程消息传递边界上出现，以这种方式调试系统可以节省大量时间。 中止 有时一个子系统需要彻底从故障的环境中摆脱出来。因此Abandonment也是一种选择，但它也只应为应对bug而存在，并且在进程中没有什么可以阻止它。但如果我们想要退回到调用栈的某个点上，并已知栈中没有其他会阻止我们，然后恢复并继续在同一个进程中运行的话，那又会怎么样呢？ 对于这种情况，异常更接近于我们所想要的。但不幸的是，栈上的代码可以捕获正被抛出中的异常，从而有效地抑制中止的发生。因此，我们想要的是一些不可被抑制的构造。 接着来聊聊中止（Abort）。我们发明中止主要是为了支持我们使用函数反应式编程（FRP）的UI框架，而FRP模式本身将会在未来的几篇文章中出现。当FRP重计算（recalculation）发生时，事件可能会进入系统，或者新的发现出现，从而使当前的重计算失效。通常这种情况都深埋在用户和系统代码交织的计算中，如果这种情况发生，FRP引擎需要快速返回其堆栈顶部，以便可以安全地开始重计算。由于堆栈上的所有用户代码都是纯函数式的，因此在流的中途进行中止很容易做到，并且不会留下任何导致错误的副作用。并且多亏了类型化异常，所有遍历的引擎代码都经过审核和彻底修改，以确保和维护不变性。 中止的设计借用了权能的设计。首先，我们引入了一种名为AbortException的基础类型，它可以直接或以子类继承的方式使用。但它有一点却是特殊的：在他被捕获后就无法再被忽略掉，在尝试捕获它的任何catch块的末尾都会自动重新抛出该异常。因此，我们可以说这种异常是不可否认的。 但总得有代码去捕捉abort。为此，整体的想法就是离开所处的上下文，而像Abandonment一样销毁整个进程，所以这就是权能发挥作用的地方。下面是AbortException的基本样子： public immutable class AbortException : Exception { public AbortException(immutable object token); public void Reset(immutable object token); // 省略掉其他不关心的成员... } 请注意，在调用构造函数时，需提供不可变的token，而为了抑制抛出的异常，需调用Reset，并且必须提供相匹配的token，一旦token不匹配，则会触发Abandonment。这里的想法是，abort的抛出和预期的捕获方通常是相同的，或者至少是彼此相关联，所以这样可以容易地安全地彼此共享token。所以这是对象作为不可伪造的权能，在实践中一个很好的例子。 是的，栈上的任意一段代码都可以触发Abandonment，但是这样的代码已经可以简单地通过解引用null来实现。该技术禁止在尚未准备好的情况下中止上下文中的代码执行。 其他框架具有类似的模式，.NET Framework中有ThreadAbortException类型的异常，除非你调用Thread.ResetAbort，否则它也是不可否认的。但遗憾的是，由于它不基于权能，因此需要使用安全注释和托管API的笨拙组合来阻止Abort被透明地意外处理。并且更常见的情况是，这是未经检查的异常。 由于异常是不可变的，并且上面的token也是不可变的，因此常见的模式是将这些它们缓存在静态变量中并以单例的方式使用。例如： class MyComponent { const object abortToken = new object(); const AbortException abortException = new AbortException(abortToken); void Abort() throws AbortException { throw abortException; } void TopOfTheStack() { while (true) { // 调用函数，使得调用栈变得很深， // 在调用栈深处位置可能会发生Abort，这里进行捕获并将其重置： let result = try ... else catch&lt;AbortException&gt;; if (result.IsFailed) { result.Exception.Reset(abortToken); } } } } 这种模式使Abort非常高效，平均下来FRP的重计算会发生多次Abort。请记住，FRP是系统中所有UI的主干部分，因此出现通常归因于异常的缓慢显然是不可接受的。由于随之而来的GC压力，即使异常对象的分配也是一件不幸的事。 可选的“Try”API 我提到过因故障而导致Abandonment的操作，这包括分配内存，算术溢出或除零等。在其中一些实例中，一部分适用于动态错误传播和恢复，而不是Abandonment，即使在通常情况下Abandonment是更好的选择。 结果证明这是一种模式，虽然不是非常普遍，但它确实出现了。因此，我们有使用数据流方式传播溢出、NaN或任何数量的可能发生的错误的一整套算术API。 我之前已经提到了一个具体的实例，即当OOM产生可恢复的错误而不是Abandonment时，能够通过try new尝试进行新的分配。这种情况非常罕见，但如果你想为某些多媒体操作分配一个大缓冲区时，它可能会发挥作用。 守护者 我将介绍的最后一个模式，叫做守护者（keeper）模式。 在很多方面，处理可恢复异常的方式是“由内而外”的：调用一堆代码，在调用栈中传递参数，直到最后达到一些被认为是不可接受的状态。在异常模型中，控制流而后在调用栈中向上传播并展开，直到找到处理对应错误的代码。这个时候如果需要重试，则必须进行重新调用。 另一种供选择的模式是使用keeper。keeper是一个知道如何在“原地”从错误中恢复的对象，因此就不再需要展开调用栈，而只需要抛出异常的代码询问keeper如何处理异常，keeper则告知代码如何继续执行。Keeper的很好的优势是，当作为配置的功能时，代码甚至不需要知道它们存在，在这一点上，不像我们的系统中必须被声明为类型系统的一部分的异常。除此之外，Keeper的另一个优势是它们简单而开销较低。 Midori中的Keeper可以被用作快速操作，但更常见的用法是作为跨越异步边界的异常。 Keeper的规范化示例是保护文件系统的操作，访问文件系统上的文件和目录通常具有以下的一些故障模式： 无效的路径规范 文件未找到 目录未找到 文件正在使用 权限不足 媒体已满 媒体写保护 一种选择是使用throws子句为每个文件系统API进行注解，或者，像Java一样，创建一个IOException类型的层次结构，每种故障都作为其子类而存在。另一种方法是使用Keeper模式，它可以确保整个应用程序无需知道或关心IO错误，也允许集中式地恢复逻辑。这样的keeper接口可能像如下的形式： async interface IFileSystemKeeper { async string InvalidPathSpecification(string path) throws; async string FileNotFound(string path) throws; async string DirectoryNotFound(string path) throws; async string FileInUse(string path) throws; async Credentials InsufficientPrivileges(Credentials creds, string path) throws; async string MediaFull(string path) throws; async string MediaWriteProtected(string path) throws; } 当发生故障时，在每种情况下相关输入被提供给keeper，然后keeper执行可能异步的操作以进行恢复, 在许多情况下，keeper可以选择返回操作更新后的参数。例如，InsufficientPrivileges可以返回将会用到的Credentials （也许这时程序会提示用户，然后用户切换到具有写访问权限的帐户上）。在以上显式的每种故障情况中，一种可选的操作是，如果keeper不想处理该错误，则可以继续采取抛出异常的方式。 最后，注意到的是Windows的结构化异常处理（SEH）系统支持“可持续（continuable）”的异常，这种异常在概念上试图实现同样的目的，它们让一些代码决定如何重新启动错误的计算。不幸的是，它们是在调用栈上使用环境处理程序上完成的，而不是作为语言中的一等对象，因此它远不如keeper模式那么优雅，而且更容易出错。 未来方向：效果类型化 大多数人问我们是否将async和throws作为类型系统的属性分叉到整个库环境中，我对此的答案是，“不，这不是真的”。但在高度多态的库代码中这样肯定是痛苦的。 最令人震惊的例子是组合类型，如map、filter和sort等。在这些情况下，你经常有任意函数，并希望这些函数的async和throws属性透明地“传播”。 我们必须解决的设计是让你对效果进行参数化。例如，现在有一个通用的映射函数Map，它传播其func参数的async或throws效果： U[] Map&lt;T, U, effect E&gt;(T[] ts, Func&lt;T, U, E&gt; func) E { U[] us = new U[ts.Length]; for (int i = 0; i &lt; ts.Length; i++) { us[i] = effect(E) func(ts[i]); } return us; } 请注意，我们有一个普通的泛型类型E，除了它的声明以关键字effect为前缀之外。然后除了在调用func时通过 effect(E)在“传播”位置使用它之外，我们象征性地使用E来代替Map签名的效果列表。这是一个非常简单的替代操作，用effect(E)替换try，以及用E替换throws，来看看逻辑的转换。 一种合法的调用如下： int[] xs = ...; string[] ys = try Map&lt;int, string, throws&gt;(xs, x =&gt; ...); 请注意，这里的throws已经透明地传播下去，因此我们可以传递一个抛出异常的回调。 总而言之，我们将上述的讨论更进了一步，并允许程序员声明任意的效果。我以前曾经对这种类型的系统做过假设，然而我所担心的是，无论它多么强大，这种高阶编程都可能是过度的精巧且难以理解。但上述的简单模型应该会是有意义的，我想如果多几个月时间，我们会将其加以实现。 回顾与总结 我们已经来到了这段特殊旅程的终点，正如我在一开始所说的，最终是一个相对可预测和温和的结果。通过我们对错误的情况进行分类的基本原则，希望所有这些背景都能帮助你完成项目中错误处理的进化。 总之，最终的模型具有以下的特点： 一种假设细粒度隔离和从故障中的可恢复性的体系结构； 区分bug和可恢复的错误； 使用合约、断言、以及面向所有bug的更通用的Abandonment； 对于可恢复的错误，使用向下精简的，具有丰富的类型系统和语言语法的检查性异常模型； 采用返回码的有限的某些特性，比如局部检查，以提高可靠性。 虽然这是一个多年的旅程，但我们一直致力于多个领域中积极努力的改进，直到我们的项目过早地夭折。因为我们没有使用它们的足够经验以宣称获得了成功，所以我对它们进行了不同的分类。如果能走得更远，我希望我们能将大部分内容整理出来并将它们交付出去。特别地，我想把下列原则放到最终模型的类别中： 默认情况下，利用非空类型可以消除大量的可空性注解。 Abandonment以及我们对它的使用程度，在我看来是在错误模型上最大和最成功的赌注。我们进程很早地发现bug，它们是最容易诊断和修复的，基于Abandonment的错误数量超过可恢复错误的比例接近10:1，因此，这样使得检查性异常很少出现并且可以被开发者所容忍。 虽然从未有机会将这些项目发布出来，但我们已经将其中的一些经验教训带到了其他的项目中去。 例如，在从Internet Explorer重写Microsoft Edge浏览器期间，我们在一些区域采用了Abandonment机制。由Midori的工程师处理的一个关键领域是OOM。如前所述，旧代码会艰难地执行，并且几乎总是会出现错误，而Abandonment发现了许多潜伏的错误，就像我们常常在Midori中移植现有代码库时所经历的那样。更重要的是，Abandonment更多的是一种架构上的原则，可以在编程语言的现有代码库中所采用。 细粒度隔离的架构基础至关重要，但许多系统都有这种架构的非正式概念。面向OOM的Abandonment机制在浏览器中运行良好的原因是，大多数浏览器已经将单独进程专门用于各个选项卡，浏览器正以多种方式模仿操作系统的行为，并且在这里我们也看到了同样的情况。 最近，我们一直在探索将这些，包括合约在内的原则带到C++的提议，另外还有一些将这些功能带到C#中的具体提议，我们还正在积极地迭代出给C#带来一些非空检查的提议。我不得不承认，我希望所有这些提案都是最好的，但是没有一个能像在同一个错误规则中写入整个栈那样具有防弹性。请记住，整个隔离和并发模型对于大规模Abandonment至关重要。 我希望继续分享这些知识，使得能够更广泛地采用其中的一些想法。 当然，我已经提到，Go、Rust和Swift在此期间为业界提供了一些非常好的有关系统的错误模型。我们的设计可能会在各个地方有一些微小的瑕疵，但现实情况是，这些语言（Go、Rust和Swift）所诞生的环境，已经超出了在我们开始Midori之旅时在行业中所具有的环境。所以现在正是成为一名系统程序员的好时机！ 下一次我会更多地谈谈这门语言，具体来说将会看到Midori是如何利用架构、语言支持和库的万能钥匙来驯服垃圾收集器的（译者注：实际上作者后文中并没有写到GC）。我希望很快能和你们再次见面！]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Midori</tag>
        <tag>翻译</tag>
        <tag>编译</tag>
        <tag>错误模型</tag>
        <tag>语言设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Midori博客系列翻译（4）——安全的原生代码]]></title>
    <url>%2F2019%2F02%2F17%2Fmidori%2F4-safe-native-code%2F</url>
    <content type="text"><![CDATA[在我的第一篇Midori文章中，我描述了安全是我们所做的一切的基础。 我提到我们使用安全代码构建了操作系统，但仍然保持与使用C和C++编写的Windows和Linux等操作系统相比有竞争力的性能。 系统架构在许多方面发挥了关键作用，关于这点我将在未来的帖子中继续讨论。 但是，在系统的基石部分，一个从“托管”的，强类型的和内存安全的源代码中榨取原生代码性能的优化编译器，是我们最重要的武器之一。 在本篇文章中，我将就此描述一些对我们成功至关重要的关键思考和技巧。 概览 当人们想到C#，Java及相关语言时，他们通常会想到Just-In-Time（JIT）编译，尤其是在Midori开始的2000年代中期。 但是Midori却采用了不同的方式，它一开始便使用类C++的Ahead-Of-Time（AOT） 编译方式。 与C和C++相比，AOT编译托管的垃圾回收代码)存有一些独特的挑战。 因此，许多关于AOT的努力与其对应的原生代码相比并没有获得相匹配的性能，.NET的NGEN技术就是一个很好的例子。实际上，.NET中的大部分工作都专门针对于启动时间再进行优化，这显然是算的上一个关键指标。但是当构建一个操作系统及其之上的所有模块时，启动时间几乎仅仅只是皮毛而已。 在8年的时间里，我们显著地缩小我们版本的C#与经典C/C++系统之间的差距，当同时在两个不同的速度维度上利用现有的任务上比较Midori的性能时，基本的代码质量都很少成为决定性因素。事实上，反直觉的事情发生了——协同设计语言、运行时、框架、操作系统和编译器的能力——使得在一个方面上的折衷可以在其他方面获得优势，这也为编译器提供了比以往更多的关于程序语义的符号信息。因此，我敢说，我们的语言能够在相当多的情况下超过C和C++的性能。 在深入探究编译器之前，我必须有所提醒。架构上的决策，如无处不在的Async和（即将推出的）Zero-Copy IO（零拷贝IO）文章，在“整个系统”级别缩小性能差距上与我们更加相关， 特别是在我们编写缺乏GC的系统代码时。但是，高度优化的编译器打下的基础，了解并利用其安全性，对我们的结果至关重要。 如果我没有指出这个领域中其他团队与我们同时取得了巨大进展的工作，那么会是我的失职。这里的进展包括，Go语言跨越了系统性能和安全性之间的优雅界限；另外，Rust在这方面也做的很棒。 .NET Native和相关的Android Runtime 项目以更强限制的方式为C#和Java带来了AOT编译，并将其作为一种“静默”优化技术，以避免在移动应用程序上由JIT引起的延迟。 最近，我们一直致力于通过CoreRT项目以广泛地方式将AOT带入.NET环境中，通过这项努力，我希望我们能够将下面的一些经验教训带到真实世界的编程环境中。 虽然由于突破性变化之间的微妙平衡，我们还能走多远还有待观察，然而，我们花了几年时间，数十人年的工作量，才能使所有事情和谐有序地工作，因此这种知识的转移需要一定的时间。 首先，让我们简要地回顾一个问题：原生代码和托管代码之间到底有什么区别？ 相同点 由于我对将“原生和托管”进行错误的二分的方式有所鄙夷，因此我必须为使用这种说法而道歉。在阅读完这篇文章后，我希望能说服你它们其实是连续统一体。 C++现在比以往任何时候都更安全，同样地，C#表现地更好。 有趣的是，这些大量的教训直接适用于我们团队最近在安全C++上所做的工作。 所以让我们首先讨论它们的共同点。 所有龙书中的基础主题，只要适用于原生代码，对于托管代码都同样适用。 通常，编译代码的过程是下列两种行为的平衡，一方面为目标体系结构产生最高效的指令序列，以快速执行程序；另一方面，为目标体系结构发出最小的指令编码，以便在目标设备上紧凑且有效地使用存储系统来存储程序。 你最喜欢的编译器上存在无数个旋钮，可根据你的场景在两者之间进行切换。 或许在移动设备上，你需要更小的代码体积，而在多媒体工作站上，可能需要最快的代码。 选择托管代码不会改变这种平衡关系的任何地方，你仍然需要相同的灵活性。 在C或C++编译器中用于实现此目的的技术基本上与用在安全语言的技术相同。 你需要一个出色的内联器，同时还需要公共子表达式消除（CSE）、常量传播和折叠，强度折减以及出色的循环优化器。 目前，你可能还希望使用静态单赋值形式（SSA）和一些独特的SSA优化方法，如全局值编号（尽管在任何地方使用SSA时都需注意工作集和编译器的吞吐量）。 除此之外，对你来说很重要的目标体系结构，还需要专门的机器相关的优化器，包括寄存器分配器等。 最后，你还需要一个进行过程间优化的全局分析器，以跨pass的方式来扩展过程间优化的链接时代码生成，和现代处理器的矢量化器 （SSE，NEON，AVX等），以及可根据实际情况通知所有以上优化部件的配置文件引导优化（PGO）。 虽然拥有一种安全的语言可以以一种独特而有趣的方式带来意想不到的变化，对此我将在下面进行介绍，但你同时也需要所有以上这些标准的编译器优化方法。 虽然我讨厌这样说，但在所有这些优化技术上做得很好就是你的“筹码”。早在2000年代中期，我们不得不以手工方式实现所有这些方法。 值得庆幸的是，现在已经有现成的非常棒优化编译器，如LLVM，其中大部分的功能已经通过了测试，并随时准备帮助你进行改进。 不同点 但当然，托管和原生在许多地方是存在差异的，否则，这篇文章也不会很有趣。 差异更多体现在优化器所生成的代码和数据结构的“形状”上，这些“形状”如下的形式出现：不同的指令序列、不存在对应C++等价代码的逻辑操作（如更多的边界检查）、数据结构布局差异（如额外的对象头信息或接口表）以及最大的不同之处在于大量的支撑运行时的数据结构。 与C语言中的简单的数据类型相比，对象在大多数托管语言中都有“比实际更大的体积”（请注意：C++数据结构并不像你想象的那样简单，并且可能比你的直觉更接近于C#）。在Java中，每个对象的头部中都有一个vtable指针，而在C#中，尽管结构除外，但大多数情况也都是如此。 GC可以对布局施加额外的限制，例如填充和增加几个字节来于记录信息。 请注意，这些都不是特定于托管语言的特征——C和C++分配器也可能注入额外的信息，当然，许多C++对象也都带有vtable。但是可以公正地说，大多数C和C++在这些方面的实现上往往更经济。 在大多数情况下，出于文化不是技术原因，在堆中添加几千个对象，尤其是当系统由带有隔离堆空间的大量轻量级进程（如Midori中）组成时，内存消耗会快速增加。 另外，在Java中有更多的虚拟调度（virtual dispatch），因为默认情况下方法都是虚拟的，而在C#中，幸运的是，默认情况下方法是非虚拟的（我们甚至默认将类密封）。太多的虚拟调度完全可以内联化，而这对于小型函数来讲也是关键的优化技术。 在托管语言中，代码则倾向于具有更多的小型函数，其原因出于以下两个：1）属性值；2）更高级别的程序员倾向于过度使用抽象。 尽管很少有这方面的形式化描述，但也存在“ABI”（应用程序二进制接口）用于管理代码和运行时之间的交互。 ABI可以看做是车辆与道路之间接触部分，它包含了调用约定，异常处理，尤其是机器代码中的GC清单（manifest）。 虽然这不是托管代码所特有的概念，比如C++同样存在运行时和ABI， 只是C++中主要由对象头部信息，以及像分配器这样的库等组成，并以更透明的方式链接到程序，而不像传统的C#和Java的虚拟机，其运行时却是不可协商的（JIT情况下也是相当粗暴的）。 由于托管代码和C++的同构关系突然变得明显起来，因此以这种方式思考对我来说是有帮助的。 真正的大问题是数组边界检查。传统的做法是在访问索引之前检查索引是否在数组范围内，以便加载或存储，因此存在一个额外的字段提取、比较和条件分支。当前的分支预测已经做的相当不错，但存在一个简单的道理是：如果你想完成更多的工作，则需要更大的开销。 有趣的是，我们在C++的array_view&lt;T&gt;上所做的工作会产生所有这些相同的开销。 与此相关的是，还需要对托管代码中不存在于C++的null类型进行检查。 例如，如果在C++中对空对象指针执行方法调度，则无论如何都会运行该函数，但如果该函数试图访问this，则它将会产生内存错误，但在Java和.NET中，编译器需要（根据规范）甚至在调用发生之前，显式地进行检查，并在这些情况下抛出异常。这些细小的分支同样可以叠加到一起，而我们将根据optimized编译版本的C++语义消除这样的检查。 在Midori中，我们在编译中默认使用溢出检查，这与现行的C#中必须为此行为显式传递/checked标志有所不同。 根据我们的经验，捕获的意外和无意的溢出的数量，相比于带来不便和开销来讲是非常值得的，但这确实意味着我们的编译器需要非常善于理解如何消除不必要的检查。 另外，在Java和.NET中，静态变量开销非常大，甚至超出了你所期望的。 由于它们是可变的，因此不能存储于用作进程间共享的可执行文件只读段中。 而且令人惊讶的是，被注入到生成代码中的延迟初始化检查数量超出了你的想象。虽然从.NET的preciseinit切换到beforefieldinit语义能够带来一些帮助，因为每次访问静态成员都不需要再进行检查，而只需检查可能有问题的静态变量，但与精心设计的，具有常量和定向的全局初始化的C程序相比，它仍然具有很大的开销。 最后的主要内容则特定于.NET：结构。 虽然结构有助于缓解GC压力，这对大多数程序来说都是好事，但它们也带有一些微妙的问题。 例如，CLI指定了初始化时一些奇怪的的行为，例如如果在构造期间发生异常，则结构的空位必须初始化为全零，其结果导致大多数编译器都需制作防御性的副本。 而另一个相似的例子是，只要调用readonly结构上的函数，编译器就必须制作防御性副本。 将结构复制到整个其他地方是非常常见的，因此当你计算程序执行周期数时则会出现偏差，尤其是因为它通常意味着花费在memcpy中的时间开销，我们提出了很多技术解决这个问题。有趣的是，当所有问题被提出和解决时，我很确定的一点是，考虑到它的RAII，复制构造函数，析构函数以及开销等所有因素，我们的代码质量是优于C++的。 编译架构 我们的架构涉及到三个主要的部件： C#编译器：执行词法分析，语法解析和语义分析，最终将C#源代码文本转换为基于CIL的中间表示（IR）。 Bartok：以前一阶段的IR作为输入，进行基于MSIL的高层次分析，转换和优化，最后将IR削弱到更具体的机器表示形式。例如，当Bartok处理完IR时，泛型就已不存在了。 Phoenix：以前一阶段的低层次IR作为输入进行频繁的处理。这就是大多数“把油门踩到底”的相关优化的地方，其最后输出的结果是机器代码。 这与Swift编译器的设计（特别是SIL）的相似之处是显而易见的，.NET Native项目也在某种程度上体现了这种架构。坦率地说，大多数高级语言的AOT编译器都是如此。 在大多数地方，编译器的内部表示都利用了静态单赋值形式（SSA），SSA形式一直保持到编译的最后阶段，这促成并改进了前面提到的许多经典编译器优化的使用。 该架构的目标包括： 促进快速原型设计和实验； 生成与商业C/C++编译器相当的高质量机器代码； 支持调试优化的机器代码以提高生产率； 基于采样和检测代码，提升配置文件引导优化； 适合自托管（self-host）： 生成的编译器编译足够快； 足够快，因此编译器开发人员乐于使用它； 当编译器出现bug时，很容易对问题进行调试。 最后是一个简要警告：我们进行了很多方面的尝试，多到我已无法全部回忆起来。在我参与之前，Bartok和Phoenix都已存在多年： Bartok是托管语言研究的温床，其包含从优化到GC再到软件事务内存的各个方面；而Phoenix本来是作为取代已发布的Visual C++编译器而存在。 所以，无论怎样我都无法讲完所有的故事，但我会尽我所能。 优化 让我们深入研究一些扩展到涵盖安全代码的经典编译器优化方法的特定领域。 边界检查消除 C#数组是带有边界检查的，而我们的也同样如此。 虽然在常规C#代码中消除多余的边界检查很重要，但在我们的环境下更需如此，因为即使是使用系统的最低层也需使用已检查边界的数组。 例如，在Windows或Linux内核的中，你看到的是int*类型，同样地，在Midori中你看到的是int[]类型。 为了说明边界检查长什么样子的，请考虑如下的一个简单例子： var a = new int[100]; for (int i = 0; i &lt; 100; i++) { ... a[i] ...; } 这是带有边界检查的循环内数组访问所生成的机器代码的示例： 1234567891011; 首先，将数组长度放入EAX：3B15: 8B 41 08 mov eax,dword ptr [rcx+8]; 如果EDX&gt;=EAX，则访问超出范围，跳转到错误处理例程：3B18: 3B D0 cmp edx,eax3B1A: 73 0C jae 3B28; 否则，访问正常；计算元素的地址，并赋值：3B1C: 48 63 C2 movsxd rax,edx3B1F: 8B 44 81 10 mov dword ptr [rcx+rax*4+10h],r8d; ...; 错误处理，仅仅是调用抛出异常的运行时辅助程序：3B28: E8 03 E5 FF FF call 2030 如果你在每次循环迭代中采用如此方式做记录，那么将不会得到非常紧凑的循环代码，而且你肯定不会有对其进行矢量化的可能性。 因此，我们花了很多时间和精力试图消除这样的检查。 在上面的例子中，对于人类来讲显然不需要进行边界检查，然而对于编译器而言，分析并不是那么简单。它需要证明关于范围的各种事实，还需要证明a在循环体中没有别名或以某种方式被修改过。 这个问题变得如此困难的速度之快，着实令人惊讶。 在我们的系统中，有多层次的边界检查消除方法。 首先，重要的是要注意到CIL在某些区域中的精确处理的需求严格限制了优化器的作用。例如，访问数组越界会抛出IndexOutOfRangeException异常，类似于Java的ArrayOutOfBoundsException，并且CIL指定了它应该在抛出异常时准确地这样做。而正如在稍后将看到的那样，我们的错误模型更加轻松，它基于快速失败（fail-fast）和允许代码外提（code motion），使得不可避免的失败能够比其他系统更快地“发生”。 如果没有实现这一点，我们的双手将会被我即将讨论的大部分内容束缚在一起。 在最高的一层中，在Bartok中，IR仍然与程序输入相对接近，因此，可以匹配和消除一些简单的模式。 在进一步降低层次之前，ABCD算法 （即基于SSA的直接值范围分析）能够采用比模式匹配原则性更强的方法来消除更常见的模式。 幸亏有程序间长度和控制流的事实传播，我们也能够在全局分析阶段使用上ABCD算法。 接下来，Phoenix循环优化器开始发挥作用，这一层处理的是各种循环优化，以及和这一节内容最相关的范围分析。例如： 循环实体化（Loop Materialization）：该处分析实际上创建了循环。它能够识别理想地表示形式为循环的重复代码模式，并且在有性能收益时，将其重写为这样的形式。 这包括手动展开循环，以便矢量化器可以处理它们，即使它们以后可能重新被展开； 循环克隆，展开和版本控制：该处分析创建循环副本以用作特殊化处理，这包括循环展开，创建矢量化循环的体系结构特定版本等等； 归纳（Induction）范围优化：这是我们在本节中最关注的处理阶段。 除了进行经典的归纳变量优化（如加宽）之外，还使用归纳范围分析来删除不必要的检查。 作为该阶段的副产品，边界检查通过将它们外提到循环之外的方式被消除和合并。 这种原则性强的分析比之前介绍的方法处理能力更强。 例如，存在如下的一些做法可以编写更早期的循环，达到“欺骗”前面讨论的更基础技术的目的： var a = new int[100]; // Trick #1：使用变量length而不是常量。for (int i = 0; i &lt; a.length; i++) { a[i] = i; } // Trick #2：从1开始计数for (int i = 1; i &lt;= a.length; i++) { a[i-1] = i-1; } // Trick #3：后向计数for (int i = a.length - 1; i &gt;= 0; i--) { a[i] = i; } // Trick #4：根本不使用for循环。int i = 0; next: if (i &lt; a.length) { a[i] = i; i++; goto next; } 你已经发现了，很明显，在某些时候可以采用某种方式阻止优化器执行任何操作，特别是如果在循环体内进行虚拟调度，其中的别名信息也将丢失。 显然，当无法静态地知道数组长度时，如上面长度为100的例子所示，事情将会变得更加困难。但如果可以证明循环边界和数组之间的关系时，那所有信息都不会丢失。同时在C#中，大部分的分析方法都需要数组长度是不可变的。 不管怎么说，做好优化的区别体现在如下的原始版本： 123456789101112131415161718; 将归纳变量初始化为0：3D45: 33 C0 xor eax,eax; 将边界值放入EDX：3D58: 8B 51 08 mov edx,dword ptr [rcx+8]; 检查EAX是否仍然在边界之内，如果没有则跳转：3D5B: 3B C2 cmp eax,edx3D5D: 73 13 jae 3D72; 计算元素的地址并将其存入其中：3D5F: 48 63 D0 movsxd rdx,eax3D62: 89 44 91 10 mov dword ptr [rcx+rdx*4+10h],eax; 增加循环归纳变量的值：3D66: FF C0 inc eax; 如果变量值仍然小于100，则跳回到循环开始位置：3D68: 83 F8 64 cmp eax,64h3D6B: 7C EB jl 3D58; ...; 错误处理例程：3D72: E8 B9 E2 FF FF call 2030 以及如下完全优化且无边界检查的循环版本之间： 12345678910; 将归纳变量初始化为0：3D95: 33 C0 xor eax,eax; 计算元素的地址并将其存入其中：3D97: 48 63 D0 movsxd rdx,eax3D9A: 89 04 91 mov dword ptr [rcx+rdx*4],eax; 增加循环归纳变量的值：3D9D: FF C0 inc eax; 如果变量值仍然小于100，则回到循环开始位置：3D9F: 83 F8 64 cmp eax,64h3DA2: 7C F3 jl 3D97 有趣的是，如今当我们使用C++新的array_view&lt;T&gt;类型进行同样的实现时，遭遇到了似曾相识的问题。 有时候我和Midori的前同事开玩笑说，我们注定要在接下来的10年里慢慢地，有耐心地重复自己之前做过的事情。 我知道这听起来很傲慢，但却几乎每天都有这种感觉。 溢出检查 如前所述，Midori默认使用检查后运算（通过C#的/checked标志）进行编译，这消除了开发者没有预料到错误类别并因此能够为溢出问题正确的编码。当然，我们保留了显式的checked和unchecked的作用域构造方式，并在适当时覆盖默认值，这是一种更可取的方式，因为程序员声明了其对于程序的意图。 不管怎样，正如你所料到的，这也会降低代码的质量。 为了便于比较，假设添加了以下两个变量： int x = ...; int y = ...; int z = x + y; 现假设x在ECX寄存器中，y在EDX中，这是一个标准的未经检查的求和操作： 03 C2 add ecx,edx 或者，如果你显得更花哨，那么使用单个LEA指令也可将结果存储在EAX寄存器中，正如许多现代编译器的做法： 8D 04 11 lea eax,[rcx+rdx] 好了，下面是插入边界检查的等价代码： 3A65: 8B C1 mov eax,ecx 3A67: 03 C2 add eax,edx 3A69: 70 05 jo 3A70 ; ... 3A70: E8 B3 E5 FF FF call 2028 大多是那些该死的条件跳转指令（JO）和错误处理例程（CALL 2028）。 事实证明，前面提到的很多证明边界检查是多余的方法也同样适用于溢出检查，所有这一切都是为了证明关于范围的一些事实。例如，如果你可以证明某些检查由某些前期检查所支配，并且前期检查是后续检查的超集，那么后续检查就没有必要了。 如果相反的情况成立，也就是说，前期的检查是后续检查的子集，则可以将更强的检查移至程序的前面。 另一种常见模式是相同或类似的算术运算在彼此相邻的位置多次发生： int p = r * 32 + 64; int q = r * 32 + 64 - 16; 很明显，如果p的赋值没有溢出，那么q的赋值也不会溢出。 在真实世界中的代码可能发生了另一种神奇的现象——在同一邻域中进行边界检查和算术检查是相当常见的。 假设有从数组中读取一堆值的如下代码： int data0 = data[dataOffset + (DATA_SIZE * 0)]; int data1 = data[dataOffset + (DATA_SIZE * 1)]; int data2 = data[dataOffset + (DATA_SIZE * 2)]; int data3 = data[dataOffset + (DATA_SIZE * 3)]; ... 等等 ... 良定义的C#数组不存在值为负的边界，如果编译器知道DATA_SIZE足够小以至于可能发生溢出的计算不会小于0，那么它可以消除边界检查所需的范围检查。 还有许多其他模式和特殊情况可以涵盖，但是前面以及展示了与循环优化集成的非常好的范围优化器所展现的强大功能。 它可以覆盖各种场景，包括数组边界和算术运算。 虽然花费了大量的工作，但最终还是值得的。 内联 对于大多数的部分，内联与真正的原生代码是一样的。内联也是同等重要，并且由于C#开发者倾向于编写许多微小方法（如属性访问器等），所以显得其更加重要。 由于本文中的许多主题，获取小代码可能比在C++中更加困难——具有更多分支和检查等。因此，在实践中，大多数的托管代码编译器比本机代码编译器所内联的要少得多，或者至少需要以非常不同的方式进行调整，这实际上对性能起到了决定性作用。 还有一些习惯性膨胀的领域，例如对于原生后端编译器来讲，lambda算子在MSIL中编码的方式是不可理解的，除非其对此事实进行逆向工程。 例如，对如下的代码进行优化： void A(Action a) { a(); } void B() { int x = 42; A(() =&gt; x++); ... } 在进行内联之后，能够将B转变为如下的形式： void B() { int x = 43; ... } 类型为Action的参数A是一个lambda算子，并且如果你知道C#编译器是如何在MSIL中编码lambda的，那么你将明白该技巧有多么的困难。 例如，如下是B的MSIL代码： .method private hidebysig instance void B() cil managed { // 代码大小 36 (0x24) .maxstack 3 .locals init (class P/&apos;&lt;&gt;c__DisplayClass1&apos; V_0) IL_0000: newobj instance void P/&apos;&lt;&gt;c__DisplayClass1&apos;::.ctor() IL_0005: stloc.0 IL_0006: nop IL_0007: ldloc.0 IL_0008: ldc.i4.s 42 IL_000a: stfld int32 P/&apos;&lt;&gt;c__DisplayClass1&apos;::x IL_000f: ldarg.0 IL_0010: ldloc.0 IL_0011: ldftn instance void P/&apos;&lt;&gt;c__DisplayClass1&apos;::&apos;&lt;B&gt;b__0&apos;() IL_0017: newobj instance void [mscorlib]System.Action::.ctor(object, native int) IL_001c: call instance void P::A(class [mscorlib]System.Action) IL_0021: nop IL_0022: nop IL_0023: ret } 为了获得这种神奇结果，需要常量传播ldftn，识别委托构造的工作方式（IL_0017），利用该信息内联B并同时消除了lambda和delegate，然后再次主要通过常量传播，将算术折叠成利用常量42初始化x。 我总觉得这种多种不同考量的优化的自然组合的方式是非常“优雅”的。 与原生代码一样，配置文件引导优化使我们的内联决策更加有效。 结构 CLI的结构几乎和C的结构很相似，但它们却不完全一样。CLI强加了一些会产生开销的语义，而这些开销几乎总是表现为过度的复制，更糟糕的是，副本通常隐藏于程序中。 值得注意的是，由于复制构造函数和析构函数，C++在这方面也存在一些实际问题，通常甚至比我将要描述的更加糟糕。 但也许最令人讨厌的是，CLI初始化结构的方式需要防御性的副本。 例如，考虑如下的程序，其中S的初始化方法抛出了异常： class Program { static void Main() { S s = new S(); try { s = new S(42); } catch { System.Console.WriteLine(s.value); } } } struct S { public int value; public S(int value) { this.value = value; throw new System.Exception(&quot;Boom&quot;); } } 此处的程序预期行为是：必须将值0写入控制台中。 实际上，这意味着赋值操作s = new S(42)必须首先在栈空间上创建一个新的S类型的slot并对其进行构造，然后仅仅将它的值赋给s变量。 虽然对于像这样的单个int的结构来讲并不是什么大问题，但对于大型的结构，这意味着要使用memcpy函数进行赋值。而在Midori中，我们知道哪些方法可以抛出异常，哪些方法无法抛出，而这些都要归功于我们的错误模型（将在后面进行介绍），所以也意味着我们几乎可以在所有的情况下避免这样的开销。 另一个令人讨厌的地方出现在如下形式的代码中： struct S { // ... public int Value { get { return this.value; } } } static readonly S s = new S(); 每次从s.Value读取值： int x = s.Value; 都将得到数据的局部副本。 它实际上在MSIL中可见，且没有readonly关键字： ldsflda valuetype S Program::s call instance int32 S::get_Value() 也就是如下的形式： ldsfld valuetype S Program::s stloc.0 ldloca.s V_0 call instance int32 S::get_Value() 请注意，编译器选择使用ldsfld并由lodloca.s指令紧随其后，而不是通过第一个示例中的ldsflda指令直接加载地址，因此其生成的机器代码将会更加糟糕。这里我们也无法通过引用传递结构体，正如我后面将要提到的那样，它需要数据的复制并且可能再次出现问题。 由于我们的编译器知道方法不会改变成员的值，因此在Midori中，我们对此问题进行了解决。因为所有的静态值都是不可变（immutable）的，所以上面的s不再需要防御性的副本。 除此之外的另一种方式，结构体也同样可声明为immutable，如下所示： immutable struct S { // 如上 ... } 或者可采用另一种方式：由于所有静态值在任何情况下都是不可变的，因此存有疑问的属性或方法可注解为readable，这意味着它们不能被改变，所以也就不再需要防御性的副本。 我在前面已经提到了引用传递。 在C++中，开发者知道使用*或&amp;的方式，通过引用传递大型的结构，从而避免过度的复制。我们也养成了同样做法的习惯，例如，我们有名为in的参数： void M(in ReallyBigStruct s) { // 可读但不可写s的值 ... } 我承认我们可能把这个问题推向极端，直到对我们的API产生了影响。如果我能从头再来一次，我会回过头来消除C#中class和struct之间的根本区别。 事实证明，指针毕竟没那么糟糕，并且对于系统代码而言，你真的需要深入理解“近”（值）和“远”（指针）之间的区别。 我们确实在C#中实现了C++引用的功能，这能够带来一些帮助，但还不够。 关于此更多内容将出现在未来对编程语言的深入研究中。 代码体积 我们还努力推动减少代码体积，在此花费的努力甚至比我所知道的一些C++编译器还要多。 泛型的实例化只是一些带有替换的代码复制和粘贴。 很明显这意味着与开发人员实际编写的代码量相比，编译器要处理的代码数量将会激增。我在之前的文章中已经介绍了泛型的许多性能挑战，一个主要问题就是传递闭包问题。.NET中直观上的List&lt;T&gt;类实际上在其传递闭包中创建了多大28种类型！ 而且甚至这还没把每种类型的所有方法包括进去。因此，泛型是一种使代码体积爆炸的快速方法。 我永远不会忘记重构实现LINQ的那段日子， 与在.NET中使用扩展方法不同，我们在集合类型层次结构中的最底层基类上创建了所有LINQ操作的实例方法。 对于实例化的每个集合，这意味着大约100个嵌套类！每个LINQ操作对应于其中一个。对其进行重构是一种可以在整个Midori“工作站”操作系统文件中节省超过100MB空间的简单方法。 是的没错，节省了100MB！ 我们学会了更加周到地使用泛型，比如说在外部泛型内的嵌套类型通常不是什么好主意。除此之外还积极地共享通用实例，甚至比CLR所做的更多。 也就是说，我们共享了GC指针位于相同位置的值类型的泛型。所以说，如果给定一个结构S： struct S { int Field; } 那么List&lt;S&gt;将共享与List&lt;int&gt;相同的代码表示。 并且同样地，假定有如下的结构： struct S { object A; int B; object C; } struct T { object D; int E; object F; } 那么List&lt;S&gt;和List&lt;T&gt;之间将共享实例。 另外，你可能没有意识到的一点是，C#生成了确保struct结构具有sequential特性布局的IL： .class private sequential ansi sealed beforefieldinit S extends [mscorlib]System.ValueType { ... } 结果是，我们不能与一些假设的List&lt;U&gt;共享List&lt;S&gt;和List&lt;T&gt;： struct U { int G; object H; object I; } 为此，除了其他原因例如让编译器在打包，缓存对齐等方面具有更大的灵活性之外，我们在语言的struct中默认使用auto。 实际上，sequential只对你进行不安全代码时很重要，而在我们的编程模型中，这样的代码甚至都是不合法的。 我们没有在Midori中支持反射机制。原则上，我们最终计划将其作为纯粹的可选功能项，而在实践中从来都不需要它。 我们发现代码生成始终都是更合适的解决方案，通过这种做法，对于C#的文件体积，我们在最佳情况下至少减少了30%。 如果你考虑的是保留完整MSIL的系统，正如通常情况下的做法，即使对于NGen和.NET的AOT解决方案，将能够进一步减少代码的体积。 实际上，我们也删除了很多System.Type，使得没有Assembly，没有BaseType，是的，甚至没有FullName类型。 .NET Framework的mscorlib.dll中仅类型名称就有大约100KB。当然，名称也是很有用的，但我们的事件框架利用代码生成来产生仅在运行时实际需要的那部分代码。 在某个时刻，我们意识到生成的可执行文件大小的40%都是vtable。我们一直在坚持不懈地减少这部分的大小，毕竟由于所述的一切，我们仍然有足够的改进空间。 每个vtable都使用文件中的部分空间来保存指向调度中使用的虚函数的指针，当然同时还有一个运行时的表示。另外，具有vtable的每个对象也同时具有嵌入其中的vtable指针， 所以，如果你关心（整个映像和运行时）的文件大小，你就会对vtable有所关注。 在C++中，如果类型是多态的，那么它只会有一个vtable。 另一方面，在C#和Java等语言中，即使不想要或不需要使用它，类型也具有vtable，虽然说在C#中，你可以使用struct结构类型来忽略它们。 我真的很喜欢Go的这个方面的做法，因为你可以通过接口获得类似虚拟调度的功能，而只需为某些类型强制实现接口，而无需为每种类型带来vtable的开销。 C#中vtable的另一个问题是，所有对象都从System.Object继承了三个虚拟类：Equals，GetHashCode和ToString。 除了这些类通常不会以正确的方式做正确的事情之外，还存在其他的问题：Equals需要反射机制来处理值类型，GetHashCode是非确定性的并且标记了对象头（或同步块，稍后会有更多内容的讨论），而ToString不提供格式化和本地化控制。它们的存在也会使每个vtable增加三个位置，这虽然听起来可能不是很多，但它肯定比没有这些开销的C++体积要更大。 我们剩下的困扰主要来自于基于C#的假设，坦率地说，对于大多数OOP语言（如C++和Java）而言，RTTI始终可用于向下转换，因此对于泛型来讲，这尤其痛苦。虽然我们激进地采取了共享实例方法，但永远无法完全共享所有这些类型的结构，即使不同的实例往往是相同的或者至少是非常相似的。 如果我能再来一次，我会放弃RTTI，因为在90%的情况下，无论如何类型区分联合体或模式匹配都是更合适的解决方案。 配置文件引导优化（PGO） 在前文中，我已经提到过配置文件引导优化（PGO）。而在本文中的大部分方法都具有竞争力之后，PGO成为“走完最后一英里”的关键因素，它也使我们的浏览器程序在SunSpider和Octane等基准测试中增加了30%—40%的性能。 PGO的大部分工作与传统的原生profiler类似，但有两个地方有很大的不同。 首先，我们向PGO新增了本文中列出的许多独特优化方法，例如异步堆栈探测，泛型实例化和lambda等。和其他许多地方一样，我们可以在PGO上永远无休止地优化下去。 其次，除了普通性能测量分析之外，我们还尝试了样本分析。 从开发这的角度上来看，这样做可能会更好，因为它们不需要两次构建，并且还允许从数据中心的实际运行系统中收集和计数。在Google-Wide分析方法（GWP）一文中所概述的，可能是一个不错的例子。 系统结构 上述的基础知识都是重要的，但在一些更具影响力的领域，则需要与语言、运行时、框架和操作系统本身进行更深层次的架构协同设计和协同演进。 我之前写过关于这种“整个系统”方法的巨大好处，它也是有几分神奇的。 GC Midori在各个方面采用了垃圾回收机制，这是我们在整体模型的安全性和生产率上的关键因素。 事实上，在一个收集点上，我们有11个不同的收集器，每个收集器都有自己独特的特征（比如，参考这项研究）。我们有一些方法可以解决诸如长时间停顿等常见问题。 不过，我会在以后的文章中介绍这些内容，现在，让我们回到代码质量方面。 首要的顶层的决定是：保守还是精确？ 一个保守的垃圾收集器更容易融入现有系统，但它可能会在某些地方带来麻烦：它通常需要扫描更多的堆才能完成相同的工作， 并且可能错误地使对象保持存活。 我们认为这两者对于系统编程环境都是不可接受的，所以，我们做出了简单且快速的决定：我们追求精确。 但是，精确会给代码生成器带来开销。精确的垃圾收集器需要告知它在哪里能够找到根集合（root set），该根集合包括堆中的数据结构的字段偏移，并且还包括栈，甚至在某些情况下还包括寄存器。 所以需要找到它们的全部，使得避免错过任何一个对象、错误地将其回收或者在重定位期间调整指针失败，而这些情况都会导致内存安全问题。而除了运行时和代码生成器之间的紧密集成和周密考虑之外，没有任何神奇的技巧可以使这个过程变得高效。 这就进入是协作式还是抢占式的主题以及GC安全点的概念。以协作式运行的GC操作只会在线程达到所谓的“安全点”时进行收集，而以抢占式运行的GC可以通过抢占和线程暂停等方式自由地阻止部分线程，因此可能会强制性回收。一般来说，抢占式需要更多的信息记录，因为它必须在更多的地方识别根集合，包括已经溢出到寄存器中的数据。同时由于对象可能会在任意指令之间移动，它还可能导致某些在操作系统内核中出现的底层代码难以编写，而这些情况都很难进行推断（如果你对此存有怀疑，请参考此代码 及其在CLR代码库中的相关用法），因此，我们使用了协作式GC作为默认手段。我们以保证代码质量作为目的，尝试使用编译器插入的自动安全点探针，例如在循环后沿上。这种方式确实意味着GC“活锁”是有可能的，但在实践中我们很少遇到这种情况。 我们使用分代收集器，它具有减少暂停时间的优点，因为在给定集合上只需检查较少的堆。 从代码生成器的角度来看，它确实存在一个缺点，即需要在代码中插入写屏障。 如果老年代的对象曾经指向一个新生代的对象，那么收集器通常倾向于将其范围限制在新生代中，这么一来收集器也要检查老年代的对象，否则可能就会错过一些对象的收集。 写屏障以跟随特定写入指令的额外指令的形式出现。比如说，注意如下的call指令： 48 8D 49 08 lea rcx,[rcx+8] E8 7A E5 FF FF call 0000064488002028 该屏障只是简单地更新表中的项，使得GC知道下次扫描堆时要检查该段， 大多数情况下，它们最终都形成了内联汇编代码，但也取决于具体情况。 对于x64的CLR在这方面的示例做法，请参考该代码。 编译器难以对其进行优化的原因是因为对写屏障的需求在本质上是“暂时的”。 但是，我们确实在积极地为栈分配对象消除它们，并且可以将代码编写或转换为更少屏障的风格。比如说，考虑如下相同API的方法： bool Test(out object o); object Test(out bool b); 在生成的Test方法的函数体中，在前者中能找到写屏障指令，而在后者中则不会，这是为什么呢？ 因为前者正在向堆对象引用（类型为object）写入，并且编译器在单独分析此方法时，无法知道写入的是否是另一个堆对象，所以这里的分析必须是保守式，并且需要做最坏的假设。 当然后者没有这样的问题，因为bool不是GC需要扫描的类型。 GC影响代码质量的另一个方面问题是，在使用并发收集时可选地保存更重量级的并发读写屏障。 并发GC是在用户程序运行的同时进行垃圾回收活动，这种方法通常可以很好地利用多核处理器，减少暂停时间，并帮助用户代码在给定的时间段内运行更多的代码。 构建并发GC存在诸多的挑战，但其中一个问题是它产生屏障的开销非常高。 由Henry Baker提出的原始并发GC方法采用复制GC方式，具有空间“旧”与“新”的概念，所有的读和写都必须进行检查，并且必须将任何针对旧空间的操作都需要转移到新空间中。 DEC Firefly的后续研究使用硬件内存保护来降低开销，但故障情况的处理仍然非常耗时，而且，最糟糕的问题是，堆的访问时间是不可预测的。 为了解决这个问题已经进行了很多很好的研究，但我们最终还是放弃了复制的做法。 相反，我们采用了并发标记-清除压缩收集方法。这意味着在程序正常执行期间只需加入写屏障，但是某些代码需要被克隆，以便在存在对象移动时具有读屏障。我们的主要GC开发人员的研究已经发表，你可以阅读所有相关的内容。CLR也有一个并发的收集器，但它并非优秀，它主要使用复制方式来收集最年轻的一代，对老年代则采用标记清除方法并将标记阶段并行化处理。遗憾的是，有一些条件会导致顺序性的暂停（想象一下，这就像一把大“锁”），有时甚至超过10毫秒：1）所有线程必须暂停和扫描，这个操作只受线程数和堆大小的限制；2）复制最年轻的一代只受那一代大小的限制（幸运的是，在正常配置下该代内存数量很少）；3）在最坏的情况下，即使是最老的一代也可能发生压缩和碎片整理操作。 独立编译 这部分以最基本模型——静态链接作为开始。在此模型中，所有的内容被编译成单个可执行文件， 这样做的好处是显而易见的：它简单易懂，服务起来概念简单，整个编译器工具链的工作量更少。 老实说，考虑到正在发生的将Docker容器作为服务单元的运动，这种模式在当前变得越来越有意义。 但在某些时候，对于整个操作系统而言，需要的可能是独立编译，这不仅仅是因为静态链接编译整个操作系统的时间会很长，而且是因为生成的进程工作集和占用空间存在大量的重复。 独立编译面向对象的API是一件很难的事情，说实话，很少有人真正将其搞定。这里的问题包括脆弱的基类问题，这也是版本有弹性的库的真正杀手。 因此，大多数真实系统在组件之间的边界处使用了笨拙的“C ABI”。 这就是为什么Windows在历史上使用普通C语言的Win32 API，即使在底层使用COM并通过WinRT转到更多面向对象的情况下也依然如此。 在花费一定运行时的开销的条件下，Objective C的运行时解决了这一挑战。而与计算机科学中的大多数事物一样，几乎所有问题都可以通过额外的间接抽象来解决，这个问题也依然如此。 我们在Midori中采用的设计思路是所有进程都是密封的（sealed），没有动态加载，所以没有看起来像经典的DLL或SO的库文件。 对于这些场景，我们使用了一切皆异步的编程模型，这使得它和使用独立编译和版本化的进程动态连接变得容易。 但是，我们确实需要独立编译的二进制文件，纯粹是由于开发者的工作效率和代码共享（工作集）所导致。好吧，我承认我之前说谎了。 我们最终得到的是增量编译的二进制文件，其中根节点的更改会触发其依赖项级联式的重新编译，但对于叶节点，比如说应用程序而言，情况却要好得多。 随着时间的推移，我们通过精确了解哪种类型的更改可以触发映像文件的级联失效，使得工具链变得更加智能。 例如，一个从未在模块之间发生内联的函数如果它的实现（而不是函数签名）发生了更改，则无需触发重建，这类似于传统C/C++编译模型中头文件和对象之间的区别。 因为我们的编译模型也有静态和动态链接，所以与C++的非常相似，当然运行时模型则是完全不同的。我们还有“库分组”的概念，它允许我们将多个逻辑上不同但相关的库集中到一个物理的二进制文件中，这让我们可以进行更激进的模块间优化，如内联，虚拟化和异步堆栈优化等。 参数多态（也就是泛型） 上面的内容让我想到了泛型（generics），它是能把一切都搞砸的特性。 这里的问题是，除非你实现一个因为Box分配，间接取值或两者同时具备的，完全以性能为代价的擦除模型，你是没有办法预先实例化代码的所有可能版本。 比如说，假设你提供了List&lt;T&gt;，你怎么知道使用库的人需要的是List&lt;int&gt;，List&lt;string&gt;还是List&lt;SomeStructYouveNeverHeardOf&gt;？ 解决的方案有很多： 不专门处理，擦除一切； 仅专门实例化其中的一个子集，并为其余实例创建擦除后的实例。 专门处理所有实例，它能够提供最佳的性能，但同时也有些复杂。 Java使用的是方案1（事实上，擦除模型已经合并到其语言中），而许多ML编译器使用方案2。.NET的NGen编译模型是方案2的变体，其中可以简单地专门化处理的都已专门处理，而其他都是通过JIT编译的。 .NET Native还没有这个问题的解决方案，这意味着第三方库，独立编译和泛型是存在着非常大的TBD。和Midori其他一切内容一样，我们选择了最艰难但却最具有上升空间的道路，这里就意味着是方案3。实际上，我说的有点夸张，我们的团队中有几个ML编译器的传奇人物，所以知道方案2充满着危险。如果能稍微深入了解一下这篇论文 就知道这个方案有多难（和聪明），因为很难先验地知道哪些实例化对程序至关重要。我自己在Longhorn（其正式的名称是Vista）的年代试图将C#代码置入Windows核心的经验也强化了这样的信念：我们不想要JIT，哪些泛型可以使用和哪些泛型不可使用的规则是如此令人难以置信，使得其最终转变为希腊公式。 无论如何，Midori的方法比最初听起来更加困难。 设想一下你有如下的菱形关系。 库A导出了List&lt;T&gt;类型，库B和C都实例化了List&lt;int&gt;，而程序D则同时使用了B和C，甚至将List&lt;T&gt;对象从一个库传递到另一个库。那么我们应如何确保List&lt;int&gt;的版本是兼容的？ 我们称此问题为潜在的多次实例化，或简称为PMI问题。 CLR通过在运行时统一实例化来处理此问题，所有的RTTI数据结构，vtable和诸如此类的东西都在运行时构建和/或激进地进行修补。 而另一方面，在Midori中，我们希望所有这些数据结构都在只读数据段中出现，因此可以尽可能地在各个进程之间共享。 再一次地，一切都可以通过间接抽象来解决。 但与上面的方案#2不同的是，方案#3允许只在需要使用它们的地方加入间接抽象。 就本文而言，这意味着RTTI和访问那些可能受PMI影响的泛型类型的静态变量。 首先，它影响了大量代码（相对而言，方案#2通常影响的是实例字段的加载）；其次，它可以通过将状态和操作附加到已经作为隐藏参数传递的，现有的泛型字典来优化明确不是PMI的实例化。 最后，因为以上所有的这一切，也将付出相应的性能上的代价。 但该死的是它过于复杂。 很有意思的是，用于模板实例化的C++ RTTI实际上遇到了许多相同的问题。 事实上上，Microsoft Visual C++编译器在类名上使用strcmp字符串比较的方法，以解决菱形问题 （值得庆幸的是，有一些众所周知的，更有效的方法可以做到这一点，我们正在积极关注下一版VC++）！ 虚拟调度（Virtual Dispatch） 虽然在我首次从Java切换到C#时感觉很不一样，但Midori让我喜欢上了C#默认情况将方法以非虚拟的方式存在的做法，所以我相信我们不得不改变这一点。事实上我们更进了一步，即在默认情况下使用sealed类型的类，如果你想便利地使用子类，则需要明确地使用virtual标记它们。 然而，激进的去虚拟化是获得优异性能的关键，那是因为，每个虚拟方法意味着一次抽象，而影响更大的是，虚函数使得其失去了内联的机会（而这对于小型函数来说是必不可少的优化方法）。 当然，我们还进行了全局模块内分析以支持去虚拟化，但当为了编译整个程序而需将多个二进制文件组合成一整个库时，也扩展到模块之间的分析。 尽管我们的默认设置是正确的，但对C#开发者来说，我的经验是他们对虚拟和过于抽象的代码存有兴趣。 围绕高度多态的抽象（如LINQ和Reactive Extensions）的API生态系统的剧增助长了这种情况的发生，并灌输了一些的不良行为（比如“无偿的过度抽象”），我想你可以在C++中高度模板化的代码上得出类似的观点。 正如你所猜测的那样，在我们的每个分配和指令都很重要的代码库最低层，并没有很多这样的问题；但在更高层次的代码中，特别是在那些倾向于由高延迟异步操作主导的，可以接受一定的开销，且非常注重开发效率的应用程序中大量的出现。 而通过代码审查，基准测试和激进的静态分析检查，围绕识别和修剪过多冗余代码的强大文化有助于确保适当地使用此类功能。 接口是一个挑战。 .NET Framework中有一些设计不良，效率低下的模式。 比如说IEnumerator&lt;T&gt;仅仅只是为了获取下一个项的操作，就需要两个接口的指派！ 与其相比较的是，C++迭代器可以编译成只使用指针的递增外加一次解除引用的简单方式。 对于许多类似的问题，都可以通过更好的库设计来解决（比如说，我们最终设计的枚举器甚至根本没有接口的介入）。 除此之外，调用C#接口是一件很棘手的事情。 现有的系统不像C++那样使用指针调整，因此通常接口的指派需要进行表内搜索。 首先为了获取vtable，需要一层间接的跳转；然后为了获取接口表，又是另一层间接的跳转。 有些系统尝试对单态调用进行callsite缓存，也就是说，缓存最新的调用并期望相同的对象类再次进入该callsite。这种方式需要可变的stub，更不用说一个异常复杂的thunk和诸如此类的东西的系统。 在Midori，我们从未违反过W^X原则，并且由于其不利于共享也避免了可变的运行时数据结构，使得减小了工作集的大小，同时分摊了TLB和数据缓存的压力。 我们的解决方案是更早地利用了内存排序模型，使用了所谓的“胖”接口指针。 胖接口指针由两个单字组成：第一个是指向对象本身的指针，第二个是指向该对象的接口的vtable的指针。 因为必须在接口vtable中进行查找，所以这使得转换到接口的速度变得稍慢。但对于你一次或几次调用的地方，缓存可以有效的解决，并且通常效果是相当显著的。Go做了类似的事情，但由于以下两个原因而略有不同： 首先，由于其接口都是duck typed，因此采用了动态生成接口表的方式；其次，由于Go没有我们Midori强大的并发模型，胖接口指针会遭到破坏从而可能会违反内存安全性。 虚拟调度的最终挑战是泛型虚方法，或者称之为GVM。 我们的方法概括起来就是，禁止了他们的使用。 即使在.NET中使用NGen生成映像文件，所有它需要仅仅是一次LINQ查询a.Where(...).Select(...)的函数调用，然后便进入到了JIT编译器。 另外即使是对于.NET Native，当发生这种情况时，也会惰性地创建了相当多的运行时数据结构。 简而言之，尚未有已知的方法使得AOT以一种在运行时中高效的方式编译GVM，因此我们甚至都不提供GVM。 这对编程模型来说是一个有点烦人的限制，但由于这样的做法确实我们带来了效率，所以我们还是选择这样做。 另外，令人吃惊的是，在.NET中潜伏了大量的GVM。 静态值 当我知道10%的代码体积用于存储静态初始化检查时，这让我感到十分惊讶。 许多人可能没有意识到CLI规范提供了两种静态初始化模式：默认模式和beforefieldinit模式。 默认模式与Java的做法相同，这听起来太可怕了。 静态初始化程序将在访问该类型上的任何静态字段，该类型上的任何静态方法，该类型上的任何实例或虚方法（如果它是值类型）或该类型上的任何构造函数的执行之前运行。 “何时”部分与实现这一目标所需要的一样重要，因为现在所有这些地方都需要在生成的机器代码中进行显式的延迟初始化检查！ beforefieldinit的松弛就显得约束比较弱，它保证了初始化程序将在实际访问该类型的静态字段之前运行，这为编译器在决定何时初始时提供了很大的余地。 值得庆幸的是，如果你只坚持使用字段初始化器，C#编译器会自动选择beforefieldinit模式。 然而，大多数人并没有意识到选择使用静态构造函数的不可思议的成本，特别是对于所有方法调用现在都会进行初始化保护的值类型来说。 因此，这是如下两者之间的区别： struct S { static int Field = 42; } struct S { static int Field; static S() { Field = 42; } } 现假设结构有如下的属性值： struct S { // 如上 ... int InstanceField; public int Property { get { return InstanceField; } } } 如果S没有静态初始化程序或者使用了beforefieldinit模式（在上面的字段初始化程序示例中由C#自动注入），那么这将是产生如下的Property`的机器代码： 123; 结构是一个单字；将其值移入EAX中，并返回：8B C2 mov eax,edxC3 ret 如果添加类的构造函数，会发生以下情况： 123456789101112131415; 大到足以装下整个frame：56 push rsi48 83 EC 20 sub rsp,20h; 将字段加载到ESI中：8B F2 mov esi,edx; 加载cctor的初始化状态：48 8D 0D 02 D6 FF FF lea rcx,[1560h]48 8B 09 mov rcx,qword ptr [rcx]BA 03 00 00 00 mov edx,3; 调用条件初始化函数：E8 DD E0 FF FF call 2048; 将字段从ESI移动到EAX，而后返回：8B C6 mov eax,esi48 83 C4 20 add rsp,20h5E pop rsi 对于每个属性的访问都是如此！ 当然，即使应用了beforefieldinit，所有的静态成员仍会执行这些检查。 尽管C++没有遇到同样的问题，但它确实存在令人费解的初始化排序语义。 并且就像C#的静态值一样，C++11通过“魔法静态”功能 引入了线程安全的初始化方法。 我们几乎消除了Midori在这个方面的整个混乱局面。 之前已经提到过，Midori没有可变的静态值。 更准确地说，我们扩展了const的概念以涵盖任何种类的对象， 这意味着静态的值在编译时会进行求值，将结果写入生成的二进制映像文件的只读段，并在所有进程中共享。 而对于代码质量更重要的是，所有运行时初始化检查都被移除，并且所有的静态访问都被固定的地址所替换。 在系统的核心部分，比如内核中，仍然存在可变的静态值，但用户代码中却不存在可变静态值。 因为这样值的数量很少，所以我们未使用它们的经典C#风格的延迟初始化检查，而是在系统启动时手动进行初始化的。 正如我之前所提到的，整个镜像代码体积减少了10%，并且速度提升了很多。 不过很难确切知道这比标准C#程序节省了多少空间，因为当我们着手进行更改时，开发者已经很清楚这些问题，并且在他们的类型中自由地使用[BeforeFieldInit]属性以避免开销。 因此，10%实际上是我们在整个过程中实现的代码体积节省的下限值。 Async模型 我已经写了很多关于异步模型的内容，这里我将不再赘述。 不过我将重申一点：编译器是使链接运行栈运行的关键。 在链接栈模型中，编译器需要将探针插入到检查可用栈空间的代码中。如果出现没有足够空间来执行某些操作情况，比如进行函数调用或在栈上动态分配等，编译器则需要安排新的链接附加到内存中，并切换到它的位置。大多数情况下，这相当于一些范围检查，对运行时函数的条件调用以及对RSP的修补。 探针看起来像是如下的代码： 123456789; 检查栈空间使用量： lea rax, [rsp-250h] cmp rax, qword ptr gs:[0] ja prolog; 如果栈空间不足，则链接到新的段： mov eax, 10029h call ?g_LinkNewStackTrampolineprolog:; 真正的运行代码出现在这里 ... 不用说的是，出于以下两个原因，你希望尽可能少地进行探测操作：首先，它们会产生运行时开销；其次，他们会增加代码体积。因此，我们使用一些技术来消除探针。 编译器当然知道如何计算函数运行栈的使用量，因此，对于探测的内存量实际上还可以更聪明一些。 我们将这些知识融入我们的全局分析器中，并可以在代码移动和内联后进行合并检查。 我们将检查外提到循环之外，并在大多数情况下，对消除检查进行了优化，有时甚至以使用更多栈空间作为代价。 为了消除探针，我们最有效的技术是在经典栈上运行同步代码，并指导我们的编译器完全省略掉探针，这利用了我们对类型系统中异步的理解。而经典的运行栈之间的切换只需简单地更改RSP的值： 12345678; 切换到经典栈：move rsp, qword ptr gs:[10h]sub rsp, 20h; 完成一些任务（比如和原生的C/C++进行互操作）...; 再切换回来：lea rsp, [rbp-50h] 我知道由于这样的切换，Go放弃了链接栈。 并且起初对于我们来说，这种方式也是非常糟糕，但经过大约一年或两年的努力，切换时间逐渐降低到低于总开销的0.5%。 内存顺序模型 Midori对安全并发 的态度确实有一个惊人的好处：你可以免费获得顺序一致的内存排序模型。现在，你可能希望再次阅读那篇安全并发的文章，那么请随意吧！ 为什么会是这样呢？首先，Midori的进程模型在默认情况下确保以单线程方式执行。 其次，进程内部的任何细粒度并行都由有限数量的API控制，所有这些都是无竞争的。 缺少竞争意味着我们可以有选择性地在fork和join位置注入屏障指令，而无需开发者注意或了解其细节。 显然，这对开发者的工作效率有着不可思议的好处。 因此，Midori程序员从未被内存重排序问题所困扰，而这也无疑是该项目最值得骄傲的结果之一。 同时这也意味着编译器可以自由地进行更激进的代码移动优化，而不会牺牲编程模型的高效性。换句话说，我们实现了两全其美。 不过少数的内核开发者还是不得不考虑底层机器的内存排序模型，因为他们是实现异步模型本身的那群人。 为此，我们消除了C#中无论如何都会被完全破坏的volatile概念，并支持类似于C++中atomic的机制。 出于以下两个原因，该模型是非常不错的。 首先，对于每一次读写操作，你需要什么样的内存屏障是明确的，实际上也是重要的（因为这会影响变量的使用，而不是它的声明）；其次，显式模型告诉编译器关于哪些可以优化而哪些不行的更多信息，对于具有特定用途的场景中，则才是最重要的。 错误模型 我们的错误模型之旅很长，并且将成为未来一篇文章的主题。 然而，简而言之，我们试验了错误处理频谱的两个相对的端点——异常和返回错误代码，以及两者之间的许多折衷点。 以下是我们从代码质量角度的一些发现。 返回错误代码是不错的方式，因为从类型系统就能告知该处代码可能会发生错误，所以开发者被迫对其进行处理（前提是他们不忽略返回值）。 返回错误代码也是一种简单的方法，并且只需要比异常或相关机制（如setjmp/longjmp）少得多的“运行时戏法”。 因此我很喜欢这样的特性。 然而，从代码质量的角度来看，返回代码是相当糟糕，因为它们会强制在热点路径中执行本来不会执行的指令，包括甚至不会发生的错误。 而且还需要从函数返回一个值，导致占用寄存器和/或栈空间，以及调用者需要执行分支来检查结果。 当然，我们希望代码都能正确预测，但事实上后果是开发者需要做更多的工作。 当尝试构建可靠的系统时，无类型异常是相当糟糕的，而操作系统需要的就是可靠。 当你调用一个函数时，不知道会有隐藏的控制流路径是非常不可接受的。除此之外，它们还需要更笨重的运行时的支持来展开堆栈，搜索处理程序等。 在编译器中对异常控制流进行建模也是一件真正痛苦的事情（如果你不相信我，只需阅读这篇邮件交流的内容）。因此，我很讨厌这样的特性。 我习惯于不会因为害怕遇到Java神经而不检查的异常的有类型异常，解决了其中的一些缺点，但它也遇到了自身的挑战。 我将在未来的文章中再次进行详细分析。 从代码质量的角度上来看，异常是不错的选择。 首先，可以组织代码段以便“冷”的处理程序不会在成功路径上占用缓存。 其次，在正常的调用约定期间，不需要执行任何额外的工作。 没有返回值的封装，因此没有额外的寄存器或栈空间的压力，并且在调用者中无需有分支。但是，异常也有一些缺点，比如在无类型模型中，必须假设每个函数都可以抛出异常，这显然抑制代码移动的能力。 我们的模型最终是两者的混合体： 对编程bug采取了快速失败（fail-fast）的策略； 对动态可恢复错误采用了有类型的异常。 我可以说，快速失败与有类型异常之间使用的最终比率为10:1， 异常通常用于I/O和处理用户数据，例如shell和解析器，而合约是快速失败方式最大的来源。 最终得到的是上述代码质量属性的最佳可能配置： 没有对调用约定带来影响； 封装的返回值和调用分支之间没有关联的胶水代码； 所有抛出异常的函数在类型系统中都是已知的，从而实现更灵活的代码移动； 所有抛出异常的函数在类型系统中都是已知的，为我们提供了精巧的EH优化，例如在try不会抛出异常时将try/finally块转换为直接代码。 我们模型一个不错的意外收获是，编译时可以选择使用返回代码返回或异常机制。 多亏了这一点，实际上我们做了实验来观察这对我们系统的体积和速度有什么影响， 基于异常的系统最终在某些关键基准测试中体积缩小了约7%，速度提高了4%。 最后，我们最终得到的是我使用过的最强大的错误模型，当然也是性能最好的模型。 合约 如上所述，Midori的编程语言有作为一等公民的合约机制： void Push(T element) requires element != null ensures this.Count == old.Count + 1 { ... } 其模型很简单： 默认情况下，运行时检查所有合约； 编译器可以自由地证明合同是一定有误的，并发出编译时错误； 编译器可以自由地证明合约是一定无误的，并删除这些运行时的检查。 我们有条件编译的模式，但是我现在要跳过它们，这部分内容请关注即将发布的关于我们语言的文章。 在早期，我们尝试使用像MSR的Clousot这样的合约分析器来证明合约，然而，出于编译时的原因，我们不得不放弃这种方法。事实证明，编译器已经非常擅长于简单的约束求解和传播。 因此，最终我们只是将合约建模为编译器已知的事实，并让它在必要的时候插入检查代码。 例如，完成上述范围信息的循环优化器已经可以利用如下的检查： void M(int[] array, int index) { if (index &gt;= 0 &amp;&amp; index &lt; array.Length) { int v = array[index]; ... } } 为了消除在防御性if语句中的冗余边界检查，为什么不在这里做同样的事情呢？ void M(int[] array, int index) requires index &gt;= 0 &amp;&amp; index &lt; array.Length { int v = array[index]; ... } 然而，当涉及独立的编译时，这些事实是特殊的。 合约是方法签名的一部分，我们的系统确保了合适的子类型替换，让编译器在独立编译的边界上进行更激进的优化。 它可以更快地完成这些优化，因为它们不依赖于全局分析。 对象和分配 在以后的文章中，我将详细描述我们与垃圾收集器之间的博弈， 然而，帮助我们取胜的技术是积极地减少行为良好的程序在堆上分配对象的大小和数量。这有助于优化整体工作集，从而使程序更小更快。 第一种技术是减少对象大小。 在C#和大多数Java VM中说，所有的对象都有对象头。 对象头的标准大小是单字（word），即32位体系结构上的4字节和64位上的8字节。作为vtable指针的扩充，它通常用于标记对象，在.NET中用于随机内容，如COM互操作，加锁，哈希值的记忆化等等（甚至在源代码它被为“厨房的水槽”）。 好吧，对于两者，我们最终都抛弃了。 我们没有COM互操作，没有不安全的自由线程，因此没有加锁操作（任何情况下，给任意对象上锁都是一个坏主意）。 我们的Object也没有定义GetHashCode等等。这为每个对象节省了一个单字的空间大小，并且在编程模型中没有明显的开销（实际上恰恰相反的是，还得到了某些改进），因此也就没什么可说的了。 此时，每个对象的唯一开销就是vtable指针。 对于结构来说，当然是没有vtable指针的（除非它们采用了box的方式）。我们尽力消除所有这些开销，但可悲的是，由于RTTI方式的使用，很难将优化变得激进。我认为这是另一个我想回去重新解决，并完全颠覆C#类型系统的领域，使得其能效仿更多的C，C++甚至是类似Go的模型。 不过最后，我认为我们确实取得了与普通C++程序比拟的竞争力。 这里充满了挑战。正如著名的C++空基优化一样，将struct布局从C#的当前默认的sequential切换到我们首选的默认auto方式，肯定会有所帮助。 我们还进行了激进的逃逸分析，以便更有效地分配对象，如果发现一个对象是能够在栈上分配，则它将被分配在栈而不是堆上。 我们的初始实现能够将10%左右的静态分配从堆移动到到栈上，这激励我们更加激进地减少对象的大小，消除vtable指针和整个未使用的字段。 考虑到这种分析是如此的保守，我对这样的结果非常满意。 如果开发者想要给编译器提供提示信息，同时在语义上强制执行某种程度的包含，我们也提供了C++引用和Rust借用之间的混合。 例如，假设我想分配一个小型数组与被调用者进行共享，但确定被调用者不存在对它的引用，其做法也就像下面这样简单： void Caller() { Callee(new[] { 0, 1, ..., 9 }); } void Callee(int[]&amp; a) { ... 保证a不会逃逸 ... } 编译器使用int[]&amp;信息在栈上分配数组，并且通常完全消除了vtable的生成， 再加上复杂的边界检查消除算法，这一切给了我们更接近C性能的程序。 系统中的Lambda/delegate也是结构，因此无需堆的分配。 捕获的显示框架受上述所有问题的影响，因此我们经常可以在栈上分配它们，造成的结果是下面的代码是完全无需堆分配的。 事实上，由于一些早期的优化，如果被调用者被内联优化，那么它就像通过实际的lambda函数体被扩展为一系列指令一样，而没有产生任何实际的函数调用！ void Caller() { Callee(() =&gt; ... 完成某些任务... ); } void Callee(Action&amp; callback) { callback(); } 在我看来，这确实是借用系统的杀手级用例。 由于担心分配和效率低下的问题，开发者在我们拥有此功能之前的早期就避免使用基于lambda的API。 而另一方面，在完成此功能之后，充满活力的基于lambda的API生态系统又重新蓬勃发展。 吞吐量 以上所有的内容都与代码质量，也就是说，与生成代码的大小和执行速度有关。 然而，编译器性能的另一个重要方面是吞吐量，也就是说代码编译的速度能有多快。 对此，像C#这样的语言也存在一些自身的挑战。 我们遇到的最大挑战与语言固有的安全性无关，更多的是与一个非常强大的功能有关：参数多态，或者不那么自负的说法——泛型。 我之前已经提到过，泛型只是一种方便的复制粘贴机制。 并在本文中提到了它对代码大小带来的一些挑战，然而，其也对编译吞吐量也带来了问题。 如果List&lt;T&gt;的实例创建了28种类型，每种类型都有自己的少数几种方法，那编译器将需要处理更多代码。 独立编译会有所帮助，但是如前所述，泛型通常是跨越模块边界的方式使用。因此，其可能会对编译时间产生的影响，而事实上也是如此。 实际上，这与大多数C++编译器花费大量时间的地方没有太大差别。 在C++中，泛型叫做模板，由于大量使用模板化抽象（如STL，智能指针等），更现代的C++代码库具有与上述相类似的问题。 为了避免这个问题带来的影响，许多C++代码库仍然只是“带有类的C”的形式。 正如我之前提到的，我希望我们放弃RTTI，这么做会减少泛型的问题。但我认为即便如此，泛型仍然是我们在编译吞吐量上最大的挑战。 有一种看起来不是，但实际确实有趣的方式是，你可以尝试进行分析以裁剪一些泛型。虽然这种方式是有效的，但分析也需要时间，而这就是需要节省的地方。 我们习惯跟踪的一个指标是AOT编译程序的速度比仅仅进行C#编译要慢多少。 而这是一个完全不公平的比较方式，因为C#编译器只需要生成MSIL，而AOT编译器则需要生成机器代码。而将AOT编译与JIT编译进行比较是一个比较公平的方式，但无论如何，在吞吐量方面做得好对于C#的使用者来讲尤其重要，因为对开发生产效率的期望至始至终是相当高的， 因此，这是我们认为客户对我们评价的关键指标，所以我们也专注于此。 在早期，这个指标是非常糟糕的，我记得是它慢了40倍。 经过大约一年半的重点优化，我们将debug版本降低到3倍左右，而optimized版本降低到5倍左右。 对于这样的成绩我很高兴！ 实现这一点没有任何秘密可言。 大多数情况下，它只需要像任何其他程序一样优化使得将编译器更快。 因为我们使用Midori的工具链构建了编译器，再使用它编译Midori自身，所以通常这是通过首先使Midori变得更好，然后再使编译器更快来达到目的的，而这是一个很不错的良性循环。 我们遇到了字符串分配的实际问题，这些问题告诉我们在编程模型中如何处理字符串，我们也发现了，疯狂的泛型实例化闭包迫使我们消除并构建工具来主动找到它们等等问题。 文化 结束前的最后一节我想说的是，文化是我们所做的最重要一方面的工作。 如果没有文化，这样一支出色的团队也就不会进行自我选择，也不会狠狠地追求上述所有这些成绩，我会花一整篇文章谈论这方面的内容。但是，回到关于编译器的内容，有两件事是有所帮助的： 我们在试验环境中测量所有指标。 “如果它不在实验室里，那对我来说它已经死了”。 我们提前和经常性审查进展情况，即使在没有取得进展的地方也是如此，而且我们也习惯性地进行自我批判性思考。 对于每个开发周期（sprint），我们都有一个所谓的“CQ Review”（其中CQ代表“代码质量”）过程。 通过审查每个基准测试，编译团队准备了好几天的时间，从最低层次的微基准测试到编译和启动所有Windows，并在此过程中分析任何变化。 所有预期的胜利都得到了确认（我们称之为“确认你的毙敌”），任何意料之外的退化都进过根本原因的分析（并提交bug），任何未实现的进展也会被分析和形成报告，以便我们可以从中学习。 我们甚至盯着那些没有改变的数字，并问自己，为什么他们没有改变？这是预期的吗？ 我们是否对其感觉不好，如果是这样，我们将如何在下个开发周期中进行改变？我们审查了竞争对手的最新编译器的进展并监控其变化率等等。 这个过程非常的健康，每个人都被鼓励进行自我批判性思考。这不是所谓的“猎巫”运动，而是一个作为团队学习如何更好地实现目标的机会。 在经历了Midori之后的，我保留了这个过程。 我对一些成员对此的争议感到惊讶，他们受到威胁并担心缺乏进展会使他们看起来很糟糕。 他们使用“数字没有变是因为它们现在不是我们关注的焦点”作为摆脱节奏的理由。 根据我的经验，只要代码发生变化，数字就会发生变化，因此最好密切关注它们，以免在几个月后当它突然成为最重要的任务时，陷入尴尬的境地。 处罚和持续的鼓声是这些评论中最重要的部分，因此即使只忽略掉其中一个也可能是有害的，所以也是不被允许的。 该过程和其他所有东西一样都是我们的秘密武器。 总结 哇噢，有如此多需要被提到的内容。我希望这些内容至少很有意思，并希望能够建立所有这一切令人难以置信内容的团队，至少做到一小部分的正义（尽管我知道我没有做到）。 这段旅程花了我们十多年的时间，特别是如果当你考虑到Bartok和Phoenix在Midori成立之前已存在多年的事实。 仅仅通过AOT的方式编译C#并且做得很好，会让我们收获上述许多的好处。 但要真正获得神奇的原生性能，甚至在某些领域超过它，需要一些关键的“整个系统”结构上的赌注。我希望有一天我们能够在这个性能水平上为世界提供安全性的保障。 鉴于业界的安全状况，全世界真的都需要它。 到目前为止，我已经简要提及到我们的编程语言，使得我需要进一步对其深入下去。那么，下次再见！]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>安全</tag>
        <tag>Midori</tag>
        <tag>翻译</tag>
        <tag>编译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Midori博客系列翻译（3）——一切皆异步]]></title>
    <url>%2F2018%2F11%2F25%2Fmidori%2F3-asynchronous-everything%2F</url>
    <content type="text"><![CDATA[Midori由大量通过强类型消息传递接口相互连接的，超轻量级细粒度进程构建而成。我们传统上常见的程序是可能带有一些内部线程的单一宏进程。而在Midori中，进程则由数十个小型进程所表示，从而实现自然，安全和大部分的自动并行化。同时，在Midori中，显然同步阻塞是不允许的，这意味着包括所有文件和网络I/O，消息传递，以及诸如与其他异步任务进行会合等任何“同步”活动，在字面上的一切都是异步的。这样的设计使得所实现的系统可高度并发，且能快速响应用户的输入，以及灵活的扩展。但也正如你想象的那样，这在设计上也带来了一些具有吸引力的挑战。 异步编程模型 乍一眼看，异步编程模型很像C#的async/await。 而这并不是巧合，因为我也是.NET task的架构师和开发主管。作为Midori的并发设计者，对于即将发布的.NET新版本，我必须承认我对异步编程模型存有偏爱。 因此，即使知道对于Midori，它可能不会像预期的那样发展，但我们依旧开始了数年的开发旅程。而当离开时，我们与C#团队密切合作，将一些在Midori上形成的方法带回到C#中，并在C#开始探索异步模型时，也使用了async/await模型的变体大约一年之久。虽然我们未能将Midori的所有优点带到.NET中，但也确实实现了其中的一部分，而这部分主要是在性能方面。 而对于无法回到过去将.NET的task变成结构体，这一点至今让我感到遗憾。 但我却逐步超越了我自己。到达这一步的旅程是漫长的，让我们从头讲起。 Promises 我们使用的异步模型的核心是一项名为Promise的技术。虽然在如今，该想法已是无处不在，但是，你很快将会看到，我们所使用Promise的方式将更加有趣。受到E语言系统的强烈影响，使得与流行的异步框架相比，我们最大的不同在于做到了完全的异步——例如，在我们的系统中，没有一个同步的API。 该模型的最重要的方式是使用了显式的回调，而这对于任何使用过Node.js编程的人都非常熟悉。 这里的想法是为任何最终会产生T（或失败）的操作产生一个Promise&lt;T&gt;。 产生的操作可以在进程内异步运行，甚至可以远程执行。结果的使用者无需知道具体运行的位置，他们只需要将Promise&lt;T&gt;作为一等类型值来处理，也就是说当需要获取T值时，必须进行会合（rendezvous）操作。 其基本的回调模型如下： Promise&lt;T&gt; p = ... 一些操作 ...; ... 可选地，与该操作并发地完成其他操作 ...; Promise&lt;U&gt; u = Promise.When( p, (T t) =&gt; { ... 当T变得可用时 ... }, (Exception e) =&gt; { ... 产生失败时 ... } ); 最终，我们从静态方法切换到实例方法： Promise&lt;U&gt; u = p.WhenResolved( (T t) =&gt; { ... T变得可用时 ... }, (Exception e) =&gt; { ... 产生失败时 ... } ); 请注意这里的Promise链：操作的回调返回类型为U的值或者根据需要抛出异常。然后，值为u的Promise使用者也将如此操作，依此类推进行下去。 这是一种并发的数据流编程方式，其优点是操作的正确依赖关系控制着系统中活动的调度。 经典系统经常停止工作，不是因为正确的依赖关系，而是由于错误的依赖关系所导致，例如在调用堆栈的底层中发出同步I/O调用，而上层的调用者却对此一无所知。 事实上，这也是Windows系统上经常出现白屏的原因之一。 对此，我依然记得几年前的一篇论文，它指出了Outlook中出现挂起的主要原因：某个常用的API偶尔会尝试通过网络，与打印机进行通信来枚举Postscript字体。 请求所花费的时间虽然不可预测，但由于系统缓存了字体，所以只需要偶尔真正向打印机发出请求。 因此，这种表面“良好”的行为使开发人员误以为从UI线程进行调用是安全的。 测试期间（开发人员在造价昂贵的计算机上使用近乎完美的网络时）没有任何不良的后果产生， 但遗憾的是，当网络状况恶化时，其造成的后果是与旋转的“甜甜圈”（光标）和白屏相伴的10秒钟系统挂起。而到目前为止，在我所使用的所有操作系统中，此问题依然存在。 上述举例中产生问题的原因是，调用API的开发人员不清楚可能会产生高延迟。这种延迟甚至非常隐蔽，因为其深埋于调用栈中，被虚函数调用所掩盖。 在Midori中，所有的异步都在类型系统中表示，上述的例子将不会发生，因为这样的API将返回一个Promise类型。 没错，开发人员虽然仍可以做一些荒谬的事情（比如在UI线程上产生死循环），但像这种搬起石头砸自己脚的事情将会变得困难得多，特别是当涉及到I/O操作时。 如果想停止链式数据流怎么办？这也没有问题。 p.WhenResolved( ... 如上 ... ).Ignore(); 结果证明这是一种反模式，它通常表明你正在改变共享状态。 这里的Ignore需要一点解释是——除非你显式地这样做，编程语言不允许忽略其返回值。 同时，这种特定的Ignore使用还添加了一些诊断功能，以帮助调试你意外忽略的重要事项（和异常等失败情况）。 最后，我们为常见的模式添加了一些作为辅助的重载和API： 123456789101112131415// 只响应成功情况，并自动抛出错误：Promise&lt;U&gt; u = p.WhenResolved((T t) =&gt; &#123; ... T变得可用... &#125;);// 使用类似finally的结构：Promise&lt;U&gt; u = p.WhenResolved( (T t) =&gt; &#123; ... T可用 ... &#125;, (Exception e) =&gt; &#123; ... 产生失败时 ... &#125;, () =&gt; &#123; ... 无条件执行... &#125;);// 执行各种循环：Promise&lt;U&gt; u = Async.For(0, 10, (int i) =&gt; &#123; ... 循环体 ... &#125;);Promise&lt;U&gt; u = Async.While(() =&gt; ... predicate, () =&gt; &#123; ... 循环体 ... &#125;);// 等等。 基本上可以确定的是，这并不能算的上是新颖的想法。 Joule语言和Alice语言甚至都已有了良好的内置语法支持，使上述繁琐笨拙的回调传递方法变得更容易使用。 但无法容忍的是，该模型抛弃了数十年以来熟悉的编程语言结构，例如循环。 这一点真的真的很糟糕，因为它往往会导致代码遭遇回调困境，通常出现在多层次的嵌套和一些非常重要故而必须正确的代码中。 例如，假设你在磁盘驱动程序中看到如下代码： Promise&lt;void&gt; DoSomething(Promise&lt;string&gt; cmd) { return cmd.WhenResolved( s =&gt; { if (s == &quot;...&quot;) { return DoSomethingElse(...).WhenResolved( v =&gt; { return ...; }, e =&gt; { Log(e); throw e; } ); } else { return ...; } }, e =&gt; { Log(e); throw e; } ); } 所以根本不可能在这样的代码中搞清楚所有的逻辑，因为这很难判断所有return的返回位置和所有未处理异常，并且很容易出现重复的代码（例如错误处理），因为经典的块作用域不再适用。上帝禁止你使用循环，但这里是磁盘驱动程序，它需要可靠性的保证！ 进入到Async和Await的世界 几乎 所有 的主要 编程语言 都已具有类似async和/或await的数据结构，我们在2009年时，也已经开始对其大规模使用。这里我说大规模使用时，我是认真的。 async/await的方法让我们的系统保持了非阻塞的性质，并消除了上述可用性方面的混乱， 事后看来，这种优势是非常明显的，但是请不要忘了，在当时，大规模使用的最主流语言还是F#及其异步工作流 （另见此文）。 尽管async/await对可用性和生产力方面带来了提升，但我们团队对其也存在巨大争议，对此，我将在稍后详细介绍。 我们所设计的async/await的与C#和.NET中的略有不同。 所以让我们来看看从上面的Promise模型演进到新的基于async/await模型的过程，并且在抽丝剥茧的过程中，逐渐指出其中的差异。 我们首先将Promise&lt;T&gt;重命名为AsyncResult&lt;T&gt;，并将其作为结构体 （这一点类似于.NET的Task&lt;T&gt;，但其更多地关注于“数据”而不是“计算”）。据此产生了如下的一系列相关的类型： T：即时同步计算的结果，并且不会导致失败 Async&lt;T&gt;：异步计算的结果，并且不会导致失败 Result&lt;T&gt;：可能导致失败的即时同步计算的结果值 AsyncResult&lt;T&gt;：可能导致失败的异步计算的结果值 最后一个实际上是Async&lt;Result&lt;T&gt;&gt;的别名。 可能失败的值和不会导致失败的值之间的区别又将是另外一个主题。但总之，我们的类型系统为我们保证了它们的属性。 同时增加了await和async关键字，如果一个方法被标记为async： async int Foo() { ... } 那么意味着该方法的内部允许存在await关键字： async int Bar() { int x = await Foo(); ... return x * x; } 正如它们在C#中的那样，async/await仅仅作为上述回调方法的语法糖而存在。 但最终，我们从性能的角度出发，使得其存在意义更加广泛，并在其基础上添加了轻量级协程和链接栈。 其有关的更多内容如下。 调用async方法的调用者必须进行如下的二选一：使用await并等待其结果，或使用async并启动异步的操作。 因此，系统中的所有异步操作都将显式进行： 123int x = await Bar(); // 调用Bar，并在等待其结果返回。Async&lt;int&gt; y = async Bar(); // 异步调用Bar，并在未来某个时刻处理。int z = await y; // ... 正如即使计算，它将等待Bar操作完成。 直到很久以后我们才意识到，这样的作法给我们带来了非常重要但又微妙的优势。 因为在Midori中，“等待”某个事件的唯一方法是使用异步模型，并且没有任何隐藏的阻塞代码是由类型系统提供的。更重要的是，它告诉了我们所有无法用于等待的情况，并告知我们什么是纯粹的同步计算！因此，这种方式可用于保证没有代码会阻塞UI绘制，也正如将在如下看到的一样，它还包含许多其他强大的功能。 由于系统中异步代码的绝对规模，我们在语言中增加了许多C#仍然不支持的模式，这包括迭代器（iterator），for循环和LINQ查询： IAsyncEnumerable&lt;Movie&gt; GetMovies(string url) { foreach (await var movie in http.Get(url)) { yield return movie; } } 或使用LINQ风格： IAsyncEnumerable&lt;Movie&gt; GetMovies(string url) { return from await movie in http.Get(url) ... filters ... select ... movie ...; } 整个LINQ基础架构，包括资源管理和背压（backpressure），也参与到流式计算中。 我们将数百万行的代码从旧的回调方式转移到新的async/await模式中。 在显式回调模型的复杂控制流中，我们发现了大量的bug，特别对于循环和错误处理逻辑而言，现在可使用熟悉的编程语言结构，而不是笨拙的API方式加以实现。 我已经提到过，对于这点是有争议的：虽然团队中的大多数都乐见其在可用性上的改进，但也并非所有人都持此观点。 也许最大问题是旧的回调模型采用了一种pull风格的并发，在这种方式中，调用者在继续自己的操作之前需等待被调用者。 而在这个新模型中，你不能再这样做，当然，可能总是这归功于async关键字，但这肯定比旧模型带来更多的摩擦。旧式熟悉的阻塞模型变成了一个简单的await关键字。 我们以反应式的IObservable&lt;T&gt;/IObserver&lt;T&gt;适配器形式提供了pull和push之间的桥接。 虽然不敢宣称它非常成功，但是对于未使用数据流的带有副作用的行为，它们是很有用的。 实际上，我们整个UI框架都基于函数式反应式编程的概念。以性能的名义，它与Reactive Framework略有不同， 但对于此问题，需要一篇独立的文章进行描述，本文将不再展开。 一个有趣的后果是在返回T之前的await和直接返回Async&lt;T&gt;之间产生了差异，而在先前在类型系统中并不存在。 坦率地说，对此我感到非常烦恼直到现在。 比如说： async int Bar() { return await Foo(); } Async&lt;int&gt; Bar() { return async Foo(); } 我们想表达这两者的表现形式是等价的，但是事实并非如此。 前者阻塞并保持堆栈帧活跃，而后者却不能。 一些编译器可以巧妙地解决这种常见的模式——这实际上是异步尾调用的精神上的等价物——但事情并不总是这么简单。 就其本身而言，这个问题不是非常严重。 然而，它在流式处理等重要领域引起了一些反模式情况。 开发人员倾向于在他们过去传递Async&lt;T&gt;的区域进行await，从而导致不必存在的暂停堆栈帧的大量积累。 我们对大多数的模式都有很好的解决方案，但直到项目结束时我们都在努力解决这个问题，尤其是在追求10Gb网卡传输速度饱和度的网络堆栈中。 我们将在下面讨论所采用的一些技术。 但是在这次探索之旅结束时，这样的变化是非常值得的，不仅是在模型的简单性和可用性方面有提升，而且是在为我们后续优化打开了大门。 执行模型 这种变化让我首先经历的是执行模型。 我们经历了五种不同的模型，都取得不错的结果。 实现“异步皆一切”的关键是超轻量级的进程。这归功于在一篇早期帖子中描述的安全基础所建立的软件隔离过程（SIP）机制之上。 无共享可变静态状态使得将进程保持尽量小。 令人惊讶的是，在具有table和可变静态变量的典型程序中，有大量的地址空间被破坏，同时会花费大量的启动时间来初始化这些共享区域。 正如我之前提到的，我们将大多数的静态函数固化为在许多进程中共享的常量。执行模型使得堆栈的开销变得更小（更多细节将在下文中提到），这也是一个关键因素。 但是最后的贡献因素甚至却都不是技术，而是文化。 我们在实验环境中每天测量进程的启动时间和资源的使用量，并在优化的过程，确保我们每次冲刺都比上一次有所提高。 我们中的一群人每周会进入一个房间，对着各种数字并回答关于性能为什么上升/下降或保持不变的问题。 对于这种关于性能的文化我们是普遍存在的，并通过这种方式，保持了系统基础的轻量和灵活。 在进程内部运行的代码无法被阻塞， 而在内核中，代码允许在指定区域中被阻塞，但是请记住在内核中没有运行任何用户态的代码，因此（内核代码在指定区域中被阻塞）仅是一个实现的细节。这里当我说“没有阻塞”时，我是认真的：Midori没有按需换页的机制。在传统的操作系统中，按需换页意味着对内存的访问可能会物理阻塞以执行I/O操作。我不得不说的是，没有按需换页所带来的页面抖动是如此的受欢迎，以至于直到了今天，我在新的Windows系统上所做的第一件事就是禁用分页。与其愚蠢地进行换页操作，我更希望操作系统在内存不足时杀死进程，并继续可靠地运行。 C#的async/await实现完全是一个前端的编译技巧。 如果你曾在生成的汇编上运行过ildasm，那么你就知道：它将捕获的变量提升到对象的字段中，将方法的主体重写为状态机形式，并使用Task的继续传递机制来保持像迭代器这类的对象向前通过状态。 我们以这种方式开始并与C#和.NET团队分享了一些关键的优化方法。 但不幸的是，在Midori的规模上，这种方法根本无法工作。 首先，请记住，Midori是一个为使用内存垃圾回收而编写的完整操作系统，对于充分发挥这一功能，我们收获一些必要的关键教训。 但我要说的是，主要方向是即使是短寿命的，也需避免像瘟疫一样多余的内存分配。 在早期有一个贯穿.NET的口头禅：Gen0代回收是免费的。 不幸的是，这种理念已经塑造了很多.NET库代码，并且是彻头彻尾的贯穿。Gen0的回收导致暂停和脏缓存，并在高度并发的系统中导致拍频问题。 然而，我要指出的是，在Midori规模上进行垃圾收集工作的一个技巧恰恰是细粒度的进程模型，因为其中每个进程都有一个独立的堆，可以独立地进行回收。 我将有一篇专门介绍我们如何通过垃圾回收器获得良好表现的文章，但这是最重要的架构上的特征。 因此，首要的关键优化是：async方法不应该分配任何内存。 我们及时与.NET分享了这一经验，以便于C#中await的发布。 可惜的是，在那时，.NET的Task已经成为了一个类。 由于.NET要求异步方法的返回类型为Task，使得它们无法零分配，除非你不遗余力地使用类似缓存单例Task对象之类的笨拙模式。 第二个关键优化是：确保await所分配的async方法尽可能少。 在Midori中，一个async方法被另一个async方法所调用是非常常见的，同时它也可能调用了另一个async方法……依此类推下去。 如果考虑状态机模型中所发生的情况，则阻塞的最末端方法会触发级联分配的复杂度为O(K)，其中K是await发生时堆栈的深度，而这将是非常糟糕的情况。 我们最终采用的是一个只在await发生时分配的模型，并且只为整个这样的调用链分配一次，我们将此链称为“activity”。最顶层的async划分了activity的边界。 因此，async可能会产生一些开销，但await却是零开销的。 因此，这需要一个额外的步骤，而这一点却是最重要的。 最终的关键优化是确保async方法尽可能地减小开销， 这意味着它消除了状态机重写模型的一些不太理想的地方。 但是在实际中，我们最终弃用了它，其原因在于： 它完全破坏了代码质量，阻碍了像内联这样的简单优化。因为很少有内联使用者认为，带有多个状态变量的switch语句，并加上堆分配的显示框架（display frame），再包含大量局部变量的复制的过程，是一个“简单的方法”。由于我们与使用原生代码编写的OS进行竞争，因此这一点很重要。 它需对调用约定进行修改。也就是说，返回的必须是Async*&lt;T&gt;对象，就像.NET的Task&lt;T&gt;一样。 这并非易事，即使我们返回的是结构并消除了分配的问题，而它们返回的是多字且要求代码通过状态和类型测试来获取值。也就是说，如果我的async方法返回的是int值，那么我也希望生成的机器码也TMD返回int值。 最后，一个普遍的问题是捕获的堆状态过多。而我们希望等待中的activity所消耗的总空间尽可能小，除了在它们之间不断切换的一些进程之外，一些进程通常最终会包含数百或数千个轻量级进程。 出于占用空间和缓存的原因，它们作为人工精心编写的状态机应保持越小越好，而这一点非常重要。 我们构建的模型是异步activity在链接堆栈（linked stack）上运行。 这些连接从小到128字节开始，并可根据需要进行增长。 经过多次实验，我们采用了一个每次链接大小加倍的模型：也就是说，首个链接大小是128字节，然后是256字节…直到最大为8K大小的块。 对此功能的实现需要编译器的深度支持，它也确实表现良好。 编译器知道何时进行链接检查，特别是在循环之外，并且（考虑到内联）当它可以预测堆栈帧大小时会探测更大数量的链接。 但是链接存在一个常见问题，即最终可能会进行频繁地重新链接，尤其是在循环内函数调用的边缘处。但是上述的大多数优化都阻止了这种情况的出现，而且，即使这种情况发生了，我们的链接代码也是由人工编写的汇编代码——IIRC，用于链接的三个指令，另外我们也一直关注于可以重用的活跃链接段。 除此之外，我们还获得了其他的重要创新。 还记得我之前曾暗示过，仅通过async关键字可以判断出，静态地知道函数在类型系统是否是异步的。这使我们能够在编译器中执行经典堆栈上的所有非异步代码，使得最终结果是所有同步代码都保持无探针状态！ 而另一项创新是OS内核可以在一组堆栈池中调度所有同步代码， 这组堆栈池总是处于活跃状态，这一点类似于经典的线程池，但不局限于OS调度程序。因为线程从未被阻塞，所以不会导致堆栈成为O(T)，其中T是整个系统中活跃的线程数，相反，你最终得到的堆栈大小是O(P)，其中P是机器上的处理器数量。 回想一下，消除按需分页也是达到这一目标的关键，所以这些真是一堆“大赌注”，所有这一切加起来足以形成革命性的成果。 消息传递 到目前为止，系统中尚未提及的基础部分是：消息传递。 进程不仅是超轻量级的，而且在本质上是单线程的。 由于系统的非阻塞特性，每个进程都运行了一个无法被阻塞的事件循环（event loop）。 它的任务是执行一段非阻塞的程序，直到程序结束或通过await挂起等待，然后再获取下一个任务，依此类推。之前处于等待状态的await如果事件被满足，这将被调度为新的转动曲柄。 曲柄的每次这样的转动被恰如其分地被称为“旋转”。 这意味着在旋转只可能发生在异步activity和await等待点之间，使得并发的交织只可能发生在定义明确的点上。 这对于面向并发的状态推理来讲是一个巨大的福音，但它也带来了一些陷阱，对此我们将稍后进行探讨。 然而，这种方式最大的优势是进程间不存在共享内存的竞争条件。 我们确实开发了一个任务和数据并行框架，其利用了我之前提到的语言的并发安全功能——不变性，隔离和只读注解——来确保不违反这种数据竞争的自由度，这被用来进行使用额外计算能力的细粒度计算。然而，大多数系统通过分解成通过消息传递连接的进程来进行并行执行。 每个进程都可导出异步的接口，它看起来类似如下： async interface ICalculator { async int Add(int x, int y); async int Multiply(int x, int y); // 等等... } 与大多数异步RPC系统一样，从该接口可以生成服务器stub和客户端代理的代码。 于服务器端，我们需实现如下接口： class MyCalculator : ICalculator { async int Add(int x, int y) { return x + y; } async int Multiply(int x, int y) { return x * y; } // 等等... } 正如我在前一篇文章中所描述的那样，每个服务器端对象也可以，像程序的主入口点那样，仅地通过暴露构造函数的方式来请求获取权能。而我们的应用程序模型则会处理好激活和连接服务端程序和服务。 服务器还可以在其自己的进程或远程进程中返回其他对象的引用， 而系统与垃圾回收器一起协调管理对象的生存周期状态。 因此，例如有一个如下的MyTree对象： class MyTree : ITree { async ITree Left() { ... } async ITree Right() { ... } } 你可能已经猜到，客户端将获得代理对象的引用，该对象连接到在进程中运行的此服务器对象。 服务器可能与客户端处于相同的进程中，但通常情况下对象可能物理位置相距很远，这是由进程间通信方式所决定的： class MyProgram { async void Main(IConsole console, ICalculator calc) { var result = await calc.Add(2, 2); await console.WriteLine(result); } } 想象一下如果Calculator是系统服务，则该程序将与该系统服务通信来求两个数字之和，而后将结果打印到控制台（该过程本身也可能是另一个不同的服务）。 系统的一些关键特征使得消息传递非常高效。 首先，跨进程通信所需的所有数据结构都处于用户空间态，因此不需要到内核模式进行转换，事实上，他们大多是无锁的。 其次，该系统使用一种称为“流水线”的技术来消除消息往返和同步回传。 在通道填充满之前，可以将批量消息填充到通道中，使得消息每次一批一批地传递。 最后，一种称为“三方切换”的新技术被用来缩短参与消息传递对话的各方之间的通信路径，该方法省去了在通常系统中仅负责简单地中转消息得中间人，因为它除了增加延迟和开销之外不具有任何价值。 跨消息传递边界的可编组类型（可消息传递的数据类型）包括： 基本类型（int，string等）。 不包含指针（明确标记为可编组）的自定义POD。 指向流的引用（见下文）。 指向其他async对象的引用（例如，上文中的ICalculator）。 特殊的SharedData对象，对此需要更多的解释。 上述的大部分内容是显而易见的，然而，SharedData则有点微妙。Midori的整个构造过程都采用了“零拷贝”的基本理念，这是未来其中一篇文章的主题，也是让我们在一些关键的基准测试中超越许多经典系统的秘诀。 但其中主要的思路是，如果可以避免则不应该复制任何数据。 因此，我们不希望在进程之间发送消息时以复制的方式编组byte[]。 SharedData是一个自动重新计数的指针，指向进程之间共享堆中的不可变数据，操作系统内核管理该堆内存并在所有引用计数为零时对其进行回收。因为引用计数是自动完成的，所以保证了程序不会出错，这充分利用了我们语言中的一些新功能，如析构函数等。 同时，我们还有“近对象（near objects）”的概念，它采取了额外的步骤，可在同一进程堆中对不可变数据的引用进行编组， 使得可以通过引用来编组富对象。 例如： 12345678// 堆中的异步对象：ISpellChecker checker = ...;// 堆中的复杂的不可变的Document对象，可能使用了其他的table：immutable Document doc = ...;// 通过在自身进程中发送消息来对Document进行check，而无需复制：var results = await checker.Check(doc); 你可以猜到，所有这些都建立在一个更为基本的“通道（channel）”概念之上，这与你在Occam，Go和相关的CSP语言中看到的相类似。 我个人发现消息是如何在系统周围浮动的结构和相关检查比直接编码到通道本身更舒适，但你的自身体验可能会有所不同。其结果与使用Actor的编程相类似，只是在进程和对象身份之间的关系方面存在一些关键差异。 流 我们的框架有两种基本的流类型：Stream持有一个字节流，而Sequence &lt;T&gt;持有数据T。 它们都是前向的（我们有其他的可seek类）和100%纯异步的。 你可能会问，为什么有两种类型？它们从完全独立的类开始，最终收敛到一起，彼此共享了许多策略及实现。然而，它们保持完全不同的根本原因是，如果我们知道只是简单地处理原始字节流，那么与完全泛型的版本相比，可以在实现中做出很多有趣的性能改进。 但是，为了讨论方便，这里你需认为Stream和Sequence&lt;byte&gt;是相互同构的。 如前所述，我们还有IAsyncEnumerable&lt;T&gt;和IAsyncEnumerator&lt;T&gt;类型。这些是代码中想要对流进行消费时，需要进行编码的最通用接口。当然，开发人员可以实现自己的流类型，特别是由于我们在编程语言中使用了异步的迭代器。 一整套的异步LINQ运算符可以在这些接口上工作，因此LINQ可以很好地用于消费和组合流和序列。 除了基于可枚举的流消费技术之外，还提供了所有标准瞥见和批处理的API。 然而，需要重点指出的是，整个流框架是构建在内核的零拷贝基础之上，以避免不必要的复制。 每当我在.NET中看到一个用byte[]来流处理的API时，我就会流下眼泪。 最终的结果是我们的流实际用于系统非常基础的区域，如网络堆栈本身，文件系统，Web服务器等。 如前所述，我们支持流API中的推（push）式和拉（pull）式并发，例如，我们支持采用以下方式的生成器： // 推：var s = new Stream(g =&gt; { var item = ... 做一些事情 ...; g.Push(item); }); // 拉：var s = new Stream(g =&gt; { var item = await ... 做一些事情 ；...; yield return item; }); 流的实现方法照本宣科地搞定了批处理的细节，并大体上确保了流式传输尽可能的高效。 一个关键技术是借鉴了TCP中的流量控制技术，流的生产者和消费者完全在抽象的框架下进行合作，以确保流水线不会过于的不平衡。在这一点上很像TCP的流量控制，通过维护所谓的“窗口”，随着可用性的来去不断打开和关闭控制阀门。 总的来说，这种方式很有效，例如，我们的实时多媒体栈中有两个异步的流水线，一个用于处理音频，另一个用于处理视频，并通过将它们合并在一起，以实现A/V同步。 总的来说，内置的流量控制机制能够有效地防止丢帧的情况发生。 “重大”的挑战 以上的内容像是一场匆忙的旅行， 我故意忽略了其中一些关键细节，但希望你能获得整体的轮廓。 在这次旅程中，我们发现了几个“重大的挑战”。 我永远不会忘记它们，因为它们连续三年组成了我整个年度绩效评估的大体轮廓。 我决心征服他们，虽然不能说我们的成果是完美的，但我们确实在此做出了巨大的改进。 Cancellation（取消） 对可取消任务的需求已经不是什么新鲜事， 对此我设计了.NET中的CancellationToken抽象，其主要目的是解决我们之前围绕带有“隐式范围（implicitly scoped）”的环境权限所面临一些挑战。 Midori与.NET的不同之处在于其具有的规模，使得其异步的任务无处不在，不仅跨越多个进程，甚至是还是跨主机之间的。 追踪失控的任务是一件非常困难的是，我的一个简单例子是，如何可靠地实现浏览器的“取消”按钮。 由于简单地渲染网页便涉及数个浏览器自身的进程，以及各种网络进程——这包括NIC的设备驱动程序，以及UI堆栈等等。 能够立即可靠地对所有这些工作执行取消操作不仅具有吸引力，并且也是必需的。 其解决方案最终建立在CancellationToken的基础之上。 其关键创新在于首次在我们的整体消息传递模型上重建了CancellationToken的思想，并在所有正确的位置使用它。 例如： CancellationToken可以扩展它们的范围实现跨进程； 整个async对象可包含在CancellationToken中，并用于触发撤销操作； 可使用CancellationToken调用整个async函数，以便取消其向下传播； 存储像这样的区域需进行手动检查以确保状态保持一致。 总之，我们采用了“整体系统”的方法来解决整个系统中的取消问题，包括扩展跨进程取消的范围。 我对我们采用的这种思路非常满意。 状态管理 可以通过一个简单的例子来说明可能会出问题的“状态管理”： async void M(State s) { int x = s.x; await ... something ...; assert(x == s.x); } 那么问题是，断言会触发吗？ 答案显然是肯定的。 即使没有并发，重入也会是一个问题。 根据我在“await … something …”语句中所做的事情，s所指向的State对象可能会在返回之前发生变化。 但有些微妙的是，即使“await … something …”没有改变对象，断言可能也会触发，考虑如下的一个调用： State s = ...; Async&lt;void&gt; a = async M(s); s.x++; await a; 调用者保留同一对象的别名。 如果等待中操作M需要等待，则控制权将重新交还给调用者， 而后，调用者在等待M完成之前将x递增。 不幸的是，当M恢复时，它会发现x的值不再与s.x的值相匹配。 这个问题以其他更加隐蔽的方式表现出来。 例如，回想一下之前的那些服务对象： class StatefulActor : ISomething { int state; async void A() { // 使用状态A } async void B() { // 使用状态B } } 设想一下，A和B都包含await操作，除了多次自我激活的交错之外，它们还可相互交错。 如果你认为它们看起来像是一对竞争条件，那你猜对了。 事实上，如果说消息传递系统没有竞争条件是一个彻头彻尾的谎言，甚至有一些论文在Erlang的背景下讨论该问题。 因此，说我们的系统没有数据竞争条件更为正确。 无论如何，这里是有竞争冒险存在的。 其解决方案也从经典的同步方法中得到启发，并应用以下多种技术之一： 隔离 标准同步技术（防止写后写或读后写冒险）。 事务处理 直至今日，我们更喜欢隔离。 事实证明，Web框架提供了很好的，可供学习的教训： 大多数情况下，服务器对象是“会话”的一部分，不应该跨多个并发客户端使用。 它往往很容易将状态划分为子对象，并使用它们进行会话。我们围绕可变性的语言注释有助于指导这一过程。 三者中较少考虑的技术是同步。值得庆幸的是，在我们的语言中，我们知道哪些操作存在读与写的竞争，因此可以利用它使用标准读写器加锁技术智能地阻止调度消息。这看起来是个很不错的方法，但如果做得不正确可能导致死锁（对此我们将尽力检测）。 正如你所看到的，一旦你采用了这个方法，世界就不那么优雅了，所以我们不鼓励使用它。 最后，对于事务处理，我们根本没有对其进行实践过，因为分布式事务是邪恶的。 总的来说，我们尝试从互联网上学习，并应用适用于大规模分布式系统的架构。 无状态的方法是迄今为止最简单的模式，而隔离紧随其后，其他一切方式都显得有点脏。 备注：未来我一定会写一篇专门讨论语言注释的文章。 有序性 在分布式系统中，除非你不遗余力地保持有序状态，否则事物会是无序的。 并且不遗余力地保持有序状态会消弱系统的并发性，增加状态的记录开销和大量复杂性。 于此我学到的最大教训是：分布式系统是无序的。 这糟糕透了，不过不要去试图打败它，否则你会后悔尝试的。 Leslie Lamport有一篇关于该主题的经典必读文章：Time, Clocks, and the Ordering of Events in a Distributed System。 但无序的事件却让开发人员感到意外。 下面是一个很好的例子： // 三个异步对象：IA a = ...; IB b = ...; IC c = ...; // 让b与a交互：var req1 = async b.TalkTo(a); // 让c与a交互：var req2 = async c.TalkTo(a); await Async.Join(req1, req2); 如果你认为b在c与a交互之前理应与a交互，那么你将陷入非常糟糕的一天。 我们提供控制顺序的机制。 例如，你可以刷新通道中的所有消息，并等待消息回传。 当然，你随时可以await某个操作，但由于往返操作会引入一些不必要的延迟。我们还有一个关于“流”的抽象，采用最有效的方式，保证一系列异步消息按顺序传递。 与状态管理层一样，我们发现大量的有序性问题的存在往往表明设计上出了问题。 调试 在早期，由于在系统中存在大量的任务，调试也是一项挑战。 与许多此类挑战一样，解决方案是使用工具。 在我们的工具中，activity和线程一样作为一等公民而存在。 同时，我们引入了跨进程的消息传递的因果ID，因此如果从一个进程中进入消息调度，则可能会在其他远程进程中追溯到消息源。 进程崩溃的默认行为是收集此跨进程堆栈追踪（stack trace），以帮助开发者找到目标位置。 我们改进后的执行模型的另一个巨大好处是堆栈又回来了，没错，你实际上有异步activity的堆栈跟踪等待多个级别，而无需额外开销。像.NET这样的许多系统都不得不竭尽全力将来自不同类似堆栈对象的堆栈跟踪拼凑在一起。虽然我们在跨进程中也遇到了该挑战，但在单个进程内部，所有activity都有正常的堆栈跟踪并且变量处于良好的状态。 资源管理 在某种程度上，我收获了一个重要认识，传统系统中阻塞方法可作为提供给系统所有任务的自然节流措施。默认情况下，你的普通程序并不能表达其所有潜在的并发性和并行性，但我们的系统的确做到了，虽然这听起来像是一件好事，事实上也确实如此，但它带来了暗黑的一面。在面对如此多的情况时，你到底如何管理资源并智能地调度所有任务？ 这是一条蜿蜒曲折的道路，我不会声称我们已经彻底解决， 甚至都不会声称靠近这个目标。 我只会说，在这个问题对于系统的稳定性来说比其他情况所造成的灾难性都要小。 我过去在Windows和.NET Framework的线程池上遇到了类似的问题，鉴于任务项可能会在线程池中阻塞，那么将如何一次性确定保持活跃状态的线程数？总有不完美的启发式方法可以使用，那么我可以说我们的方法并没有变得更糟。 如果真的有的话，那么错误地使用较多的潜在并行性，可用资源变得饱和可以算作一个。 以100%的CPU利用率运行Midori系统是很常见的，因为它正在运行有意义的任务，而这在PC和传统应用程序中非常罕见。 但我们问题的规模比我见过的任何系统都要复杂得多，因为所有的一切都是异步的。 设想一下，如果某个应用程序遍历整个文件系统，并为磁盘上的每个文件执行一系列异步操作。 在Midori中，应用程序，文件系统和磁盘驱动程序等都是不同的异步进程。 那么很容易想到会产生类似fork炸弹的问题。 因此，这里的解决方案可分解为双管齐下的防御措施： 自我控制：异步代码明白它可能会使系统充满任务，并明确地尝试避免这样做； 自动资源管理：无论用户编写什么样的代码，系统都可以自动加以控制。 出于显而易见的原因，我们倾向于自动资源管理 这采用了决定要访问哪些进程，决定哪些进程运行的OS调度程序的形式，以及在某些情况下，像流控制这样的技术，就像我们在上面看到的流一样。这是我们最“开放式”和“未解决”的研究领域。我们尝试了许多非常酷的想法，这包括尝试对异步activity的预期资源使用进行建模（类似于关于凸优化的论文）。事实证明这非常困难，但如果你能将它与自适应技术相结合，肯定会获得一些有趣的长期回报。也许令人惊讶的是，我们最有希望的结果来自于使广告竞价算法适用于资源分配，再加上博弈论的要素，使得这种方法变得非常有趣。如果系统收取所有系统资源的市场价值，并且系统中的所有代理商都具有有限的“购买力”，我们可以预期他们将根据可用的市场价格购买那些最有利于自己的资源。 但自动管理并不总是完美的，这就是自我控制发挥作用的地方。程序员也可以通过使用诸如“wide-loops”之类的简单技术，来限制未完成的activity的最大数量。wide-loops作为一个异步循环，其中开发人员指定了最大的未完成迭代数量，系统确保它不会立刻超过此计数的启动值。 虽然总觉得有点俗气，但加上资源管理，就足够了。 我可以说我们并没有栽在这里，虽然我们真的以为我们会栽于此。 但我也不得不说这是所有问题的解决方案中我最不满意的一个，不过这方面仍然是创新性系统研究的沃土。 放松一下 确实有太多的内容适合放进这篇文章中。正如你所看到的，我们将“无处不在的异步”发挥到了极致。 与此同时，世界也经过漫长的发展，比我们开始时更接近这个模型。 在Windows 8的开发中，异步API的引入是其中一个重点，就像在C#中添加await一样，我们在当时提供给了他们，我们自己的经验和教训。我们正所做事情对其造成了一点影响，但肯定没有达到上面所描述的水平。 所产生的系统以与标准含义完全不同的方式自动地进行并行。 大量的微小进程和大量异步消息确保了系统不断前进，即使面对网络等可变延迟操作也是如此。 我最喜欢的一个演示，是向史蒂夫·鲍尔默展示我们在自己的多媒体栈上模拟Skype的实现，即使再怎么尝试它也不会出现挂起现象。 尽管我想继续研究架构和编程模型相关的主题，但我却认为需要退后一步， 因为我们的编译器在前文中的很多方面不断出现，它也是我们的秘密武器。 我们在编译器上所使用的技术使我们能够实现所有这些更宏大的目标， 没有这个基础，我们就永远不会同时实现安全性和原生代码。下次当我们深入地探讨编译器时再见！]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>操作系统</tag>
        <tag>Midori</tag>
        <tag>翻译</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Midori博客系列翻译（2）——对象即安全权能]]></title>
    <url>%2F2018%2F11%2F18%2Fmidori%2F2-objects-as-secure-capabilities%2F</url>
    <content type="text"><![CDATA[在上一篇博客中，我们已经看到Midori是如何建立在类型，内存和并发安全的基础之上的。 在本文中，我们将看到它们又是使一些新颖的方法来实现安全变得可能，也就是说，这些方法让我们的系统消除了环境权限和访问控制问题，有利于编织到系统及其代码的结构中的权能之上。 与我们的许多其他原则一样，这种保证是通过编程语言及其类型系统“从构造”处提供的。 权能 首要的问题是，权能究竟是什么？ 在我们大多数人都知道和喜爱的安全系统中（例如UNIX和Windows），授予做某事的许可是基于身份的，通常以用户（user）和组（group）的形式出现。 某些受保护的对象（如文件和系统调用）具有附加到这些身份的访问控制方法，这些控制限制了哪些用户和组可以使用该对象。在运行时，操作系统使用环境标识，如正在运行当前进程的用户，基于这些访问控制来检查是否允许执行所请求的操作。 为了说明这个概念，考虑对open API进行如下简单的C语言调用： void main() { int file = open(&quot;filename&quot;, O_RDONLY, 0); // 与`file`进行交互... } 在内部，此调用将查看当前进程的标识，给定的文件对象的访问控制表，以及相应地允许或拒绝调用的标识符。 有大量的机制用于模仿用户的各种机制，例如UNIX上的su和setuid操作以及Windows上的ImpersonateLoggedOnUser操作。 但这里的主要问题是open仅仅是“知道”如何检查一些全局状态，以了解所请求操作的的安全含义。另一个有趣的方面是传递了要求进行只读访问的O_RDONLY标志，这也会影响对授权过程产生影响。 呃，那么这有何问题呢？ 问题在于基于环境权限的访问控制这是不精确的，它依赖于对程序不可见的环境状态，因此无法轻松地对操作存在的安全隐患进行审计。 你只需要知道open是如何工作的，而且正是由于不精确，所以很容易出错，而错误通常导致安全漏洞。 具体来说，它很容易伪装成用户并欺骗程序做一些从未打算做的事情。 这被称为“混淆代理人问题”。你需要做的就是欺骗shell或程序以冒充超级用户，那么就几乎可以做任何特权操作。 相反地，基于权能的安全性不以同样的方式依赖于全局权限。 它使用所谓的“不可伪造的令牌”来表示执行特权操作的能力。 无论决策是如何制定的，都存在一个完全复杂的策略管理主题和关于社会和人类行为的授权行为。总的来说，如果软件无意执行某些操作，它根本就不会收到执行这些操作所需的令牌。 并且由于令牌是不可伪造的，程序甚至无法尝试操作。在像Midori这样的系统中，类型安全也意味着程序不仅不能执行未授权的操作，而且通常会在编译期间捕获这些操作。 在编译时拒绝了不安全操作，这有多酷！ 正如您可能已经猜到的那样，之前假设的open API看起来会非常不同： void main(File file) { // 和`file`交互... } 好的，显然我们不再是在基于环境权限的访问控制范畴内了，那么事情将变得非常不同。 我刚刚没有提到的是，这里的其他部分（调用者）必须获得一个File对象，那他们又是如何得到的？ 老套的回答是，没有人会谁在乎，获得的方式完全取决于调用者。但是如果他们确实持有File句柄，那么它们必须被授权访问File，因为在类型安全的系统中，对象引用是不可伪造的。 策略和授权的问题现在被推到可以说它们本来就属于的源头处。 我想我可能过度简化了一点，因为这个回答可能会产生更多的问题。 那么让我们继续深入分析。 那么，让我们再问一个问题：如何获得File对象？ 上面的代码既不知道也不关心File来自何处。 它只知道给它一个具有类File的API的对象。 它可能是由调用者通过new操作获得， 更有可能的情况是，它是通过调用一个单独的实体获得的，比如文件系统或目录，而这两个实体也都是权能对象： Filesystem fs = ...; Directory dir = ... something(fs) ...; File file = ... something(dir) ...; MyProgram(file); 你现在可能真的会对我生气了。fs又来自哪里？我又如何从fs获取Directory对象？我又是如何从dir获取File对象的？我刚刚把所有有趣的话题都挤到一起，就像水球一样，但却什么都没回答！ 现实情况是，当你尝试使用权能设计文件系统时，这些都是你现在将遇到的所有有趣问题。你应该不希望允许用户自由地在整个文件系统层次结构上进行枚举访问，因为如果用户可以访问Filesystem对象，或系统的根目录，那么它其实可以以向下传递的方式访问所有内容。这就是你开始和权能打交道时所做的那种想法。您认真考虑信息封装和曝光，因为您所拥有的只是保护系统安全的对象。也许，你会有一种方法，一个程序请求在文件系统的某个地方请求访问某个状态，声明，然后“权能母体”决定是否给你。这是我们的应用程序模型所扮演的角色，主要是如何main掌握程序清单所需的权能。从那时起，它只是对象。关键是整个系统中没有任何地方可以找到经典的环境权威，因此这些抽象都不能在其构造中“作弊”。 Butler Lampson的一篇经典论文“Protection”清楚地阐明了一些设计上关键基本原则，例如不可伪造的令牌。 从某种意义上说，我们系统中的每个对象都是它自己的“保护域”。如果想了解更多的细节（或者错误地任务访问控制列表和基于权能的系统是等价的），那么我也推荐“Capability Myths Demolished”中权能与经典安全模型进行比较和对比的方式。 Midori绝不是第一个以对象权能为核心构建操作系统的系统。事实上，我们从KeyKOS及其后继者EROS和Coyotos中获得了重要的灵感。 这些系统像Midori一样，利用面向对象方式来提供权能，我们很幸运的是能够在团队中拥有这些项目的一些最初设计者。 在继续讨论之前，按顺序发出警告：即使某些系统不是真正的权能系统，它们也会混淆地使用“capability”这个术语。 例如，POSIX定义了这样一个系统，因此Linux和Android都继承使用了它。 虽然POSIX的“权能”比典型的经典基于环境状态和访问控制机制表现更好，因为它实现了比这些方式更细粒度的控制，但它们确实比我们在这里讨论的真正权能更接近经典模型。 对象和状态 作为对象的权能的一个好处是，你可以将有关面向对象的现有知识应用于安全和权限领域。 由于对象代表着权能，因此它们可以如你所希望的那样进行细粒度或粗粒度控制。您可以通过合成方式创建新的权能，或通过继承方式修改现有的权能。 依赖关系的管理方式与面向对象系统中的任何依赖关系一样：通过封装，共享和请求对象的引用。 因此你可以在安全领域利用各种经典的设计模式。 但我不得不承认这个想法过于简单，以至于使某些人感到震惊。 一个基本的想法是撤销（revocation）。 对象是具有类型的，我们的系统允许使用另一个实现来替换现有的实现。 这意味着如果你向我请求一个Clock对象，我无需在任何时候都向你授予访问时钟的权限，我甚至都不需向你提供真正的Clock对象。 相反地，我可以向你提供我自己实现的一个Clock子类，它作为真正Clock的代理，并可以在某些事件发生后拒绝你的请求。 因此你必须要么信任时钟源，要么在在不确定的情况下，显式地保护自己免受攻击。 另一个概念是状态。在我们的系统中，我们通过在编译期间“从构造”的方式，在编程语言中禁掉了可变的静态变量。这是正确的，不仅静态字段只能被写入一次，而且它所引用的整个对象图在构造之后也将被冻结。 事实证明，可变静态变量实际上只是环境权限的一种形式，不可变静态变量可以阻止用户在全局静态变量中缓存Filesystem对象，并自由地共享它，从而构造出一些和经典安全模型非常类似，而且是Midori极力避免的东西。 不可变静态变量在安全并发方面也有很多好处，甚至给我们带来了性能优势，因为这种方式下，静态只是变成了更加丰富的常量对象图，可以在二进制文件中固化和共享。 完全消除可变静态变量对Midori系统的可靠性带来了难以量化和低估的改善，而这也是我最怀念的地方之一。 回想一下上面提到的Clock，这是一个极端的例子。但没错的是，它没有诸如C的localtime或C#的DateTime.Now的读取时间的全局函数，而为了获得时间，你必须显式地请求Clock权能，而这具有消除整个类函数中非确定性的效果。一个无需IO，即可以在类型系统中确定（想想Haskell的monad） 的静态函数，现在变得纯函数化、可记忆化并且甚至可以在编译时进行eval （这有点类似于constexpr on steroids）。 我将首先承认，这将存在一个逐渐成熟的过程，是开发者需要面对的，正如他们学习了对象权能系统中的设计模式。 权能的“大袋子”随着时间的推移而增长，以及在不合时宜的时候请求权能是很常见的。例如，设想存在一个秒表Stopwatch的API，它可能会需要Clock，那么你是否需要将Clock传递给需要访问当前时间的每个操作，例如Start和Stop？或者你是否预先构建了一个带有Clock实例的Stopwatch，从而将秒表对时间的使用进行封装，使其更容易传递给其他对象（重要的是，意识到这基本上向接收者赋予了读取时间的权能）。另一个例子，如果你的抽象需要15个不同的权能才能完成它的工作，那么它的构造函也需要使用15个参数的列表？这将是多么笨重和烦人的构造函数！相反，更好的方法是将这些权能逻辑地分组到单独的对象中，甚至可以使用父类和子类等上下文存储来简化它们的获取。 经典的面向对象系统的缺陷也给这种方式带来了弱点。 例如，向下类型转换（downcasting）意味着你不能完全信任继承作为信息隐藏的手段。 如果你请求一个File，而我提供了派生自File的CloudFile类，它向其添加了自己的类似公有云的功能，那么你可能会悄悄地向下转换为CloudFile并执行我不想要的操作。 我们通过对类型转换的严格限制，以及将最敏感的权能放在另一个完全不同的计划上来解决此问题…… 分布式权能 我将简要介绍在未来的帖子中需要进一步涉及的领域：我们的异步编程模型。 该模型构成了我们如何进行并发和分布式计算的基础，和我们执行IO的方式，以及与本文最相关的是，权能是如何扩展它们在这些关键域中的覆盖范围的。 在上面的Filesystem示例中，我们的系统通常在不同的进程中托管该Filesystem后面引用的真实对象。 这种方式下，调用一个方法实际上是将一个远程调用分派到另一个进程上，而进程为该调用提供相应的服务。因此，在实践中，大多数（但不是全部的）权能都是异步对象，或者更确切地说，是允许与服务交互的不可伪造的令牌，我们称之为“最终（eventual）权能”。而Clock却是一个反例，它是我们称之为“提示（prompt）权能”——它包含系统调用而不是远程调用。 但是大多数与安全相关的权能往往是远程的，因为大多数需要权限的操作通常会最终触及到IO上，而很少需要权限来仅仅执行简单地计算。 而实际上，文件系统、网络堆栈、设备驱动程序、图形界面以及更多的子系统都采用了最终权能的形式。 这种操作系统整体安全性的统一以及我们构建分布式的，高度并发的安全系统的方式，是我们最显著，最具创新性和最重要的成就之一。 我应该指出的是，就像通用权能的想法一样，类似的想法在Midori之前就已经存在。虽然我们没有直接使用，但是来自于Joule语言 和后来的E语言 的想法为我们提供了非常强大的构建基础。Mark Miller在2006年的博士论文是这整个领域的重要财富。 我们有幸与我曾合作过的最聪明的人之一密切合作，而他恰好是这两个系统的首席设计师。 封装起来 关于权能的优点还有太多地方可以说的。总之，类型安全的基础让我们大踏步前进，它产生了一种与环境权限和访问控制相比非常不同的系统架构。该系统以前所未有的方式将安全的分布式计算带到了最前沿。出现的设计模式确实充分利用了面向对象，也充分利用了各种看起来比以往更加重要的设计模式。 我们从未在该模型上进行较多的曝光。与策略管理等体系结构方面相比，面向用户的层面还未得到充分研究。例如，我很怀疑我们是否想在程序界面中提示我的母亲，她是否想让程序使用Clock。最有可能的方式是，我们希望自动授予某些权能（如时钟），并将其他权能通过组合的方式分组为相关的权能，而作为对象的权能幸运地为我们提供了大量已知的设计模式。我们的系统中确实有一些蜜罐，却没有一个被黑客攻击（好吧，至少我们尚不知道有被攻击成功过），但我无法确定最终系统的可量化安全性。因此我可以定性地说，在系统结构的许多层面上感觉具有更好的冗余安全性，但我们却没有机会大规模地加以证明。 在下一篇博客中，我们将深入研究贯穿于整个系统的异步模型。异步编程在当前是一个热门话题，例如await出现在C#，ECMAScript7，以及Python和C++等语言中。同时加上通过消息传递方式连接的细粒度分解的轻量级进程，可实现高度并发，可靠且高性能的系统，其异步性与所有这些语言一样易于使用。下篇博客见！]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>安全</tag>
        <tag>Midori</tag>
        <tag>翻译</tag>
        <tag>权能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Midori博客系列翻译（1）——三类安全性的故事]]></title>
    <url>%2F2018%2F10%2F24%2Fmidori%2F1-a-tale-of-three-safeties%2F</url>
    <content type="text"><![CDATA[Midori建立在三类安全性的基础之上，这包括：类型安全、内存安全和并发安全。 它们“从构造”上消除了的各类错误，并在可靠性、安全性和开发人员生产力等方面取得了重大改进。 另外，它们还从根本上允许我们以新颖强大的方式，依赖类型系统来提供新的抽象、执行最新的编译器优化等。 回顾过去，我们项目的最大贡献就是证明了整个操作系统及其服务、应用程序和库的生态系统确实可以使用安全的代码编写，同时不会损失性能，并且在数个重要维度上取得了一些重大突破。 首先，让我们按照基本顺序定义三类安全性： 内存安全禁止访问无效的内存区域。当破坏内存安全性时会产生多种缺陷，这包括缓冲区溢出，释放后使用（use after free，UAF）和双重释放（double free）等。一般来讲，违反内存安全性是严重的错误，可能导致代码注入等漏洞。 类型安全禁止以与内存分配时类型不一致的类型方式访问该内存。当违背类型安全时也会导致多种缺陷，这包括类型混淆，数据类型转换错误和未初始化的变量等。 虽然通常不如内存安全严重，但类型安全被破坏也可能导致漏洞，特别是当间接导致内存安全漏洞时。 并发安全禁止以不安全的方式并发使用共享内存。这些并发冒险以数据竞争，或读后写、写后读和写后写冒险的形式广为人知。一般来说，如果违背了并发安全性，常常会导致类型安全，进而内存安全被破坏。 并发安全的漏洞通常非常微妙，例如内存撕裂（memory tearing）等，因此我们认为并发性漏洞是可利用安全漏洞的“下一个热点领域”。 存在多种方法来构建上述三种安全性中的一个或多个，以及防止被破坏的安全手段。 软件故障隔离（Software fault isolation） 构建内存安全，作为对抗最严重攻击的措施，但这种方式也带来了一些运行时开销。尽管携带证明的代码可以减少开销，但这些技术也无法提供类型安全和并发安全。 另一方面，基于语言的安全，则是通过类型系统规则和局部检查（与全局相反的）体系来完成，通过推导的方式，该体系可确保不发生违反安全性的操作，再加上可选的运行时检查（例如在缺乏更强大的依赖类型系统时的数组边界检查）。 这种方法的好处是它采取一种通常更有效的方法来阻止安全漏洞，因为开发人员不是在软件运行时，而在编写代码时便可发现这些漏洞。 但是，如果你采取欺骗的方式使得类型系统允许非法得操作，你就完蛋了，因为没有后备措施可以阻止黑客们违反内存安全性以运行任意代码。 多种技术经常被结合一起使用，以获得这些技术的所有优点，这也被称为“深度防御”。 采用运行时安全的优秀案例包括Google的C++ sanitizer 和微软的“/guard”功能。 而采用基于语言的安全的不错的例子则包括C#、Java、大多数函数式语言和Go等。但是，我们也看到这种方式的不完备，因为C#有“unsafe”关键字允许违反安全性的不安全区域的存在。 那么，到底应该如何构建一个操作系统，其核心目的是，使用安全的编程环境来控制并行运行的硬件资源、缓冲区、服务和应用程序等所有可能造成不安全后果的例程？ 这是一个不错的问题。 答案非常简单：分层。 当然，系统中会有一些不安全的代码，而每个不安全组件都需要负责“安全封装”它自身的不安全性。 这说起来容易做起来难，而且肯定是系统中最难实现的部分。 这就是为什么所谓的可信计算基（TCB） 要始终保持尽可能小的原因。因此，不安全代码不应存在于操作系统内核和运行时之上的任何部件中，而应存在于微内核之上的极少部分。 没错，Midori的操作系统调度程序和内存管理器皆是用由安全代码编写而成的，并且所有应用级和库代码也肯定是100%安全，就像我们的Web浏览器一样安全。 有趣的是，依靠类型安全的方法中，编译器将成为TCB的一部分，因为虽然编译器是用安全代码编写的，但它仍需输出指令供处理器直接执行。 但这里产生风险可以通过携带证明的代码和类型汇编语言（TAL）等技术稍作补救，另外，添加运行时检查和软件故障隔离等方法，也可以减少部分风险。 我们的分层方法的一个很好的后果是系统构建在自己的基础之上，这将我们的关键原则发挥到了极致，而在我前面的一篇文章中对此也进行了一些介绍。 当你的操作系统内核、文件系统、网络栈、设备驱动程序、用户界面、图形堆栈、网页浏览器、网络服务器和多媒体堆栈……甚至编译器本身都是用你的设计的安全编程模型编写而成，那么可以非常肯定这种安全模型适用于你系统中的大部分的部件。 所以，你可能考虑所有这些安全性带来的开销有多大。简单的说，系统中总会存在那些如果没有指针运算和数据竞争等不安全操作就无法完成的例程。而我们所做的大部分工作都是为了尽量减少这些增加的开销。 我可以很高兴地告诉你，我们最终得到了一个具有竞争力的系统，在自身的基础上构建系统是保持这种竞争力的关键。事实证明，诸如无阻塞I/O、轻量级进程、细粒度并发、异步消息传递等架构决策带来的好处，远远超过了需要在全部堆栈保持安全性所带来的“较小”的开销。 例如，我们确实有某些类型只是存放数据的桶结构，但这些只是被动数据结构（POD）。 它们的存在使我们能够以高效且不会损失安全性的方式，从字节缓冲区中解析数据，以及在完全不同的类型之间来回转换。 例如，我们有作为一等公民的切片（slice）类型，它允许在缓冲区上形成安全和校检的访问窗口，并形成统一访问所有系统内存的安全方式（我们正在添加至.NET的切片类型的灵感也来源于此）。 你可能还会考虑支持类型安全所需的运行时类型信息（RTTI）的开销有多大。 好吧，多亏了POD，以及对可辨识联合合适的支持，使得我们无需进行太多的类型转换。而即使在我们进行类型任何地方，编译器都对结构进行了优化，因此最终结果并不比只支持虚拟调度（virtual dispatch）的典型C++程序要差（所以不要担心类型转换和它的开销）。 贯穿于整个过程的通用主题是，编译器技术在过去20年中已经发展得非常好。 在大多数情况下，安全性带来的额外开销可在很大程度上被优化掉，虽然这并不表示开销可以降到零，但在大多数程序中，我们能够让其控制在可接受的范围内。 并且，令人惊讶的是，我们发现了大量由于安全性所导致的新奇的优化方法！例如，类型系统中的不变性使得我们可以在多个堆和程序之间采用更积极的方式共享页面，以及采用合约的方式使优化器更激进地提升类型安全检查等。 而另一个有争议的方面是并发安全，特别是考虑到Midori项目开始时正好与2000年代后期令人兴奋的多核的发展相重叠。 你说什么，Midori没有并行性？ 需要注意的使，我未说我们完全禁止并发，只是我们禁止了不安全的并发。 首先，系统中的大多数并发采用在轻量级的软件隔离进程之间消息传递的方式进行表达。 其次，在一个进程中，我们通过强制类型系统和编程模型规则的方式来形式化安全共享内存的并行规则，其最终结果很自然地就禁止了编写具有共享内存数据冒险的代码。 这里推动形式化的关键内因是，不允许共享地址空间的两个“线程”同时看到同一个对象是可变的，也就是说多个线程可同时读取同一内存中，或者仅单个线程可写入，但不允许多线程同时写入。 我们的OOPSLA论文讨论了一些细节，Rust也取得了类似的成果并进行了很好地描述。 在多种细粒度并行的场景中，例如Midori的多媒体栈中，它都工作的很好。 在Midori以后，我一直致力于提供对于.Net以及C++而言如何同时实现安全性和性能的重要经验。其中最显著的产品是我们最近作为C++核心指南的一部分推出的安全配置（safety profiles）。 因为我们将.Net变成了跨平台的项目，所以我希望能在C# 7和我们正在进行的C# AOT的项目中展示更多内容。与Midori宛如真空的安全环境不同，其他这些环境（.Net和C++）则需要进行微妙的妥协，这虽然很有趣，但也减缓我们将这些想法实现到产品中的步伐，但我也很高兴开始看到在Midori的安全性上的工作终于接出了果实。 内存安全、类型安全和并发安全的结合为我们的开发提供了强大的基础。 最重要的是，它提高了开发人员的工作效率，使我们能够快速演进，因为导致严重后果的缓冲区溢出、数据冒险和死锁等安全漏洞在Midori中根本就不会发生。因此，（我相信）总有一天，所有的操作系统都会采用这种方式编写。 在本系列的下一篇文章中，我们将看到这种基本的安全性是如何提供了在编程模型和类型系统中担任一等公民的基于权能的安全模型（capability-based security model）的，以及“从构造”上消除环境权限（ambient authority）和默认在所有地方启用最小权限原则。我们下次再见！]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>安全</tag>
        <tag>Midori</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Midori博客系列翻译（0）——介绍]]></title>
    <url>%2F2018%2F10%2F20%2Fmidori%2F0-blogging-about-midori%2F</url>
    <content type="text"><![CDATA[已经离开了足够长的时间，因此我觉得在博客中谈论以前在微软的“Midori”项目是安全的。在接下来的几个月里，我将发表十余篇文章，以涵盖这个项目最有趣的方面，以及我认为的主要教训。 Midori是一个研究/孵化项目，它的目标是在整个微软软件栈上的探索可能的创新。其涵盖了包括编程语言、编译器、操作系统及其服务、应用程序和整体编程模型在内的所有方面。在该项目中，我们侧重于对云计算、并发和安全的考虑。同时，该项目包含了新颖的“文化”方法——全员开发以及非常专注于代码，因此它看起来更像是今天微软的样子，以及对微软未来所期望的模样，而不是8年前项目开始时的微软。 我于2009年开始在Midori项目工作，直到2012至2014年期间，团队中的各个成员相继离开而去了各自新团队。在这期间，我带领团队专注于面向开发者的体验，这包括编程语言、编译器、核心框架、并发模型和IDE工具等，同时也写了不少的代码。 虽然起初我们从C#和.NET技术开始，但在离开时Midori最终走向了对安全性、可靠性和性能的追求。而现在，我正在帮助将Midori的许多经验教训带回到交付的产品中，这也包括可能会令人惊讶的C++。因此，我的大多数博客文章都将重点关注于那些我们正尝试用于改善现有其他产品的关键教训，例如，无处不在的异步、零拷贝I/O、对安全和性能不可调和性的消除、基于功能的（capability-based）安全、安全并发、建立关于技术的辩论文化等。 我得首先承认，于初大家都不知道Midori会怎么样发展，因为研究通常就是这样。而我最大的遗憾是，从一开始就没有将它开源，因为开源可以很好地使互联网的各类优秀开发者对其进行评判。与所有其他大公司一样，围绕Midori核心技术命运的决策并非完全由技术驱动，并且可悲的是，甚至不完全由业务所驱动，于此也有一些重要的教训。我的第二大遗憾是我们没有发表更多关于Midori的论文，但该系列博客可能有助于重新阐述其中的部分内容。 在我发布新文章时，也将同时更新此列表： 三类安全性的故事 对象即安全权能 一切皆异步 安全的原生代码 错误处理模型 性能文化 关于并发的15年 Midori是一段迷人的旅程，也是我职业生涯中迄今为止最有趣的事情，因此期待与您分享这一旅程。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Midori</tag>
        <tag>翻译</tag>
        <tag>微软</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微内核的回归]]></title>
    <url>%2F2018%2F09%2F04%2FThe-raise-up-of-microkernel%2F</url>
    <content type="text"><![CDATA[（本文写于2018年初，但由于原博客不再维护，原始的Markdown文件也已丢失，于是我重新整理并添加了一些新的内容，再次发布到本博客中） 最近调研了操作系统近几年的发展，特别是微内核操作系统的发展，我越来越清晰地归纳出一个结论，如果操作系统未来还能有突破性发展的话，那也许是发生在微内核上。 首先要解释一下微内核和与之相对的宏内核是什么，以及两者的优缺点。微内核是指操作系统的最底层是一个包含最基本功能的kernel（内核），这个kernel通常只负责最基本的最底层的任务，如上下文切换、中断处理、进程间通信（IPC）和时钟处理等，而其他的系统任务，如硬件驱动，文件系统和内存管理都以用户态进程（即ring3）的形式运行，并且相互之间通过IPC进行通信；宏内核则与之相反，所有的系统任务均在内核态（ring0）处理，系统模块之间通过函数调用方式进行交互。这两个不同架构模式的操作系统概念自提出已经过去了三十年（最早的微内核系统是Mach，于1985年被提出，之前的操作系统都是宏内核，如Unix），工业界和学界普遍认为微内核的优势在于kernel很轻（通常C代码在10000行左右），因此攻击面和代码出错的可能性更低，而且大部分任务是以进程的方式运行，一旦出错只会影响到这个进程本身，稳定性更强，而宏内核与之相反，一个驱动的微小错误很容易导致整个系统崩溃。但是微内核最被诟病的是它的性能，因为一个简单的系统调用可能会涉及到多个系统任务，以及大量的IPC和相对应的上下文切换，这样的开销是巨大的，而在宏内核中，一次系统调用只需要两次上下文切换。关于宏内核和微内核有著名的“Linus Tanenbaum debate”，可以算的上操作系统设计和研究最佳的材料，值得反复阅读。 由于历史和性能的原因，我们日常接触到的操作系统，90%以上都是宏内核（包括类Unix和Windows，Mac OS X最初是基于微内核，但是最后也加了很多宏内核的方式），微内核一度仅仅局限于研究目的，除了QNX这种车载娱乐等专业领域上的操作系统之外。但是最近几年的微内核的发展以及不断涌现的新操作系统，可以说是给人耳目一新的感觉，这里简单介绍三个项目： seL4： 提到seL4，不得不提到L4微内核操作系统家族。因为Mach的IPC简直就是性能灾难，所以Jochen Liedtke提出了L3和后续的L4结构，对IPC的性能改进很大，甚至相比较Unix都有很大的性能优势。而seL4是在L4操作系统上，运用形式化验证（formal verfication）的方法来证明kernel在模型上的正确性。在其SOSP09的论文中宣称这是一个”bug free”的内核，它付出的代价也是巨大的，总共花了11person year 的工作量进行形式化验证。但是这样的付出对于一个严肃和safety-critical的系统是值得的，而显然这对于宏内核是完全不可能的事情。 Fuchsia：这是Google在2016年公开的一个项目，尽管Google一直没有对外公布它的目的和计划，但是它普遍被认为将用于取代Android系统，以求彻底解决Android及其底层的Linux kernel的各种历史问题。Fuchsia的底层Zircon本身是基于lk，而lk原本是一个嵌入式微控制器系统，最具有最基本的任务调度，同步原语等功能。但是Zircon在lk基础上构建各种系统服务，而Fuchsia又在Zircon上构建了图像化服务和其他应用程序，从最近的[测试视频][Fuchsia-demo上看，Fuchsia已经达到了基本可用的状态。 Redox OS：这是一个从2015年开始的开源微内核操作系统项目，它最大的特点在于完全使用rust（和少量必需的汇编）作为内核开发的语言，显示了rust在保持强大的表述能力的同时，对底层资源的操作也能灵活自如。但是让我最惊讶不已的是，Redox在仅两名核心开发人员（加上一些GSoc参与者）的条件下，用了不到三年的时间，已经差不多宣称要实现self-hosting，并具有比较完整的图形化子系统。这也从某种程度上显示了rust生态的威力。 当再一次从头比较微内核和宏内核的几个关键争论点，我惊讶的发现它们或多或少已经发生了改变，其一是性能问题，硬件和处理器得到了很大的发展，摩尔定律和多核技术使得硬件能力基本处于过剩状态，现在的大部分性能问题可以说是软件造成的（我还清晰地记得本科计算机原理课老师经常要把写软件的人拿出来批判一番……），而且L4在微内核本身的IPC性能已经有了长足的发展，就更没有理由认为微内核比宏内核性能更差。其二，越来越多的新场景，包括IoT，自动驾驶和区块链等，对操作系统的稳定性和可靠性提出了更高的要求，从CVE的统计中我们可以看出，Linux内核的漏洞数量基本呈逐年上升的趋势，虽然微内核并不能从根本上解决所有漏洞，但seL4给我们的启示是，通过形式化验证或模型检验的方式可以消除大部分kernel中的bug，而这些方法巨大的工作量，只可能在微内核上才可能被接受。另外，seL4和fuchsia中基于capabilities的权限验证，redox中rust提供的内存安全性等，都是提高系统安全性的有效方式，而这些方式似乎已经很难加入到现有的操作系统。 至于为什么没有一款真正的微内核操作系统进入大部分人的生活，我想这是因为既有的软件生态和强大的惯性。Linux和Windows在大部分时间里已经just work，我们没有理由也没有可能在现有场景下重复造轮子，更没法从零构建出如此庞大的生态。但是历史的车轮也在向前，新生事物也是在不断批判旧事物的基础上产生的，当系统需求和使用场景发生变化时也将相应的对软件设计提出新的要求。如部署于自动驾驶中枢位置的操作系统，对安全性和稳定性的要求将大于兼容性和灵活性，也行将是微内核发挥自己长处的地方，而我也期待着见证这个历史过程。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>微内核</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动驾驶需要什么样的软件平台]]></title>
    <url>%2F2018%2F09%2F04%2FThe-software-platform-of-autonomous-vehicle%2F</url>
    <content type="text"><![CDATA[（本文写于2018年初，但由于原博客不再维护，原始的Markdown文件也已丢失，于是我重新整理并添加了一些新的内容，再次发布到本博客中） 从2014年开始，互联网公司、传统车企以及大批创业公司纷纷进入自动驾驶领域。因为自动驾驶的5级中（L1-L5从易到难），实现L4/L5级别的难度不是一家公司可以搞得定的，所以在我看来，他们的切入点可以分为两个不同层次，传统车企和少部分创业公司，以及大量的传感器制造商走的是底层的硬件制造和设计路线，即如何改进（或重新设计）整车（或部分硬件模块）以适应驾驶无人化，因为他们具有多年的硬件经验，所以这是他们的强项；互联网公司和大部分创业公司，则走的是高层感知决策规划的路线，这些玩家要么手持大量数据，要么聚集大量算法（以当前最热门的深度学习和人工智能为代表的）人才。当然还有两种路线通吃的玩家，如特斯拉，自己不但设计和制造电动汽车还在此基础了开发了autopilot辅助驾驶套件，但是，特斯拉当前提供的确实辅助驾驶的L2技术，因此不在本文的考虑之列。 虽然自动驾驶是软硬件结合的平台，而且呈现出高度专业化的特点：即使有一天自动驾驶真的成为现实，也很难说需要成百上千万的自动驾驶开发人才，所以这使得它和传统服务器、移动互联网开发有很大的不同。但是我认为它依然遵循经典软件架构的基本模式，即：从计算机发展的历史上看，经典的系统架构，大体上都可以在垂直方向上分成三个不同层次，对于桌面和服务器系统，它们是硬件、系统软件和应用软件；对于移动和手持设备，它们是硬件、移动操作系统（Android，iOS等）和App；甚至对于云计算，我们都可以将其分为服务器、IaaS+PaaS（虽然IaaS和PaaS最初是上下两层，但从最近几年的云服务提供商发展趋势上看，两者的界限已经模糊）和SaaS。在自动驾驶的三层中，上下两层的玩家很多，中间软件平台层当前却不怎么欣欣向荣（其实也有，我未来会从技术角度一一点评），但是软件平台确也是不可或缺的一层。因此，在本文我想重点谈谈在自动驾驶领域，我们到底需要怎样的软件平台。 为了回答这个问题，我先提出另一个问题，对于自动驾驶，我最关心的是什么？毫无疑问，是它的安全性。一辆以超过100km/h的速度行驶在高速公路上的无人车，即使它的机动性能再好，内饰再豪华，娱乐系统再丰富，但是它无法保证安全性，我想也是没有人敢乘坐，因为对安全感的追求已经早已融入到每种动物的基因里，而人类也毫无例外。同时，我们也可以从另外一些侧面说明问题：想想Waymo号称已经路测500万公里，但是为何依然不能落地无人租车服务；打开任何一个自动驾驶的媒体公众号，稍微统计一下里面和安全性有关的文章数量，也许你就能明白。因此从安全性，这个第一性原理出发，不难推导出自动驾驶对软件平台的需求方向。虽说安全保证不能缺少在来自上下游的整车硬件和感知规划算法的配合，但本文中我们仅具体聚焦到软件平台上，我这里将其具体归纳为以下四个方面： 可靠性：当我们坐在一辆没有司机的汽车中，等于说我们将生命将完全托付给了它。传统软件中的bug可能只会让我们不开心，但是控制汽车的软件中的bug后果真的会要了我们的命。因此无人车上对软件的bug容忍度基本趋近于零，传统软件设计和测试中的鲁棒性理论将在这里发挥巨大的作用，SMT、形式化验证（Formal verification）、模型验证（Model checker），覆盖性测试等方法都在此将发挥作用。 实时性：来外部的突发事件（如突然钻出的行人）需要被平台及时捕获并得到处理，否则也是及其危险的，这里就需要软件在设计上体现其实时处理的特征。毫无疑问，实时系统（Real-time）对于自动驾驶平台也是极端重要的，而且这里的实时不是指面向用户流畅体验的软实时，而指的是“all or nothing”的硬实时，因此在操作系统层就不能使用Linux这样的无实时保证的操作系统。另外黑莓的QNX在智能手机上未能发展壮大，而自动驾驶对于它来讲可能是更适合的场景（最近百度和黑莓关于QNX的合作也印证了这一点）。 抗攻击性：自动驾驶软件平台本质上还是软件系统，一旦联网后也同样面临如何防御来自外部的恶意入侵。恶意入侵在无人车领域也不是什么新鲜事，而特斯拉已经被曝出能够被黑客远程启动。如何防漏洞，在我看来是一项系统工程，而且必须贯穿设计、实现、调试和维护等各个环节。我不是这个领域的专家，不过也会不断学习这方面的内容，并且分享我的心得和观点。 互联性：这里我将自动驾驶软件平台的互联互通分为以下三个角度: 软件平台和远程服务的互联：平台和远程服务，特别是云计算和大数据平台，已经被大家所熟知，具有代表性是利用远程的地图数据实现路径规划，和接入租车平台参与调度等，这需要平台提供完整的网络协议栈以支持，以及高效的网络处理能力，特别对5G网络和NB-IoT等物联网协议的支持，以后应该是平台支持的重点。另外，选择如DDS等有实时性保证的协议和标准，在其他的无人车平台的实践上已经有所探索，而这也是形成端到端的实时的必须的部分。 无人车和其他物理实体的互联；这其实是物联网的典型应用。无人车为了和其他物理实体，如道路、收费站和其他车辆，进行高效地交互，必然需要去中心化地本地通信机制和协议。顺便说一句，利用物联网的技术，很多传统行驶场景中的难题都变得迎刃而解，以后有时间我将专门写一篇文章探讨这些问题。同时，利用区块链技术进行去中心化的身份认证和共识，也是解决信任安全的有效手段之一。 软件平台内部各个模块的互联：现代软件平台必然是采用模块化设计，一个模块的信号消息（摄像头感知）如何能被另一模块（刹车制动）有效接受并得到及时正确的处理。虽说传统操作系统中这些问题已经研究很多（如IPC，message passing等），但是都较少涉及到消息传递的延迟（而较关注于吞吐量），但延迟才是无人车关注的重点，这些都是需要考虑的新问题。 当然，除了安全性的考虑，其他的一些软件平台的必要特性，诸如对硬件的全面支持、良好的模块设计、稳定且一致的文档和API、成熟的工具链和开发环境以及软件生态等， 都是题中应有之义，也都是未来需要逐一考量的方面。但是除了一些专业领域，如航天、飞行和军事等，还没有哪一个通用软件平台应该将安全性提升到如此高度，而这将极大地改变该软件平台的重心。 虽然最近不断有媒体在宣传某某公司将在一年，甚至几个月之内提供无人驾驶服务，但是我依然认同李飞飞教授在2015年的一个观点，L5的自动驾驶仅仅有望在10年内成为现实。因此还有很长的路要走，这反而对于定位于长远未来的软件平台设计来讲是一件好事，提供了充足的时间用来思考、演化、验证和试错。而对于传统软件架构设计、开发的方法论来说，这也是一次自我进化的机会。未来我也将不定期地更新博客，探讨我对自动驾驶软件平台设计的思考，以及它和其他技术、概念融合的一些想法。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>安全</tag>
        <tag>自动驾驶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Windows的UMS(User-Mode Scheduling)实现轻量级线程]]></title>
    <url>%2F2018%2F08%2F27%2Fusing-Windows-UMS-for-lightweight-threading-model%2F</url>
    <content type="text"><![CDATA[前几天在看关于Rust取消M:N线程模型背后的理性选择时候，看到Daniel Micay 的一篇帖子中提到了Windows的UMS功能，了解之后s觉得有点意思。所以就花了几天研究一下，分析了它的优缺点和基本性能情况，于是总结成此文。 背景UMS (User-Mode Scheduling)是微软在其Windows 7及其以后版本的64位操作系统中添加的一个功能，其目的是支持应用对申请的线程进行自定义管理，以此方式实现类似于轻量级线程的高效并发。 虽然在云计算领域，Linux成了事实上的基础操作系统平台，但没想到却是微软首先在其自家系统上实现了此功能，Google的开发者在Linux尝试了类似的实现，不过据我所了解，到目前为止都尚未进入Linux的主分支。 我们都知道，根据用户空间和内核空间的映射关系不同，线程模型可以分为以下三种： 1:1，即内核态线程：用户空间中的不同线程，分别对应到内核中的一个线程。所有的线程上下文都是由内核来管理，并且所有线程状态的改变，包括调度、I/O阻塞、page fault和信号事件等，都需要进行一次“上下文切换(context switch)”到内核空间中才能处理。Linux和Windows原生线程都是这种类型，它的优点是模型简单，而且能够透明地利用多核(multicore)进行并行处理，缺点是应对大规模的线程管理和并发乏力，因为大量的开销都花在了上下文切换上。 N:1，即用户态线程：用户空间中的多个线程，都对应于内核的用一上下文(context)，线程的切换不再需要进入到内核处理，可以直接由用户态的runtime进行管理，在多种编程语言（如Python，PHP等）中又称为“绿色线程(green thread)”。与内核态线程相反，这类线程的优点是可以支持大量并发，但是却没法直接扩展到多核上进行处理。另外，如果有某个线程需要I/O操作，或因缺页中断而被阻塞，所有的用户态线程都将一同被阻塞。所以，通常的语言级虚拟机都对此情况进行补救措施，例如使用专门的线程进行I/O操作，以及使用mmap等系统调用避免意外的缺页中断。 N:M，即混合线程：N个不同的用户态线程对应到M个内核线程上。这种模型是介于上述两种模型之间，看似可以兼顾两者的优点，实际上却产生了更多的问题。首先是模型变得复杂，不仅要考虑单个内核线程上的用户态线程的执行同步情况，而且还要考虑用户态线程可能在多个内核线程上的调度和同步，并且实际上并没有消除用户态线程的阻塞问题。所以在现实中使用混合模型的系统不是很多，比较典型的有golang和Haskell。 另外，一个比较容易想到的消除I/O同步阻塞的解决方案是使用异步IO，即线程不等待I/O处理子程序的完成便返回，事后再通过其他方式进行确认。不过这么好的方法怎么不去使用呢？Daniel Micay在[帖子][rust-thread]里提到，其原因有两点： 历史原因，大多数的依赖库都是采用同步阻塞I/O，并利用原生内核线程进行并发的方式，在它们的基础上还无法简单地进行异步的改造； 在操作系统发展的过程中，CPU的性能也在不断的改进，其中就包括上下文切换的性能，在该帖子中提到的他作的一个对比实验的结果表明，Rust的协程（我们知道，后来Rust把协程移除了标准库）和OS Thread在创建的开销上其实性能差别不大。 那么两种在上下文切换时开销差不都，但为什么实际系统中内核态线程在高并发上的性能又比协程差很多？这是因为大量的开销实际消耗在了位于内核态的线程调度上。通用操作系统内核为了支持多种不同计算场景（不只是高并发，还有实时计算场景等）下的综合性能，所以也需要较长的时间来调度（考虑是否要实时抢断，是否公平调度等）。但实际上，在云计算中，服务响应模型是比较简单的，通常简单轮询的调度都可以达到目的。 基于这样的事实，这就导致了Windows操作系统中UMS的产生。UMS中的线程依然是原生线程，但是在切换时，内核无需进入调度流程，直接将CPU控制权交给用户态我们自定义的调度器上。调度器可以根据应用的特点和需求做出更适合且高效的调度策略，选择一个线程执行，并将CPU的执行权交给它。在本文中，我们主要分析了一个基于pervognsen的代码片段的UMS轻量级线程调度的简单实现，并和基于系统调度的普通原生线程，以及Windows的Fiber库实现的轻量级线程，三者进行性能对比测试，从中了解UMS的一些基础性能情况。具体的实现请见Github仓库。 UMS概览相关数据结构 UMS工作线程(Worker thread)：执行具体计算任务的线程，它们和普通的原生线程几乎具有相同的行为方式，并且进行系统调用，I/O或异常处理等不会阻塞其他线程。 UMS调度器线程(Scheduler thread)：UMS调度器线程本质上也是一个普通的线程，它负责对其他工作线程进行调度，执行调度策略，但它的执行时机还是需要由Windows来确定。 线程上下文(Context)：UMS线程上下文表示工作线程的状态，用于标识UMS函数调用中的工作线程。它通过调用CreateUmsThreadContext进行创建的。 完成列表(Completion List)：完成列表接收已在内核中完成执行并准备在用户模式下运行的UMS工作线程。只有Windows才能将工作线程排队到完成列表中。新的UMS工作线程自动排队到创建线程时指定的完成列表，以前阻塞的工作线程在不再被阻止时也会排队到完成列表。调度器线程可以查询完成列表，从而知道哪些线程已经处于就绪状态，然后再将这些线程加入自己私有的就绪队列中。 UMS相关的API EnterUmsSchedulingMode：将调用线程转换为UMS的调度器线程。 CreateUmsThreadContext：创建UMS工作线程的上下文。 CreateUmsCompletionList：创建UMS完成列表。 GetUmsCompletionListEvent：检索与指定的UMS完成列表关联的事件的句柄。 UmsThreadYield：在工作线程中调用，放弃CPU控制权，并触发CPU进入UMS调度器线程。 ExecuteUmsThread：运行指定的UMS工作线程。 DequeueUmsCompletionListItems：从UMS完成列表中将一个事件移出队列。 QueryUmsThreadInformation：检索有关指定的UMS工作线程的信息。 SetUmsThreadInformation：为指定的UMS工作线程设置特定于应用程序的上下文信息。 核心流程的实现UMS工作线程和调度器线程UMS工作线程的创建需要通过CreateRemoteThreadEx函数，这个跟普通线程没什么区别。不过在创建的attribute参数中需要设置PROC_THREAD_ATTRIBUTE_UMS_THREAD属性，并将通过CreateUmsCompletionList创建的完成列表，传递给UMS_CREATE_THREAD_ATTRIBUTES类型的参数。例如： 123456789101112131415161718192021222324252627PPROC_THREAD_ATTRIBUTE_LIST attribute_list = (PPROC_THREAD_ATTRIBUTE_LIST) HeapAlloc(GetProcessHeap(), 0, attribute_list_size);InitializeProcThreadAttributeList(attribute_list, 1, 0, &amp;attribute_list_size);UMS_CREATE_THREAD_ATTRIBUTES ums_thread_attributes;ums_thread_attributes.UmsVersion = UMS_VERSION;ums_thread_attributes.UmsContext = ums_context;ums_thread_attributes.UmsCompletionList = scheduler_completion_list;UpdateProcThreadAttribute(attribute_list, 0, PROC_THREAD_ATTRIBUTE_UMS_THREAD, &amp;ums_thread_attributes, sizeof(ums_thread_attributes), NULL, NULL);HANDLE thread = CreateRemoteThreadEx(GetCurrentProcess(), NULL, stack_size, function, parameter, STACK_SIZE_PARAM_IS_A_RESERVATION, attribute_list, NULL); 应用的UMS调度器线程负责创建，管理和删除UMS工作线程并调度运行的UMS线程。它的创建过程是：通过CreateThread启动普通的线程，然后调用EnterUmsSchedulingMode函数将自身转换为UMS调度器线程类型： 123456789DWORD WINAPI SchedulerThreadFunction(void *parameter) &#123; UMS_SCHEDULER_STARTUP_INFO scheduler_info; scheduler_info.UmsVersion = UMS_VERSION; scheduler_info.CompletionList = scheduler_completion_list; scheduler_info.SchedulerProc = SchedulerCallback; scheduler_info.SchedulerParam = NULL; BOOL result = EnterUmsSchedulingMode(&amp;scheduler_info); return 0;&#125; 我们都知道，普通的原生线程在通过CreateThread创建后默认会直接参与调度并执行，而在UMS模式下，新创建的工作线程默认时不会马上运行，需要等到调度器线程选择它，并通过ExecuteUmsThread函数运行，例如： 1234567while (ready_queue.size() &gt; 0) &#123; PUMS_CONTEXT runnable_thread = ready_queue.front(); ready_queue.pop_front(); BOOLEAN terminated = FALSE; ExecuteUmsThread(runnable_thread);&#125; 调度子程序入口刚才我们的调度器线程函数中，设定了调度回调函数，SchedulerCallback，该函数是UmsSchedulerProc类型，具有如下的原型。1234void WINAPI UmsSchedulerProc( UMS_SCHEDULER_REASON reason, ULONG_PTR payload, void *parameter) &#123; 该函数在如下三个时刻由系统自动的触发执行： 通过调用EnterUmsSchedulingMode将非UMS线程转换为UMS调度线程时： 当UMS工作线程调用UmsThreadYield，主动放弃CPU的执行权时： 当UMS工作线程调用阻塞的系统服务（如系统调用或页面错误）时： UmsSchedulerProc函数的Reason参数指定调用入口点函数的上述三种不同的原因之一，以便于调度子程序能够根据不同的原因，进行不同的后续调度策略，例如：1234567891011121314switch (reason) &#123; case UmsSchedulerStartup: SetEvent(scheduler_initialized_event); break; case UmsSchedulerThreadBlocked: &#123; break; &#125; case UmsSchedulerThreadYield: &#123; PUMS_CONTEXT yielded_thread = (PUMS_CONTEXT) payload; void *yielded_parameter = parameter; ready_queue.push_back(yielded_thread); break; &#125;&#125; UMS最佳实践在实现UMS的应用程序时应遵循以下最佳实践： UMS线程上下文的基础结构需由系统进行管理，不应直接修改，而是使用QueryUmsThreadInformation 和SetUmsThreadInformation来检索和设置有关UMS工作线程的信息。 为了防止死锁，UMS调度器线程不应与UMS工作线程共享锁，这包括应用程序创建的锁和通过诸如从堆分配或加载DLL等操作间接获取的系统锁。 当大多数处理和计算在用户模式下完成时，UMS是最高效的，因为它尽可能避免在UMS工作线程中进行系统调用。 UMS工作线程不应假设正在使用系统调度程序，而应该考虑是被UMS调度器线程所调度。因此，不应使用系统API设置线程的优先级或亲和性。 系统可能需要锁定UMS工作线程的线程上下文。如果调度器线程在工作线程被锁定时尝试执行该线程，则调用将失败。所以调度器线程设计为，重试对该工作线程上下文的访问。 性能测试按照仓库中的文档 进行编译并运行测试程序。在我的笔记本（Lenovo Thinkpad X270，Intel i5-6200U的4核处理器和8G主存）上: 10个线程并发： yield数量 100 1000 10000 100000 Native thread 1201ns 633ns 640ns 632ns UMS 2752ns 400ns 148ns 118ns Fiber 96ns 105ns 101ns 88ns 100个线程并发： yield数量 100 1000 10000 100000 Native thread 769ns 610ns 601ns 591ns UMS 1428ns 245ns 152ns 128ns Fiber 130ns 105ns 102ns 102ns 1000个线程并发： yield数量 100 1000 10000 100000 Native thread 941ns 790ns 793ns 785ns UMS 1400ns 276ns 146ns 127ns Fiber 175ns 167ns 177ns 180ns 在少量线程（10或100）的情况下，Fiber要比UMS性能好一些，不过在1000 个线程的情况下UMS的实现比Fiber有一定的提升。不过两者比原生的线程（Native thread）相比，还是有很大的提高。另外要值得说的是，从资源管理器里看，UMS似乎是只能在单核上并发，无法像原生线程那样直接利用多核，如果将原生线程那样也 总结通过一个简单的性能对比，我们可以看到UMS在提升并发性能上比原生线程的调度要高出不少。但是，我们还是需要看到，UMS还是由一些方面的不足： 自定义的线程调度使编码变得复杂，相对于原生线程和Fiber的实现，UMS的代码量大大增加了。所以改进方式是把相关的系统调用函数封装成易于调用的库，对上层提供透明的编程模块。 性能对比里已经提到，UMS还是像Fiber那样只能利用单核，多核的扩展还是需要更多的支持。 从Win7开始，Windows提供UMS相关的功能已经有10年的时间，不过尚未看到该技术有大规模使用的案例，这也是其比较遗憾的一方面。不过这种通过自定义调度器的解决方法是值得借鉴的，因为它为利用原生线程提供大规模并发访问找到了一条可行的方式，并且给我们提供更多的思路来实现轻量级线程。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>云计算</tag>
        <tag>Windows</tag>
        <tag>UMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Rust编写用户态驱动程序]]></title>
    <url>%2F2018%2F08%2F19%2Fwrite-userspace-driver-in-rust%2F</url>
    <content type="text"><![CDATA[概览在云计算技术的发展史上，如何提高单个服务器的并发度，一直是热门的研究课题。在20年前，就有著名的“C10K”问题，即如何利用单个服务器每秒应对10K个客户端的同时访问。这么多年大量的实践证明，异步处理和基于事件（即epoll，kqueue和iocp）的响应方式成为处理这类问题的事实上标准方法。 不过，人类的追求是永无至今的。15年后，当摩尔定律在硬件上的理论提升有1000倍时，有人对并发数量提出了更高的要求，”C10K”升级为”C10M“问题，即每秒应对10M个客户端的同时访问。咋眼一看，怎么会有这样的服务，需要每秒处理上千万的并发？实际上这样的需求是广泛存在的，典型的例子就是DNS服务器、网络授时服务以及基于内存的key-value服务器。这种服务的特点是，一次客户请求涉及的计算量可能会很少，大部分时间均花在了IO上。所以根据Amdahl定律，优化的重点需放在如何减少I/O路径上的开销。 最早提出”C10M”问题的Robert Graham认为，减少开销的关键之一在于绕过操作系统，即”kernel bypass”，因为我们使用的操作系统在设计之初并没有考虑高并发的场景，而I/O路径上的大部分例程又在内核空间中，大量无谓的消耗花在了内核空间和用户空间上下文的切换上。解决的方法就是将I/O路径（对于网络请求来讲，就是驱动和网络协议栈）全部实现在用户空间，这样可以最大程度的减少内核的干预，并且通过轮询(polling)而不是硬件中断的方法来获取网卡上的请求（而对于存储器来讲，就是complete信息）。再结合其他优化方法，例如协程和零拷贝技术，可以将并发性能优化到极致，具体请见“内核才是问题的根本”。 基于这样的背景，一种未来的趋势是出更多的硬件驱动将在用户空间中实现，而这种趋势似乎正在慢慢成为现实。例如Intel的DPDK相关的技术，以及RDMA和XDP，都是此类思路的具体实践。在本文中，我们将尝试用Rust语言来实现一个极其简单的Intel ixgbe 10G网络控制器驱动，并在编写测试程序测试其基础性能。 需要特别说明的是，本文的目的之一是探寻Rust语言编写驱动的优缺点，所以对于具体的网络接口的硬件细节关注较少，所以实现基本上是在C语言版本的驱动emmericp/ixy 的基础上进行Rust移植。本文的相关代码请移步Github仓库。 为什么用Rust？Rust是一款能够保证安全和较高性能的静态编译型语言，其目标在于取代C，成为系统软件的主要实现语言。Rust充分利用了LLVM等最新的编译优化和静态分析技术，能够将安全和性能，这两个看似矛盾的目标很好的结合在一起，而我认为这正是驱动程序所不断追求的两个目标。几乎所有的安全检查都是在编译的过程中通过静态分析加以解决，如有违反，则编译立刻停止返回失败，因此避免了运行时的额外开销。Rust提供如下三个方面的安全性： 内存安全：Rust具有完整的内存生命周期检查，保证了一块区域的内存不会在其生命周期之外被引用，同时引入了所有权和borrow机制，使得变量要么处于共享只读，要么处于互斥写状态。另外，Rust也不允许空指针和悬空指针，所有变量需经过初始化才能使用； 类型安全：Rust是强类型语言，任何形式的类型转换都需要开发者进行显式的实现； 并发安全：因为Rust的所有权机制，使得变量和内存能够在多个线程之间进行传递和共享，而不用担心数据竞争的问题。 不过要指出的是，Rust为了能够与C中的函数进行互操作，以及更好地进行其他“非安全”的操作（例如指针运算，裸指针的解引用等），提供了unsafe关键字进行支持，同时也在代码中显式地指出这个地方可能会出现安全性问题。 驱动实现对于高性能计算中，通常的一种内存使用的优化方法是使用页面大小为2MB或1GB的巨页（hugepage），其好处在于： 减少缺页中断的次数，减少前文中提到内核空间和用户空间的上下文切换带来的开销； AMD64位处理器上的hugepage页表只有2-3层，可以减少MMU巡表时间，同时也能减少页表项的个数，便于TLB的缓存。 对于ixgbe驱动，同样也需要hugepage的支持。不过在Linux下，需要手动通过写sys文件系统进行开启，例如：123mkdir -p /mnt/hugemount -t hugetlbfs hugetlbfs /mnt/hugeecho 512 &gt; /sys/devices/system/node/node0/hugepages/hugepages-2048kB/nr_hugepages 关键数据结构DeviceInfo对于大多数的NIC网卡来讲，需要不同的方式来分别处理流入(receive, RX)和流出(transport, TX)的流量。而为了增加数据的并行度，对于高速网卡而言，通常每种模式可以设置多个队列（例如64）以流水线的方式存储数据，因此顶层的数据结构DeviceInfo包含这两种模式的不同队列： 1234567pub struct DeviceInfo &#123; num_rx_queues: u32, num_tx_queues: u32, rx_queues: Vec&lt;RxQueue&gt;, tx_queues: Vec&lt;TxQueue&gt;, addr: *mut u8,&#125; addr中存放的是网卡信息在内存中的映射地址，需要通过libc中的mmap操作获取得到。而在mmap操作之前，需要先知道到网卡在内核中的文件的句柄fd值，一种比较标准的做法是通过sys文件系统去读取对于pci地址上的设备信息： 12let file = open(format!(&quot;/sys/bus/pci/devices/&#123;&#125;/resource0&quot;, pci_addr));let addr = libc::mmap(..., file.as_raw_fd(), ...); RxQueue和TxQueueRxQueue和TxQueue结构体的定义分别如下：1234567891011121314151617181920struct RxQueue &#123; descriptors: *const u8, mempool: RefCell&lt;Mempool&gt;, num_entries: u16, // position we are reading from rx_index: u16, // virtual addresses to map descriptors back to their mbuf for freeing virtual_addresses: Vec&lt;*mut Buffer&gt;,&#125;struct TxQueue &#123; descriptors: *const u8, num_entries: u16, // position to clean up descriptors that where sent out by the nic clean_index: u16, // position to insert packets for transmission tx_index: u16, // virtual addresses to map descriptors back to their mbuf for freeing virtual_addresses: Vec&lt;*mut Buffer&gt;,&#125; 对RxQueue而言： descriptors：分配的DMA内存的起始地址， mempool：全局内存池的地址 num_entries：RX中队列数量 rx_index: 当前处理的队列序号 virtual_address：队列集合 同样地，对于TxQueue也有相似的数据项。 Buffer和Mempool为了能够很好地管理DMA内存，对于通过hugepage申请到的内存页面，我们通过Mempool数据结构进行管理，其内部的结构非常简单，并且对外有明确的结构，即分配(alloc)和回收(free)网卡数据包内存。 123456789pub struct Mempool &#123; free_stack: Vec&lt;*mut Buffer&gt;, free_stack_top: u32,&#125;impl Mempool &#123; pub fn alloc_buf(&amp;mut self) -&gt; Option&lt;*mut Buffer&gt;; pub fn free_buf(&amp;mut self, buf: *mut Buffer);&#125; 从网卡流入和流出的数据包，以及存放数据的具体位置，在Buffer结构体中定义： 123456789#[repr(C)]pub struct Buffer &#123; // physical address to pass a buffer to a nic buf_addr_phys: usize, pub mempool: *mut Mempool, idx: u32, pub size: u32, head_room: [u8; SIZE_PKT_BUF_HEADROOM as usize],&#125; 其他数据结构Stat统计RX和TX分别处理了多少个数据包和相应的字节数。1234567pub struct Stats &#123; rx_pkts: u32, tx_pkts: u32, rx_bytes: u64, tx_bytes: u64,&#125; 另外，还有一些数据结构，主要是封装了硬件相关的数据，举个例子：123456#[repr(C)]#[derive(Clone, Copy)]union AdvTxDesc &#123; read: TxAddr, wb: TxWriteback,&#125; 这里，read和wb分别表示同一块内存地址在不同模式下，具有不同的状态信息。所以这里我们使用了union结构。 使用宏（Macro）简化底层操作硬件驱动的另一个主要职责是，以合乎硬件手册的规范的方式来操纵寄存器和内存映射地址，而它需要大量的繁琐的代码。在C语言中，通常使用#define来定义这些宏，例如： 123456789/** Split and Replication Receive Control Registers* 00-15 : 0x02100 + n*4* 16-64 : 0x01014 + n*0x40* 64-127: 0x0D014 + (n-64)*0x40*/#define IXGBE_SRRCTL(_i) (((_i) &lt;= 15) ? (0x02100 + ((_i) * 4)) : \ (((_i) &lt; 64) ? (0x01014 + ((_i) * 0x40)) : \ (0x0D014 + (((_i) - 64) * 0x40)))) 而在Rust语言中，宏的定义也有相应的方式，即关键字macro_rules，所以上面的内存地址的访问，在Rust中等价的表达如下： 1234567891011macro_rules! IXGBE_SRRCTL &#123; ($_i:expr) =&gt; &#123; match ($_i) &lt;= 15 &#123; true =&gt; (0x02100 + (($_i) * 4)), false =&gt; match ($_i) &lt; 64 &#123; true =&gt; (0x01014 + (($_i) * 0x40)), false =&gt; (0x0D014 + ((($_i) - 64) * 0x40)), &#125;, &#125; &#125;;&#125; 另外，相对于C，Rust中定义宏还有个好处是，它具有清晰的语义，所有传入宏里的表达式参数均是先eval之后再参与计算，避免了诸如C中的下列歧义问题，所以建议大家多使用Rust中的宏来简化和更清晰地表达。 12#define test(i) i * 2test(1 + 1) 性能测试和总结按照仓库中的文档 进行编译并运行pktgen测试程序，代码基本上重现了ixy的实验结果。 在我的实验机器（2* Xeon E5-2640 + 64GB mem + Intel 82599ES网卡）上，pktgen运行的结果如下所示：123456789101112131415161718192021222324252627282930313233virt: 7fccda600000, phys: 816400000No driver loadedResetting device 0000:01:00.0Initializing device 0000:01:00.0initializing rx queue 0virt: 7fccda400000, phys: 816800000rx ring 0 phy addr: 816800000rx ring 0 virt addr: 7FCCDA400000virt: 7fccd9c00000, phys: 816e00000initializing tx queue 0virt: 7fccd9a00000, phys: 817000000tx ring 0 phy addr: 817000000tx ring 0 virt addr: 7FCCD9A00000starting rx queue 0starting queue 0enabling promisc modeWaiting for link...Link speed is 10000 Mbit/sRX: 0 Mbit/s 0 MppsTX: 9901.384292164801 Mbit/s 14.734186286261325 MppsRX: 0.0024058573361193836 Mbit/s 0.000001991603755065715 MppsTX: 9999.00754202517 Mbit/s 14.879477785084605 MppsRX: 0.0011392588353670422 Mbit/s 0.000000995855625320841 MppsTX: 9999.552267294279 Mbit/s 14.880286870792201 MppsRX: 0 Mbit/s 0 MppsTX: 9998.990842343424 Mbit/s 14.879450658249143 Mpps 由结果可以看出，TX基本上跑满10Gb的带宽，所以由Rust实现驱动在性能上能够和C不相上下。 但是，当前的实现中还有许多值得改进的地方，比如： 在Rust中，通常不应该有自己实现的内存分配器，更不应该有显式地的free类型的操作。不过因为我们使用了Hugepage来处理底层内存管理，所以这部分必须要自己实现，一种更优雅的做法是实现Rust中的alloc::alloc::Alloc类型的trait，以及相应的函数实现，以便于与其它的库很好的兼容，实现内存的自动管理。 1234trait Alloc &#123; unsafe fn alloc(&amp;mut self, layout: Layout) -&gt; Result&lt;NonNull&lt;u8&gt;, AllocErr&gt;; unsafe fn dealloc(&amp;mut self, ptr: NonNull&lt;u8&gt;, layout: Layout);&#125; 代码中的有些地方并不符合Rust的风格，例如在DeviceInfo中，rx_queues: Vec&lt;RxQueue&gt;项已经包含了队列的长度信息，不应该再添加重复的num_rx_queues: u32。 以上问题在以后优化中将持续改进。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>驱动</tag>
        <tag>Rust</tag>
        <tag>Kernel bypass</tag>
        <tag>ixgbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Capnproto优化RPC组合操作]]></title>
    <url>%2F2018%2F08%2F13%2Fusing-capnproto-for-operation-pipeline%2F</url>
    <content type="text"><![CDATA[Capnproto简介Capnproto是一款号称具有”infinity faster”的RPC框架。你可以认为它是JSON，只是它直接生成了二进制格式的消息；你可以认为它是Protocol Buffer，只是它更快而已。Capnproto 有多快呢？它主页上有张图是这样的： 不过连官方也表示这样的比较是不公平的，因为它仅测量了在内存中编码和解码消息的时间。Capnproto这里获得了满分，因为它根本就没有编码/解码步骤，所以我认为更合理的性能对比如下图所示。 相比之下，还是相当快的。Capnproto编码既适用于数据交换格式，也适用于在内存中表示，因此一旦构建了结构，便可以直接将字节写入磁盘中。 Schema语言Capnproto通过自定义语言来实现RPC接口和相应的操作，在这一点上和ProtoBuf以及Thrift 很像，如果你用过这两种语言，那么对此应该很熟悉。例如：1234567891011121314151617181920212223242526@0xdbb9ad1f14bf0b36; # unique file ID, generated by `capnp id`struct Person &#123; name @0 :Text; birthdate @3 :Date; email @1 :Text; phones @2 :List(PhoneNumber); struct PhoneNumber &#123; number @0 :Text; type @1 :Type; enum Type &#123; mobile @0; home @1; work @2; &#125; &#125;&#125;struct Date &#123; year @0 :Int16; month @1 :UInt8; day @2 :UInt8;&#125; 其内置的类型包括： Void: Void Boolean: Bool Integers: Int8, Int16, Int32, Int64 Unsigned integers: UInt8, UInt16, UInt32, UInt64 Floating-point: Float32, Float64 Blobs: Text, Data Lists: List(T) 以及常量，struct，union，enum，group等组合结构。另外，接口函数还支持泛型和泛函数等，可以说是相当强大。具体的语法请参考官方文档。 优化RPC组合操作不过我认为，Capnproto的优势还是体现在优化RPC组合操作上。 我们都知道，接口文件（Interface）描述了客户端和服务端之间所有的交互方式。设想一种场景，随着一个系统的不断演化，客户端新的行为需要之前从来没有过的接口操作，而这个时候，服务端相应的RPC方法，以及接口文件无法马上得到，而这个操作又恰恰可以是多个旧操作的组合。 举个例子，服务端维护一个数据库，保存的是某个网站上所有博客的内容，暴露给客户端的RPC操作仅有： 根据ID获取一篇博客信息: get(key) 根据ID删除博客内容： remove(key) 根据ID存储相应博客信息： store(key, blog) 现在客户端需要马上实现一个新的操作：copy某个博文从key1到key2，copy(key1, key2)。在接口不变的情况下，我们当然可以先用get将blog传回客户端，再用新ID和blog进行store操作。 不过在Capnproto框架下，可以采取不太一样的方式。Capnproto的RPC采取一种类似于Promise的方法，将所有接口操作流水化，中间结果不用传回客户端，因此这样减少了一次中间结果的往返传递，同时也减少了调用延迟。 也就是说，原来的需要如下方式实现的copy操作： 12value = get(key1);store(key2, value); 变成了类似如下的形式： 123getPromise = get(key1);storePromise = store(key2, getPromise);storePromise.then(...); 这里的中间步骤，将不再有blog数据传输。 在本文接下来的部分，我将用代码片段演示capnp接口的实现过程。完整的示例代码，请查看github仓库。 capnp接口为了使得客户端可以惰性地获取get(key)操作得结果，首先定义Blog信息的interface结构： 123interface Blog &#123; read @0 () -&gt; (blog :Text);&#125; Blog接口具有一个操作：read()，调用的结果是实际的blog数据。因此，get不再返回:Text 类型的数据，而是返回一个:Blog类型的接口。只有在调用这个接口的read函数之后才获取其中的值： 12345678interface BlogStore &#123; interface Blog &#123; read @0 () -&gt; (blog :Text); &#125; get @0 (key :UInt64) -&gt; (blog :Blog);&#125; 同时，为了使得store(key, blog)操作中的blog值，能够既支持从客户端传来的数据，又支持上次get操作返回的Blog接口，需要定义一个Store结构体： 123456struct Store &#123; union &#123; blog @0 :Text; previousGet @1 :Blog; &#125;&#125; 这个结构体中只有一个union项，表示可能的值是二者之一（capnp语言中的union不能单独定义，只能在struct中出现）。因此store操作的定义变成了如下形式： 1store @1 (key :UInt64, blog :Store); 最后，我们再加上remove(key)操作的定义，整个blogstore.capnp文件的内容就是下面这个样子： 123456789101112131415161718192021@0xf79af02aadd13d6d;interface BlogStore &#123; interface Blog &#123; read @0 () -&gt; (blog :Text); &#125; struct Store &#123; union &#123; blog @0 :Text; previousGet @1 :Blog; &#125; &#125; get @0 (key :UInt64) -&gt; (blog :Blog); store @1 (key :UInt64, blog :Store); remove @2 (key :UInt64);&#125; 利用capnp编译器编译blogstore.capnp，生成相应的blogstore.capnp.h和blogstore.capnp.c++：1capnpc -oc++ blogstore.capnp 在此基础上，还需要实现客户端代码和服务端代码，具体的教程可以参考官方的RPC教程。 性能对比设定所有的blog数据均是4096字节大小的UTF-8字符串数据。在AWS的c3.large主机上，我的代码实现在不同网络结构下的性能对比： Operation Get Store Remove Copy Unix domain socket 207µs 161µs 152µs 232µs Loopback device 246µs 163µs 152µs 267µs Local network 446µs 372µs 301µs 381µs 一次copy操作所用的时间大致和get相当，但是远小于get和store之和。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>Capnproto</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hello]]></title>
    <url>%2F2018%2F08%2F11%2Fhello%2F</url>
    <content type="text"><![CDATA[Hello, Vincent Vega.]]></content>
  </entry>
</search>
